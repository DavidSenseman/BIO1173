{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/main/Class_06_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ki7Qaf8aomp"
      },
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZuqN8TMaomp"
      },
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "Sb7ypOhxaomp"
      },
      "source": [
        "**Module 6: Convolutional Neural Networks (CNN) for Computer Vision**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "### Module 6 Material\n",
        "\n",
        "* Part 6.1: Using Convolutional Neural Networks\n",
        "* **Part 6.2: Using Pretrained Neural Networks with Keras**\n",
        "* Part 6.3: Looking at Keras Generators and Image Augmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGTQ-cciaomp"
      },
      "source": [
        "### Lesson Setup\n",
        "\n",
        "Run the next code cell to load necessary packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKQylnEiLDUM"
      },
      "source": [
        "### Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n",
        "  Running the following code will map your GDrive to ```/content/drive```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seXFCYH4LDUM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# YOU MUST RUN THIS CELL FIRST\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6mkraW6aomq"
      },
      "source": [
        "### Define functions\n",
        "\n",
        "The cell below creates the function(s) needed for this lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k_xChO0Fkn4S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Simple function to print out elasped time\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Record your specific GPU/TPU accelerator**\n",
        "To faciliate grading of your homework, it is important that you specify which hardware accelerator you are using. Unfornuately, this has to be done manually since there is no other way to get this information.\n",
        "\n",
        "In the cell below there is a Python dictionary called my_GPU_dict. Below the dictionary is the code fragment:\n",
        "\n",
        "~~~text\n",
        "# Enter the correct key number in the square brackets [ ]\n",
        "my_GPU = my_GPU_dict[ ]\n",
        "~~~\n",
        "\n",
        "Before you can continue, you must place a number within the square brackets corresponding to your selected GPU or TPU. For example, if you are using the recommended A100 GPU you would enter the number 2 in the square brackets and then run the cell."
      ],
      "metadata": {
        "id": "u9Hifbl4-B7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Record your current Runtime GPU/TPU\n",
        "\n",
        "\n",
        "# List of Current GPU/TPUs\n",
        "my_GPU_dict = {\n",
        "    1: 'CPU',\n",
        "    2: 'A100 GPU',\n",
        "    3: 'L4 GPU',\n",
        "    4: 'T4 GPU',\n",
        "    5: 'TPU v2-8'\n",
        "}\n",
        "\n",
        "# Enter the correct key number in the square brackets [ ]\n",
        "my_GPU = my_GPU_dict[  ]\n",
        "\n",
        "# Print selection\n",
        "print(f\"My current runtime GPU/TPU is: {my_GPU}\")"
      ],
      "metadata": {
        "id": "TN6RfeCa-SbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see something like the following:\n",
        "\n",
        "~~~text\n",
        "My current runtime GPU/TPU is: T4 GPU\n",
        "~~~\n",
        "If you don't put a number inside the square brackets, you will receive an error message."
      ],
      "metadata": {
        "id": "8wI4EX6u-bS2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q09yMGGcmp9N"
      },
      "source": [
        "# **Part 6.2: Transfer Learning for Computer Vision**\n",
        "\n",
        "Many advanced prebuilt neural networks are available for computer vision, and Keras provides direct access to many networks. **_Transfer Learning_** is the technique where you use these prebuilt neural networks.\n",
        "\n",
        "There are several different levels of transfer learning.\n",
        "\n",
        "* Use a prebuilt neural network in its entirety\n",
        "* Use a prebuilt neural network's structure\n",
        "* Use a prebuilt neural network's weights\n",
        "\n",
        "We will begin by using the **MobileNet** prebuilt neural network in its entirety. MobileNet will be loaded and allowed to classify simple images. We can already classify 1,000 images through this technique without ever having trained the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB4Im0gKfF0J"
      },
      "source": [
        "We begin by downloading weights for a MobileNet trained for the imagenet dataset, which will take some time to download the first time you train the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUDtlNDxfMBA"
      },
      "outputs": [],
      "source": [
        "# Download Pre-Trained neural network\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "\n",
        "model = MobileNet(weights='imagenet',include_top=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
        "17225924/17225924 ━━━━━━━━━━━━━━━━━━━━ 0s 0us/step\n",
        "~~~"
      ],
      "metadata": {
        "id": "RqJkkVnbcAnv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwuvm2W_fRZy"
      },
      "source": [
        "The loaded network is a Keras neural network. However, this is a neural network that a third party engineered on advanced hardware. Merely looking at the structure of an advanced state-of-the-art neural network can be educational."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YF5ZFnrqfXA5",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "3877f9c7-f798-4613-b72c-b434c9614347"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mobilenet_1.00_224\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mobilenet_1.00_224\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m864\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_1 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m288\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_1_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_1 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_1_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pad_2 (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_2 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_2_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_2 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m8,192\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_2_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_3 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m1,152\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_3_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_3 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m16,384\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_3_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pad_4 (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_4 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m1,152\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_4_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_4 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m32,768\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_4_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_5 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m2,304\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_5_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_5 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m65,536\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_5_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pad_6 (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_6 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m2,304\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_6_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_6 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m131,072\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_6_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_7 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m4,608\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_7_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_7_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_7 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m262,144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_7_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_7_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_8 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m4,608\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_8_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_8_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_8 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m262,144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_8_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_8_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_9 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m4,608\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_9_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_9_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_9 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m262,144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_9_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_9_relu (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_10 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m4,608\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_10_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_10_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_10 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m262,144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_10_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_10_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_11 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m4,608\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_11_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_11_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_11 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m262,144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_11_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_11_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pad_12 (\u001b[38;5;33mZeroPadding2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_12 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m4,608\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_12_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_12_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_12 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │         \u001b[38;5;34m524,288\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_12_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_12_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_13 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │           \u001b[38;5;34m9,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_13_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_13_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_13 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │       \u001b[38;5;34m1,048,576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_13_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_13_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_preds (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)          │       \u001b[38;5;34m1,025,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ predictions (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_1_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_1_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pad_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_2_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_2_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_3_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_3_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pad_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_4_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_4_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_5_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_5_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pad_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_6_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_6_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_7_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_7_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_7_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_7_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_8_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_8_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_8_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_8_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_9_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_9_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_9_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_9_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_10_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_10_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_10_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_10_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_11_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_11_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_11_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_11_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pad_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_12_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_12_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_13_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_dw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_13_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_pw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_preds (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,253,864\u001b[0m (16.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,253,864</span> (16.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,231,976\u001b[0m (16.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,231,976</span> (16.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,888\u001b[0m (85.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,888</span> (85.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show model structure\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcdKUTOAfbw0"
      },
      "source": [
        "Several clues to neural network architecture become evident when examining the above structure.\n",
        "\n",
        "**_MobileNet_** is a neural network architecture designed for mobile and embedded applications to be computationally efficient. The key components of the MobileNet architecture include depthwise separable convolutions and pointwise convolutions.\n",
        "* **Depthwise separable convolutions:** MobileNet replaces traditional convolutions with depthwise separable convolutions, which consists of two separate operations: depthwise convolutions and pointwise convolutions. Depthwise convolutions apply a single filter for each input channel, while pointwise convolutions apply 1x1 convolutions to combine the outputs of depthwise convolutions.\n",
        "* **Pointwise convolutions:** Pointwise convolutions are used to increase the depth of the feature maps while keeping the spatial dimensions the same. This allows for efficient learning of complex patterns while reducing the computational cost.\n",
        "* **Inverted residuals with linear bottleneck:** MobileNetV2 introduces inverted residuals with linear bottleneck to improve performance. Inverted residuals use an expansion layer to increase the number of channels followed by a depthwise convolution and a projection layer to reduce the number of channels back to the original dimensions.\n",
        "\n",
        "Overall, the MobileNet architecture is designed to be lightweight and efficient while maintaining high accuracy for a wide range of tasks, making it ideal for deployment on mobile and edge devices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTyH6hyyaomr"
      },
      "source": [
        "## Example 1: Use MobileNet to classify images\n",
        "\n",
        "The code in the cell below creates a two functions that we will need to use classify images using MobileNet.\n",
        "\n",
        "* **make_square()** Since MobileNet is designed to classify images with the same number of horizontal and vertical pixels (i.e. a 'square' image), this function uses a combination of padding and cropping to convert any image into a 'square` image.\n",
        "  \n",
        "* **classify_image()** This function does most of the work. It first retrives the image from the HTTPS server and resizes it before processing it by the MobileNet model that we previously downloaded. The actual prediction is made by this line of code:\n",
        "\n",
        "~~~text\n",
        "  # Use MobileNet model to predict image\n",
        "  pred = model.predict(x)\n",
        "~~~\n",
        "\n",
        "We will now use the MobileNet to classify several image URLs below.  You are encourged to to add additional URLs of your own to see how well the MobileNet can classify."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from PIL import Image, ImageFile, UnidentifiedImageError\n",
        "from matplotlib.pyplot import imshow\n",
        "import requests\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from IPython.display import display\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet, decode_predictions\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS = 224, 224, 3\n",
        "\n",
        "model = MobileNet(weights='imagenet')\n",
        "\n",
        "# Define HTTPS image source\n",
        "ROOT = \"https://biologicslab.co/BIO1173/images/class_06_2/\"\n",
        "\n",
        "# Function to make sample image square\n",
        "def make_square(img):\n",
        "    cols, rows = img.size\n",
        "    pad = ((rows - cols) // 2, 0, (rows - cols) // 2, 0) if rows > cols else (0, (cols - rows) // 2, 0, (cols - rows) // 2)\n",
        "    return img.crop(pad)\n",
        "\n",
        "# Function to classify image\n",
        "def classify_image(url):\n",
        "    ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
        "\n",
        "    try:\n",
        "        # Get image from HTTPS server\n",
        "        response = requests.get(url)\n",
        "        img = Image.open(BytesIO(response.content)).resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.LANCZOS)\n",
        "    except UnidentifiedImageError:\n",
        "        print(\"Error: Cannot identify image file. Check the image URL or file format.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return\n",
        "\n",
        "    # Preprocess the image\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x[:, :, :, :3])  # ensure no alpha channel\n",
        "\n",
        "    # Use MobileNet model to predict image\n",
        "    preds = model.predict(x)\n",
        "\n",
        "    # Show the image\n",
        "    display(img)\n",
        "\n",
        "    # Print out MobileNet's first 5 predictions\n",
        "    for pred in decode_predictions(preds, top=5)[0]:\n",
        "        print(pred)\n"
      ],
      "metadata": {
        "id": "k3x1MIVlfsYx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP6UnmqcjAAo"
      },
      "source": [
        "We can now classify an example image.  You can specify the URL of any image you wish to classify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CE0NTgraomr"
      },
      "source": [
        "### Example 1A: Classify images\n",
        "\n",
        "Our MobileNet model has been trained to recognize a wide range of images. Let's try a few different types of images to get some idea of what MobileNet knows.\n",
        "\n",
        "Let's start with a picture of Abraham Lincoln. Here is the actual image before being processed:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06_2/abraham_lincoln.jpg)\n",
        "\n",
        "Probably most US school children could correctly identify this image. You should notice that this is _not_ a square image. Let's see what happens when we process it and submit the processed image to our model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwfnWNXSo7Vk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Example 1A:\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "classify_image(ROOT+\"abraham_lincoln.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06/class_06_2_image01.png)"
      ],
      "metadata": {
        "id": "oICNdrBmefqv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEzm0Klfaoms"
      },
      "source": [
        "From visual inspection of the output, MobileNet concluded that there was a 93% chance that the image contained a `bow tie` and less than a 1% chance the image contained a `suit`.\n",
        "\n",
        "Apparently, the creators of MobileNet didn't include images of American presidents in their training set. What MobileNet \"saw\" wasn't the Lincoln's face, but the clothes he was wearing.\n",
        "\n",
        "We can also see what happens when our code converts a rectangular image into a square image. Lincoln's face is still clearly recognizable albeit a bit 'squashed'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB2bFChLaoms"
      },
      "source": [
        "### Example 1B: Classify Images\n",
        "\n",
        "Perhaps MobileNet only recognizes famous people who are currently alive? Let's see how MobileNet does with another former President of the US (POTUS)?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "hH6IpkKPaoms"
      },
      "outputs": [],
      "source": [
        "# Example 1B:\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "classify_image(ROOT+\"trump.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06/class_06_2_image02.png)"
      ],
      "metadata": {
        "id": "qOspbNN_gKwC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkW8SEhDaoms"
      },
      "source": [
        "Once again, MobileNet doesn't seem to know the names of American Presidents. Rather, MobilNet tried to classify the \"objects\" it saw, not the people.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJXZSmXnaoms"
      },
      "source": [
        "### Example 1C: Classify Images\n",
        "\n",
        "Let's try something else. How about a nice Thompson Submachine gun? This particular image is of a [Lancer Tactical Extra 50 Rounds Airsoft Magazine - Airsoft Tommy Thompson Submachine Gun (2X Drum 2X Stick)](https://us.amazon.com/Lancer-Tactical-Rounds-Airsoft-Magazine/dp/B0C24VRLM1). This airgun is sold on Amazon in case you might like to buy it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "PNk_zkAeaoms"
      },
      "outputs": [],
      "source": [
        "# Example 1C:\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "classify_image(ROOT+\"submachine_gun.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06/class_06_2_image03.png)"
      ],
      "metadata": {
        "id": "mQSz42GOhT-W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydJG5nX6aoms"
      },
      "source": [
        "Finally, we have one type of image that MobileNet has been trained on. MobileNet predicted that there was an approximately 54% chance that our image of a Thompson Submachine Gun was an 'assault_rife' and a 49% that the image was some kind of 'rifle'.\n",
        "\n",
        "Technically, the Thompson Submachine Gun is _not_ considered to be an assault rife or even a rifle, but it wasn't a bad guess."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PTCwUCdaoms"
      },
      "source": [
        "### Example 1D: Classify images\n",
        "\n",
        "Let's see how MobileNet does with an image of an American soldier with a _real_ assault rifle, an M16."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "kljX1r_gaoms"
      },
      "outputs": [],
      "source": [
        "# Example 1D:\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "classify_image(ROOT+\"M16.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06/class_06_2_image04.png)"
      ],
      "metadata": {
        "id": "0arcyhLnh7eU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Eeped0Yaoms"
      },
      "source": [
        "For this image, MobileNet did pretty good. It predicted that there was an 65% chance that the image showed an assault rifle. (The M16 is considered an assult rifle). Again, MobileNet seems to ignore the inclusion of people in an image and focus on inanimate objects in the image including the presence of a `military uniform`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynAikv5taoms"
      },
      "source": [
        "## **Exercise 1: Classify images**\n",
        "\n",
        "For **Exercise 1**, you are present our MobileNet model the following series of 8 animal images.\n",
        "\n",
        "1. puffer_fish.jpg (Exercise 1A)\n",
        "2. king_cobra.jpg (Exercise 1B)\n",
        "3. monarch_butterfly.jpg (Exercise 1C)\n",
        "4. viceroy_butterfly.jpg (Exercise 1D)\n",
        "5. meerkat.jpg (Exercise 1E)\n",
        "6. paramecium.jpg (Exercise 1F)\n",
        "7. prairie_dog.jpg (Exercise 1G)\n",
        "8. great-white-shark.jpg (Exercise 1H)\n",
        "\n",
        "You will need to make a new code cell for each exercise.\n",
        "\n",
        "If you are using COLAB, you can add a new code cell by pointing your cursor at the bottom edge of the code cell and pressing the button below:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06_2_add_code.png)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q_t3HzW1aomt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coCA5NZzaomt"
      },
      "source": [
        "If your code is correct, you should have received the following output (only the the first value is shown):\n",
        "\n",
        "1. `puffer_fish.jpg` ('n02655020', 'puffer', 0.99882895)  Note: 99% accurate!\n",
        "2. `king_cobra.jpg` ('n01748264', 'Indian_cobra', 0.999587) Note: Indian cobras are much smaller than king cobras so technically, MobileNet got this wrong. However, there is no way to know the size of the snake in the image, so we can score this as being 100% accurate.\n",
        "3. `monarch_butterfly.jpg` ('n02279972', 'monarch', 0.99983335) Note: Nailed it!\n",
        "4. `viceroy_butterfly.jpg` ('n02279972', 'monarch', 0.9988518) Note: Oops! A total fail, but completely understandable. MobileNet again predicted that there was 100% probability that the picture was a monarch butterfly (_Danaus plexippus_), when in fact it was a viceroy butterfly, a completely different genus and species (_Limenitis archippus_). Of course these two species look very, very similar. The viceroy and the monarch butterflies are [Müllerian mimics](https://en.wikipedia.org/wiki/M%C3%BCllerian_mimicry) of each other. It is certainly possible to train a neural network to do this for example [MonarchNet](https://ai4earthscience.github.io/neurips-2020-workshop/papers/ai4earth_neurips_2020_57.pdf). As will be shown below you could start with the MobileNet as give it additional training to differentiate images of monarchs and viceroys with a high degree of precision.\n",
        "5. `meerkat.jpg` ('n02138441', 'meerkat', 0.9629027) Note: Not bad! 96% accurate.\n",
        "6. `paramecium.jpg` ('n01930112', 'nematode', 0.8969467) Note: Not too close. A nematode is round worm such as the common human parasite, the pinworm (_Enterobius_). Apparently, MobileNet wasn't extensively programmed for unicelluar organisms.\n",
        "7. `prairie_dog.jpg` ('n02361337', 'marmot', 0.93886554) Note: Another fail, but again understandable. [Marmots](https://en.wikipedia.org/wiki/Marmot) genus _Marmota_ are quite similar in appearance to pairie dogs, so we can give a 'pass' to MobileNet for getting these two species confused.\n",
        "8. `great-white-shark.jpg` ('n01484850', 'great_white_shark', 0.9989716) Note: Nailed it! 100% correct prediction.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D523in0Faomt"
      },
      "source": [
        "### MobileNet Summary\n",
        "\n",
        "Overall, our MobileNet neural network did quite well, as long as you picked one of the 1000 image types it supports. For many applications, MobileNet might be entirely acceptable as an image classifier.\n",
        "\n",
        "However, if you need to classify very specialized images, like monarch vs viceroy butterflies, or marmots vs prairie dogs --image types supported by imagenet--it is necessary to use **_transfer learning_**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdhYb-8Daomt"
      },
      "source": [
        "--------------------------------\n",
        "\n",
        "## **ResNet vs MobileNet**\n",
        "\n",
        "MobileNet and ResNet are both popular deep learning architectures, but they have some key differences:\n",
        "\n",
        "* **Architecture:** MobileNet uses depthwise separable convolutions, which consist of depthwise convolutions and pointwise convolutions, to reduce the computational cost and make the model more efficient for mobile and embedded applications. ResNet, on the other hand, uses residual blocks with skip connections to learn residual mappings for easier training of deep networks.\n",
        "* **Model size:** MobileNet is known for its lightweight and compact design, making it easy to deploy on mobile devices with limited computational resources. In contrast, ResNet is a deeper network with more parameters, which can lead to higher accuracy but also requires more computational resources.\n",
        "* **Training complexity:** ResNet can be easier to train compared to MobileNet, especially for deeper architectures, due to the use of skip connections that help with gradient flow and alleviate the vanishing gradient problem.\n",
        "* **Performance:** ResNet is often used for tasks that require high accuracy, such as image classification on large datasets like ImageNet. MobileNet is designed for efficiency and speed, making it suitable for real-time applications on mobile devices.\n",
        "\n",
        "Overall, the choice between MobileNet and ResNet depends on the specific requirements of the application, such as computational resources, accuracy goals, and deployment constraints.\n",
        "\n",
        "----------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example 2: Use ResNet for Regression CNN**\n",
        "\n",
        "For Example 2 we are going to use ResNet as a basis for building a CNN that can count the number of paperclips in an image. We will provide an image and expect the neural network to count items in that image. We will use a dataset created by Jeff Heaton that contains a random number of paperclips.\n",
        "\n",
        "Here are four sample images from the 25,000 images in the paperclips dataset:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06/class_06_2_paperclips.png)\n",
        "\n",
        "\n",
        "Our goal will be to create a convolutional neural network (CNN) that can count the number of paperclips in an image. To put in a more ecological or biomedical context, a similar neural network could also be trained to count the number of giant Saguaro cacti (_Carnegiea gigantea_) in an image of the Sonoran Desert, or the number of leucocytes in a blood smear from a patient with symptoms of AML (Acute myeloid leukemia).\n"
      ],
      "metadata": {
        "id": "QFz_GonQgiOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although paperclips are not biomedically relevant items to count, the code shown below could used to count"
      ],
      "metadata": {
        "id": "YN7JybKbixZ2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgVuchh9aomw"
      },
      "source": [
        "### **Example 2 - Step 1: Set ENVIRONMENTAL VARIABLES**\n",
        "\n",
        "The code in the cell below defines a number of ENVIRONMENTAL VARIABLES that are needed for latter code cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpfadrdQcVg8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Example 2 - Step 1: Set ENVIRONMENTAL VARIABLES\n",
        "\n",
        "import os\n",
        "\n",
        "URL = \"https://biologicslab.co/BIO1173/data/\"\n",
        "DOWNLOAD_SOURCE = URL+\"paperclips.zip\"\n",
        "DOWNLOAD_NAME = DOWNLOAD_SOURCE[DOWNLOAD_SOURCE.rfind('/')+1:]\n",
        "print(\"DOWNLOAD_SOURCE=\",DOWNLOAD_SOURCE)\n",
        "print(\"DOWNLOAD_NAME=\",DOWNLOAD_NAME)\n",
        "\n",
        "PATH = \"/content\"\n",
        "EXTRACT_TARGET = os.path.join(PATH,\"clips\")\n",
        "SOURCE = os.path.join(EXTRACT_TARGET, \"paperclips\")\n",
        "\n",
        "print(\"ENVIRONMENTAL VARIABLES were successfully created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuBLdjMiaomw"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "~~~text\n",
        "DOWNLOAD_SOURCE= https://biologicslab.co/BIO1173/data/paperclips.zip\n",
        "DOWNLOAD_NAME= paperclips.zip\n",
        "ENVIRONMENTAL VARIABLES were successfully created.\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQiDl3Z6aomw"
      },
      "source": [
        "### **Example 2 - Step 2: Download and Extract Image Data**\n",
        "\n",
        "The code in the cell below downloads a zip file from the course HTTPS server, `https://biologicslab.co/BIO1173/data`, called `paperclips.zip`. The code then extracts (unzips) data in the zip file into a new folder called `/clips`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - Step 2: Download and Extract Data\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Creating necessary directories...\", end='')\n",
        "# Create necessary directories\n",
        "os.makedirs(SOURCE, exist_ok=True)\n",
        "os.makedirs(EXTRACT_TARGET, exist_ok=True)\n",
        "print(\"done.\")\n",
        "\n",
        "print(\"Downloading files...\", end='')\n",
        "# Define paths and URLs\n",
        "download_path = os.path.join(PATH, DOWNLOAD_NAME)\n",
        "extract_path = os.path.join(EXTRACT_TARGET, DOWNLOAD_NAME)\n",
        "\n",
        "# Download the file\n",
        "os.system(f\"wget -O {download_path} {DOWNLOAD_SOURCE}\")\n",
        "print(\"done.\")\n",
        "\n",
        "print(\"Extracting files...\", end='')\n",
        "# Extract the file\n",
        "os.system(f\"unzip -o -d {EXTRACT_TARGET} {download_path} >/dev/null\")\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "id": "xS62QUC7k68H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7yGFymMaomw"
      },
      "source": [
        " If your code is correct, you should see something similar to the following output:\n",
        "\n",
        "~~~text\n",
        "Creating necessary directories...done.\n",
        "Downloading files...done.\n",
        "Extracting files...done.\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX4uUN5DkuYH"
      },
      "source": [
        "### **Example 2 - Step 3: Load the Labels for the Training Set**\n",
        "\n",
        "The labels are contained in a CSV file named **train.csv** for the regression. This file has just two labels, **id** and **clip_count**. The ID specifies the filename; for example, row id 1 corresponds to the file **clips-1.jpg**. The following code loads the labels for the training set and creates a new column, named **filename**, that contains the filename of each image, based on the **id** column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4W4LeGSqYya",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Example 2 - Step 3: Load the Labels for the Training Set\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read the label file\n",
        "df = pd.read_csv(\n",
        "        os.path.join(SOURCE,\"train.csv\"),\n",
        "        na_values=['NA', '?'])\n",
        "\n",
        "# Convert\n",
        "df['filename']=\"clips-\"+df[\"id\"].astype(str)+\".jpg\"\n",
        "\n",
        "# Print out df\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGxjITNtz0sC"
      },
      "source": [
        "This results in the following dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6x3Rfnlaomx"
      },
      "source": [
        "If your code is correct you should see the following table:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06/class_06_2_df.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHLcB3lPaomx"
      },
      "source": [
        "### **Example 2 = Step 4: Split images into training and validation sets**\n",
        "\n",
        "The code in the cell below, splits the paperclips images into a training set and a validation set, with 90% of the images going into the training set. The number images in both sets is printed out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI4_qNaSqp31",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Split images into training and validation sets\n",
        "\n",
        "# create dataframes to data\n",
        "df_train = pd.read_csv(os.path.join(SOURCE, \"train.csv\"))\n",
        "df_train['filename'] = \"clips-\" + df_train.id.astype(str) + \".jpg\"\n",
        "\n",
        "TRAIN_PCT = 0.9\n",
        "TRAIN_CUT = int(len(df_train) * TRAIN_PCT)\n",
        "\n",
        "df_train_cut = df_train[0:TRAIN_CUT]\n",
        "df_validate_cut = df_train[TRAIN_CUT:]\n",
        "\n",
        "print(f\"Training size: {len(df_train_cut)}\")\n",
        "print(f\"Validate size: {len(df_validate_cut)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dtoDQGgaomx"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "~~~text\n",
        "Training size: 18000\n",
        "Validate size: 2000\n",
        "~~~\n",
        "We want to use early stopping. To do this, we need a validation set. We will break the data into 90% test data and 10% validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdF0KQvFaomx"
      },
      "source": [
        "## Transfer Learning using `ResNet`\n",
        "\n",
        "For **Example 2** we will make use of the structure of the **ResNet** neural network. However, there are several significant changes that we will make to ResNet to apply to this task.\n",
        "\n",
        "First, ResNet is a classifier. However, we wish to perform a regression to count. Secondly, we want to change the image resolution that ResNet uses. Since the synaptic weights that comes with ResNet are designed to work with a different image resolution, we can't use these weights, so we won't import them. However, this means we will need to retrain the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj_umT9VgRzI"
      },
      "source": [
        "### **Example 2 - Step 5: Create Image Generators**\n",
        "\n",
        "Next, we create the generators that will provide the images to the neural network during training.\n",
        "\n",
        "A Keras Image Generator, specifically `ImageDataGenerator`, is a powerful tool for creating batches of image data in real-time with optional data augmentation. This means it can apply random transformations like rotations, shifts, flips, and more, to your images while feeding them to your model, thus enhancing the diversity of your training data and helping prevent overfitting.\n",
        "\n",
        "In short, it automates the flow of image data from directories and applies transformations on-the-fly. It's especially useful for handling large datasets and implementing data augmentation effortlessly.\n",
        "\n",
        "In the cell below, we normalize the images so that the RGB colors between 0-255 become ratios between 0 and 1. We also use the **flow_from_dataframe** generator to connect the Pandas dataframe to the actual image files. We see here a straightforward implementation; you might also wish to use some of the image transformations provided by the data generator.\n",
        "\n",
        "The **HEIGHT** and **WIDTH** constants specify the dimensions to which the image will be scaled (or expanded). It is probably not a good idea to expand the images."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Install Keras Image Generator**\n",
        "\n",
        "The Keras function `ImageDataGenerator` is part of the Keras package `keras_preprocessing` which needs to be installed by running the next code cell."
      ],
      "metadata": {
        "id": "3gE7CIBbozNa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "THpzclwHaomx"
      },
      "outputs": [],
      "source": [
        "# Install Keras package\n",
        "\n",
        "!pip install keras_preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "Collecting keras_preprocessing\n",
        "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
        "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.26.4)\n",
        "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
        "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
        "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 kB 1.8 MB/s eta 0:00:00\n",
        "Installing collected packages: keras_preprocessing\n",
        "Successfully installed keras_preprocessing-1.1.2\n",
        "~~~"
      ],
      "metadata": {
        "id": "030Vcb-fpbYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that correct packages have been loaded, we can create our image generators."
      ],
      "metadata": {
        "id": "KC5Rh9aEpmDo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYiMObEJsoof",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "WIDTH = 256\n",
        "HEIGHT = 256\n",
        "BATCH_SIZE_TRAIN = 32\n",
        "BATCH_SIZE_VAL = 256\n",
        "\n",
        "training_datagen = ImageDataGenerator(\n",
        "  rescale = 1./255,\n",
        "  horizontal_flip=True,\n",
        "  #vertical_flip=True,\n",
        "  fill_mode='nearest')\n",
        "\n",
        "train_generator = training_datagen.flow_from_dataframe(\n",
        "        dataframe=df_train_cut,\n",
        "        directory=SOURCE,\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"clip_count\",\n",
        "        target_size=(HEIGHT, WIDTH),\n",
        "        # Keeping the training batch size small\n",
        "        # USUALLY increases performance\n",
        "        batch_size=BATCH_SIZE_TRAIN,\n",
        "        class_mode='raw')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "val_generator = validation_datagen.flow_from_dataframe(\n",
        "        dataframe=df_validate_cut,\n",
        "        directory=SOURCE,\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"clip_count\",\n",
        "        target_size=(HEIGHT, WIDTH),\n",
        "        # Make the validation batch size as large as you\n",
        "        # have memory for\n",
        "        batch_size=BATCH_SIZE_VAL,\n",
        "        class_mode='raw')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYxcfHqTaomy"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "~~~text\n",
        "Found 18000 validated image filenames.\n",
        "Found 2000 validated image filenames.\n",
        "~~~\n",
        "This means that our train and validation generator are working properly and they know where to find the images of paperclips."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rVZJBMIgqJq"
      },
      "source": [
        "# **Transfer Learning with ResNet**\n",
        "\n",
        "We will now use a ResNet neural network as a basis for our neural network. We will redefine both the input shape and output of the ResNet model, so we will not transfer the weights. Since we redefine the input, the weights are of minimal value.\n",
        "\n",
        "We begin by loading, from Keras, the `ResNet50 network`. We specify **include_top** as `False` because we will change the input resolution. We also specify **weights** as `False` because we must retrain the network after changing the top input layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBx-hAl-aomy"
      },
      "source": [
        "### **Example 2 - Step 6: Redefine the input shape**\n",
        "\n",
        "The first modification of the base ResNet model `ResNet50` that we need to make is to redefine the image shape to 256 X 256 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6MJpmLyhtahJ"
      },
      "outputs": [],
      "source": [
        "# Example 2 - Step 6: Redefine the input shape\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Set variables\n",
        "HEIGHT = 256\n",
        "WIDTH = 256\n",
        "\n",
        "input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
        "\n",
        "base_model = ResNet50(\n",
        "    include_top=False, weights=None, input_tensor=input_tensor,\n",
        "    input_shape=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xF9EKVFhAGl"
      },
      "source": [
        "### **Example 2 - Step 7: Add Layers to Convert Model to Regression**\n",
        "\n",
        "Now we must add a few layers to the end of the neural network so that it becomes a regression model. As you should expect for a regression model, there is only a single neuron in the output layer:\n",
        "~~~text\n",
        "model=Model(inputs=base_model.input,outputs=Dense(1)(x))\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gXO3lTFIs_U1"
      },
      "outputs": [],
      "source": [
        "# Example 2 - Step 7:Add layers to convert model to regression\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x)\n",
        "x=Dense(1024,activation='relu')(x)\n",
        "model=Model(inputs=base_model.input,outputs=Dense(1)(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErCUZTv1hJDx"
      },
      "source": [
        "### **Example 2 - Step 8: Train the Model**\n",
        "\n",
        "In the cell below, we provide **additional** training to the base `ResNet50` model by \"showing it\" 16200 test images with their labels (i.e. how many paperclips are in the image) using a 1800 validation image set to allow us to have EarlyStopping.\n",
        "\n",
        "Training is like before. However, we do not define the entire neural network here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - Step 8: Train the Model\n",
        "\n",
        "import time\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "\n",
        "# Set variables\n",
        "EPOCHS = 100\n",
        "PATIENCE = 20\n",
        "BATCH_SIZE_TRAIN = train_generator.batch_size\n",
        "BATCH_SIZE_VAL = val_generator.batch_size\n",
        "STEP_SIZE_VALID = val_generator.n // BATCH_SIZE_VAL\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam',\n",
        "              metrics=[RootMeanSquaredError(name=\"rmse\")])\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3,\n",
        "                        patience=PATIENCE, verbose=1, mode='auto',\n",
        "                        restore_best_weights=True)\n",
        "\n",
        "print(f\"-- Training is starting for {EPOCHS} epochs, batch size train: {BATCH_SIZE_TRAIN}, batch size val: {BATCH_SIZE_VAL}, runtime GPU/TPU: {my_GPU} ----------\")\n",
        "\n",
        "history = model.fit(train_generator, epochs=EPOCHS, steps_per_epoch=250,\n",
        "                    validation_data=val_generator, callbacks=[monitor],\n",
        "                    verbose=1, validation_steps=STEP_SIZE_VALID)\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"Elapsed time: {elapsed_time // 3600}:{(elapsed_time % 3600) // 60}:{elapsed_time % 60:.2f}\")\n"
      ],
      "metadata": {
        "id": "i3WnGyG0ehW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXHwP_hXwKwZ"
      },
      "source": [
        "If `EarlyStopping` doesn't kick in, training may require a significant amount of time to complete all 100 epochs.\n",
        "\n",
        "Here is the final output on COLAB using the `A100 GPU`:\n",
        "\n",
        "~~~text\n",
        "Epoch 29/100\n",
        "250/250 ━━━━━━━━━━━━━━━━━━━━ 18s 72ms/step - loss: 3.9306 - rmse: 1.9802 - val_loss: 1367.8900 - val_rmse: 36.9850\n",
        "Epoch 29: early stopping\n",
        "Restoring model weights from the end of the best epoch: 9.\n",
        "Elapsed time: 0.0:8.0:24.76\n",
        "~~~\n",
        "\n",
        "If we wanted to,  we could zip-up the preprocessed files and store them somewhere for later use if we needed a trained neural neural network to count the number of paperclips on a piece of paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "\n",
        "from keras.models import save_model\n",
        "import os\n",
        "\n",
        "# Save path is the current directory\n",
        "save_path = \".\"\n",
        "\n",
        "# Save the model in the native Keras format\n",
        "model.save('ResNetModel.keras')\n",
        "\n",
        "# Print out the files in current directory\n",
        "files = os.listdir()\n",
        "print(files)"
      ],
      "metadata": {
        "id": "AKWG9GdJzHND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download Trained ResNet model to your home computer**\n",
        "\n",
        "The cell above saved the trained model as `ResNetModel.keras` to your current Colab directory. When you terminate this lesson, your `runtime` will be deleted which means all of your files will be lost. If you wanted to use the trained ResNet model later, you can download it to your laptop (or desktop) by uncommenting the line below that reads:\n",
        "\n",
        "~~~text\n",
        "#files.download('ResNetModel.keras')\n",
        "~~~\n",
        "\n",
        "This will start the download process. The file `ResNetModel.keras` is about 314KB in size, so downloading it to your computer will take several minutes depending upon your Internet speed."
      ],
      "metadata": {
        "id": "m4qJgIAnt8xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#files.download('ResNetModel.keras')"
      ],
      "metadata": {
        "id": "SmRSrG5Nzy45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example 2 - Step 9: Plot `rmse` and `val_rmse`**\n",
        "\n",
        "The code in the cell below plot's the `rmse` and `val_rmse` recorded during each epoch in the training cycle. As you can see, `rmse` and `val_rmse` decrease during training as model adjusts its synaptic weights to improve its regression precision after each epoch."
      ],
      "metadata": {
        "id": "9WfTTMR8wC39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - Step 9: Plot rmse and val_rmse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.plot(history.history['rmse'])\n",
        "plt.plot(history.history['val_rmse'])\n",
        "plt.legend(['RMSE', 'Val RMSE'], frameon=False)\n",
        "plt.xticks(np.arange(0, 50, 5))\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('RMSE')\n",
        "plt.title('RMSE in Every Epoch')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N_wkyphr1Tvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06/class_06_2_image05.png)"
      ],
      "metadata": {
        "id": "XHynxEjW18wa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example - Step 10: Display an Image from the Test Set**\n",
        "\n",
        "The code in the next cell picks a random paperclip image from the training set and prints out with the actual number of paperclips in the image shown in the title.\n"
      ],
      "metadata": {
        "id": "VJsxwYTMwHrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example - Step 10: Display an Image from the Test Set\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get a batch of images and labels from the generator\n",
        "batch = next(train_generator)\n",
        "images, labels = batch\n",
        "\n",
        "# Display the first image in the batch\n",
        "plt.imshow(images[0])\n",
        "plt.title(f\"Actual Number of Paperclips: {labels[0]}\")\n",
        "actual_num_paperclips = labels[0]\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Save the image without the title\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(images[0])\n",
        "ax.axis('off')\n",
        "fig.savefig('saved_image.png', bbox_inches='tight', pad_inches=0)\n",
        "plt.close(fig)\n"
      ],
      "metadata": {
        "id": "oRlRrZXM55ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06/class_06_2_image06.png)"
      ],
      "metadata": {
        "id": "t4NvpOHK1yZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example 2 - Step 11: Count Paperclips with ResNet Model**\n",
        "\n",
        "The code in the next cell submits the image about (without a title) to our modified ResNet model that we trained in **Example 2 - Step 8** using a custom function called `load_and_preprocess_image()`:\n",
        "\n",
        "~~~text\n",
        "# Function to load and preprocess the image\n",
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Rescale if you trained with rescaled images\n",
        "    return img_array\n",
        "~~~\n",
        "\n",
        "Once the image has been processed, it is submitted (without a title) to our modified ResNet model with this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Predict the number of objects\n",
        "prediction = model.predict(img_array)\n",
        "predicted_count = np.round(prediction[0][0])\n",
        "~~~\n",
        "\n",
        "which generates a prediction as to number of paperclips it \"sees\" in the image. The code then prints out the image again, but this time with the number of paperclips the models thinks it sees in the title."
      ],
      "metadata": {
        "id": "spYnMmZIzJtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - Step 11: Count Paperclips with ResNet Model\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Function to load and preprocess the image\n",
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Rescale if you trained with rescaled images\n",
        "    return img_array\n",
        "\n",
        "# Path to your image\n",
        "img_path = 'saved_image.png'\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_array = load_and_preprocess_image(img_path, target_size=(256, 256))\n",
        "\n",
        "# Predict the number of objects\n",
        "prediction = model.predict(img_array)\n",
        "predicted_count = np.round(prediction[0][0])\n",
        "\n",
        "# Display the image and the prediction\n",
        "plt.imshow(image.load_img(img_path))\n",
        "plt.title(f\"Predicted number of paperclips: {predicted_count}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f\"The actual number of paperclips:{actual_num_paperclips}\")\n"
      ],
      "metadata": {
        "id": "Bm-wdG5iwhJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_06/class_06_2_image07.png)"
      ],
      "metadata": {
        "id": "vPGWDMJr17Ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since image selection is randomized, you won't see the same images as shown about. Unless your image has a very low number of paperclips in it, you will see that the number of paperclips predicted by the model is not exactly the same as the actual number. For the image shown above, the actual number of paperclips in the image is `59` which our model predicted the number was `78`. In this paricular instance, the model is off by ~30%.  "
      ],
      "metadata": {
        "id": "lTpqkO3uwgxq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UadJEsfGaomz"
      },
      "source": [
        "## **Lesson Turn-in**\n",
        "\n",
        "When you have completed all of the code cells, and run them in sequential order (the last code cell should be number 32) use the **File --> Print.. --> Save to PDF** to generate a PDF of your JupyterLab notebook. Save your PDF as `Class_06_2.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}