{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/main/ResNet101_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZVwSpdbE3Y"
      },
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExN-OzpYbE3Y"
      },
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4imk1kbE3Y"
      },
      "source": [
        "##### **Module 3: Convolutional Neural Networks (CNN's)**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Biology, Health and the Environment](https://sciences.utsa.edu/bhe/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "### Module 3 Material\n",
        "\n",
        "* Part 3.1: Using Convolutional Neural Networks\n",
        "* **Part 3.2: Using Pre-Trained Neural Networks with Keras**\n",
        "* Part 3.3: Facial Recognition and Analysis\n",
        "* Part 3.4: Introduction to GAN's for Image and Data Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Change your Runtime Now!**\n",
        "\n",
        "For this lesson you must have a GPU hardware accelerator (e.g. `A100`)."
      ],
      "metadata": {
        "id": "Ult76BB_wSzg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_-lPkxLbE3Z"
      },
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. By running this code cell, you will map your GDrive to /content/drive and print out your Google GMAIL address. Your Instructor will use your GMAIL address to verify the author of this class lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "seXFCYH4LDUM",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c828282-3170-4fac-e428-12e3be854710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: Using Google CoLab\n",
            "david.senseman@gmail.com\n"
          ]
        }
      ],
      "source": [
        "# You must run this cell first\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    Colab = True\n",
        "    print(\"Note: Using Google CoLab\")\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"**WARNING**: Your GMAIL address was **not** printed in the output below.\")\n",
        "    print(\"**WARNING**: You will NOT receive credit for this lesson.\")\n",
        "    Colab = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Custom Function\n",
        "\n",
        "The cell below creates a custom function called `hms_string()`. This function is needed to record the time required to train your neural network model.\n",
        "\n",
        "If you fail to run this cell now, you will receive one (or more) error message(s) later in this lesson."
      ],
      "metadata": {
        "id": "Mu5xJAWl_9vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom function\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 0️⃣  Create hms_string()\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "# Simple function to print out elasped time\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "metadata": {
        "id": "STtFj1QKTVcL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download`ResNet101`"
      ],
      "metadata": {
        "id": "-NKUT1cv4rTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ResNet101\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "\n",
        "ResNet101_model_512 = ResNet101(weights='imagenet',include_top=True)"
      ],
      "metadata": {
        "id": "z0LTPBQv4rTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01211637-364d-447f-b74c-4623cd133b74"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m179648224/179648224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Keras package\n",
        "\n",
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "id": "zDfZJ5064-JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd640a82-96f2-4e64-b554-59ce46fcc79c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from keras_preprocessing) (2.0.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from keras_preprocessing) (1.17.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Set ENVIRONMENTAL VARIABLES**\n",
        "\n"
      ],
      "metadata": {
        "id": "EyqunLqtmQLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set ENVIRONMENTAL VARIABLES\n",
        "\n",
        "import os\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 1️⃣  Create variables for downloading loading Zip file\n",
        "# ------------------------------------------------------------------------\n",
        "URL = \"https://biologicslab.co/BIO1173/data/\"\n",
        "DOWNLOAD_SOURCE = URL+\"diabetic_retinopathy_train_512.zip\"\n",
        "DOWNLOAD_NAME = DOWNLOAD_SOURCE[DOWNLOAD_SOURCE.rfind('/')+1:]\n",
        "print(\"DOWNLOAD_SOURCE=\",DOWNLOAD_SOURCE)\n",
        "print(\"DOWNLOAD_NAME=\",DOWNLOAD_NAME)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 2️⃣  Create variables for extracting the Zip file\n",
        "# ------------------------------------------------------------------------\n",
        "PATH = \"./\"\n",
        "EXTRACT_TARGET = os.path.join(PATH,\"retinopathy_512\")\n",
        "SOURCE = os.path.join(EXTRACT_TARGET, \"train_512\")\n",
        "print(\"EXTRACT_TARGET=\",EXTRACT_TARGET)\n",
        "print(\"SOURCE=\",SOURCE)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 3️⃣  Print variables for debugging\n",
        "# ------------------------------------------------------------------------\n",
        "print(\"ENVIRONMENTAL VARIABLES were successfully created.\")"
      ],
      "metadata": {
        "id": "FTJS3d5tmQLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c774447a-0df7-41b9-9c37-7e2d358bbdec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DOWNLOAD_SOURCE= https://biologicslab.co/BIO1173/data/diabetic_retinopathy_train_512.zip\n",
            "DOWNLOAD_NAME= diabetic_retinopathy_train_512.zip\n",
            "EXTRACT_TARGET= ./retinopathy_512\n",
            "SOURCE= ./retinopathy_512/train_512\n",
            "ENVIRONMENTAL VARIABLES were successfully created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image37C.png)"
      ],
      "metadata": {
        "id": "Z7ehx51EmQLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download and Extract Image Data**"
      ],
      "metadata": {
        "id": "owF95gW0mQLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and Extract Image Data\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1️⃣  Create directories\n",
        "# --------------------------------------------------------------\n",
        "print(\"Creating necessary directories...\", end='')\n",
        "# Create necessary directories\n",
        "os.makedirs(SOURCE, exist_ok=True)\n",
        "os.makedirs(EXTRACT_TARGET, exist_ok=True)\n",
        "print(\"done.\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2️⃣  Download Zip file\n",
        "# --------------------------------------------------------------\n",
        "print(f\"Downloading {DOWNLOAD_NAME}...\", end='')\n",
        "# Define paths and URLs\n",
        "download_path = os.path.join(PATH, DOWNLOAD_NAME)\n",
        "extract_path = os.path.join(EXTRACT_TARGET, DOWNLOAD_NAME)\n",
        "# Download the file\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        [\"wget\", \"-O\", DOWNLOAD_NAME, DOWNLOAD_SOURCE],\n",
        "        check=True,\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    print(\"done.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Download failed with error: {e}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3️⃣  Extract Zip file\n",
        "# --------------------------------------------------------------\n",
        "print(f\"Extracting {DOWNLOAD_NAME} to {EXTRACT_TARGET}...\", end='')\n",
        "\n",
        "# Check if zip file exists and has content\n",
        "if not os.path.exists(DOWNLOAD_NAME):\n",
        "    print(f\"Error: Zip file {DOWNLOAD_NAME} does not exist\")\n",
        "    sys.exit(1)\n",
        "\n",
        "if os.path.getsize(DOWNLOAD_NAME) == 0:\n",
        "    print(f\"Error: Zip file {DOWNLOAD_NAME} is empty\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Extract the file with error handling\n",
        "try:\n",
        "    # Use -o flag to overwrite files without prompting\n",
        "    # Use -q for quiet mode\n",
        "    result = subprocess.run(\n",
        "        [\"unzip\", \"-o\", \"-q\", DOWNLOAD_NAME, \"-d\", EXTRACT_TARGET],\n",
        "        check=True,\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    print(\"done.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error: Unzipping failed with return code {e.returncode}\")\n",
        "    print(f\"Error output: {e.stderr}\")\n",
        "    print(f\"Command that failed: {e.cmd}\")\n",
        "    sys.exit(1)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: unzip command not found. Please install unzip.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4️⃣  Verify Extraction was successful\n",
        "# --------------------------------------------------------------\n",
        "print(\"Verifying Extraction...\")\n",
        "try:\n",
        "    # Check if extraction directory exists\n",
        "    if not os.path.exists(EXTRACT_TARGET):\n",
        "        print(f\"Error: Extraction directory {EXTRACT_TARGET} does not exist\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # List contents to verify\n",
        "    contents = os.listdir(EXTRACT_TARGET)\n",
        "    if len(contents) == 0:\n",
        "        print(\"Warning: Extraction directory is empty\")\n",
        "    else:\n",
        "        print(f\"Successfully extracted {len(contents)} items:\")\n",
        "        for item in sorted(contents)[:10]:  # Show first 10 items\n",
        "            item_path = os.path.join(EXTRACT_TARGET, item)\n",
        "            if os.path.isfile(item_path):\n",
        "                size = os.path.getsize(item_path)\n",
        "                print(f\"  - {item} ({size} bytes)\")\n",
        "            else:\n",
        "                print(f\"  - {item} (directory)\")\n",
        "\n",
        "        if len(contents) > 10:\n",
        "            print(f\"  ... and {len(contents) - 10} more items\")\n",
        "\n",
        "    # Try to get more detailed information about what was extracted\n",
        "    result = subprocess.run(\n",
        "        [\"ls\", \"-la\", EXTRACT_TARGET],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        check=False  # Don't raise exception for this command\n",
        "    )\n",
        "    if result.returncode == 0:\n",
        "        print(\"Directory contents:\")\n",
        "        print(result.stdout)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during verification: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(\"Extraction completed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr8eqTjtdCW1",
        "outputId": "c7b91685-d00d-481c-fd30-a08d4bc61917"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating necessary directories...done.\n",
            "Downloading diabetic_retinopathy_train_512.zip...done.\n",
            "Extracting diabetic_retinopathy_train_512.zip to ./retinopathy_512...done.\n",
            "Verifying Extraction...\n",
            "Successfully extracted 2 items:\n",
            "  - trainLabels.csv (465317 bytes)\n",
            "  - train_512 (directory)\n",
            "Directory contents:\n",
            "total 1008\n",
            "drwxr-xr-x 3 root root   4096 Sep 15 11:51 .\n",
            "drwxr-xr-x 1 root root   4096 Sep 15 11:31 ..\n",
            "drwxr-xr-x 2 root root 548864 Sep 15 11:51 train_512\n",
            "-rw-rw---- 1 root root 465317 Sep 12 15:05 trainLabels.csv\n",
            "\n",
            "Extraction completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Labels for the Training Set**"
      ],
      "metadata": {
        "id": "69raKQFgmQLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Labels for the Training Set\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read labels and create dataframe\n",
        "ex_raw_df = pd.read_csv(\n",
        "        os.path.join(EXTRACT_TARGET,\"trainLabels.csv\"),\n",
        "        na_values=['NA', '?'])\n",
        "\n",
        "# Add file extention\n",
        "image_col = 'image'\n",
        "ex_raw_df[image_col] = ex_raw_df[image_col].astype(str) + '.png'\n",
        "\n",
        "# Print sample for verification\n",
        "ex_raw_df\n"
      ],
      "metadata": {
        "id": "fpmGEfHEmQLl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "e7289ebe-7c22-49aa-a307-3e12bc0f389a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 image  level\n",
              "0          10_left.png      0\n",
              "1         10_right.png      0\n",
              "2          13_left.png      0\n",
              "3         13_right.png      0\n",
              "4          15_left.png      1\n",
              "...                ...    ...\n",
              "35121  44347_right.png      0\n",
              "35122   44348_left.png      0\n",
              "35123  44348_right.png      0\n",
              "35124   44349_left.png      0\n",
              "35125  44349_right.png      1\n",
              "\n",
              "[35126 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99a02f49-f5bc-44a4-be8a-4d6ac76db098\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10_left.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10_right.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13_left.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13_right.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15_left.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35121</th>\n",
              "      <td>44347_right.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35122</th>\n",
              "      <td>44348_left.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35123</th>\n",
              "      <td>44348_right.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35124</th>\n",
              "      <td>44349_left.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35125</th>\n",
              "      <td>44349_right.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35126 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99a02f49-f5bc-44a4-be8a-4d6ac76db098')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99a02f49-f5bc-44a4-be8a-4d6ac76db098 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99a02f49-f5bc-44a4-be8a-4d6ac76db098');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bd0b103b-40ce-46ce-ba5b-a052b3618197\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd0b103b-40ce-46ce-ba5b-a052b3618197')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bd0b103b-40ce-46ce-ba5b-a052b3618197 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9ba14260-e81d-4b39-ba13-dc31d064ee42\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ex_raw_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9ba14260-e81d-4b39-ba13-dc31d064ee42 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ex_raw_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ex_raw_df",
              "summary": "{\n  \"name\": \"ex_raw_df\",\n  \"rows\": 35126,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35126,\n        \"samples\": [\n          \"23997_right.png\",\n          \"12793_right.png\",\n          \"18073_right.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert this code after loading your DataFrame but before splitting\n",
        "from pathlib import Path\n",
        "\n",
        "# Validate that all image files actually exist\n",
        "def validate_image_files(df, source_path):\n",
        "    source = Path(source_path)\n",
        "    existing_files = set()\n",
        "\n",
        "    # Get all actual files in the directory\n",
        "    for file_path in source.rglob('*'):\n",
        "        if file_path.is_file() and file_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
        "            existing_files.add(file_path.name)\n",
        "\n",
        "    # Check which files in DataFrame actually exist\n",
        "    df['file_exists'] = df['image'].apply(lambda x: x in existing_files)\n",
        "\n",
        "    print(f\"Total images in DataFrame: {len(df)}\")\n",
        "    print(f\"Images that exist: {df['file_exists'].sum()}\")\n",
        "    print(f\"Missing images: {(~df['file_exists']).sum()}\")\n",
        "\n",
        "    # Filter to only include existing files\n",
        "    valid_df = df[df['file_exists']].copy()\n",
        "    print(f\"Valid DataFrame size: {len(valid_df)}\")\n",
        "\n",
        "    return valid_df\n",
        "\n",
        "# Use it:\n",
        "ex_raw_df = validate_image_files(ex_raw_df, SOURCE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh4niFe0KQki",
        "outputId": "a55e5f16-fe30-42ac-d56c-a68d74227e41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in DataFrame: 35126\n",
            "Images that exist: 17448\n",
            "Missing images: 17678\n",
            "Valid DataFrame size: 17448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Split Images into Training and Validation Sets**"
      ],
      "metadata": {
        "id": "Z9FsUIsDmQLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Images into Training and Validation Sets\n",
        "\n",
        "\n",
        "# Set split fraction\n",
        "FRAC=0.8  # 80% training / 20% validation\n",
        "\n",
        "# Convert the class column to string – required for `flow_from_dataframe`\n",
        "ex_raw_df['level'] = ex_raw_df['level'].astype(str)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "#  1️⃣ Randomly split data into training and validation sets\n",
        "# ------------------------------------------------------------------\n",
        "ex_train_df = ex_raw_df.sample(frac=FRAC, random_state=42)\n",
        "ex_val_df   = ex_raw_df.drop(ex_train_df.index)\n",
        "\n",
        "# Calculate the split fraction as sanity check\n",
        "split_fraction = len(ex_train_df) / (len(ex_val_df) + len(ex_train_df))\n",
        "\n",
        "# Print out numbers\n",
        "print(f\"Training set size   : {len(ex_train_df)}\")\n",
        "print(f\"Validation set size : {len(ex_val_df)}\")\n",
        "print(f\"Calculated split fraction =\", split_fraction)\n",
        "\n",
        "# Quick sanity check\n",
        "print(\"\\nSample training rows:\")\n",
        "print(ex_train_df[['image', 'level']].head())\n",
        "\n",
        "print(\"\\nSample validation rows:\")\n",
        "print(ex_val_df[['image', 'level']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63vrz9p2L3X2",
        "outputId": "f2c9ba27-953e-4ee1-af6a-77145d981f82"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size   : 13958\n",
            "Validation set size : 3490\n",
            "Calculated split fraction = 0.7999770747363595\n",
            "\n",
            "Sample training rows:\n",
            "                 image level\n",
            "16508   20710_left.png     0\n",
            "8057   10109_right.png     2\n",
            "23120   29217_left.png     0\n",
            "24         31_left.png     0\n",
            "12902   16217_left.png     0\n",
            "\n",
            "Sample validation rows:\n",
            "           image level\n",
            "1   10_right.png     0\n",
            "7   16_right.png     4\n",
            "10   19_left.png     0\n",
            "13  20_right.png     0\n",
            "15  21_right.png     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this code before creating your generators to debug the issue\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Check which files are actually valid\n",
        "def check_valid_images(df, source_path):\n",
        "    valid_files = []\n",
        "    invalid_files = []\n",
        "\n",
        "    for filename in df['image']:\n",
        "        file_path = Path(source_path) / filename\n",
        "        if file_path.exists() and file_path.is_file():\n",
        "            valid_files.append(filename)\n",
        "        else:\n",
        "            invalid_files.append(filename)\n",
        "\n",
        "    print(f\"Total files: {len(df)}\")\n",
        "    print(f\"Valid files: {len(valid_files)}\")\n",
        "    print(f\"Invalid files: {len(invalid_files)}\")\n",
        "\n",
        "    # Remove invalid files from your dataframe\n",
        "    df_clean = df[df['image'].isin(valid_files)]\n",
        "    print(f\"After cleaning: {len(df_clean)} samples\")\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# Apply cleaning to both train and validation sets\n",
        "ex_train_df = check_valid_images(ex_train_df, SOURCE)\n",
        "ex_val_df = check_valid_images(ex_val_df, SOURCE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUl7jQf9IM_i",
        "outputId": "7f0f0a4e-0448-4560-af02-e87a0540e258"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files: 13958\n",
            "Valid files: 13958\n",
            "Invalid files: 0\n",
            "After cleaning: 13958 samples\n",
            "Total files: 3490\n",
            "Valid files: 3490\n",
            "Invalid files: 0\n",
            "After cleaning: 3490 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create Image Generator**"
      ],
      "metadata": {
        "id": "nWCh6S_kmQLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Image Generator\n",
        "\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# Specify Image Size\n",
        "IMG_W, IMG_H = 512, 512\n",
        "\n",
        "BATCH_TRAIN  = 64\n",
        "BATCH_VAL    = 64\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 1️⃣ Training generator – augmentations\n",
        "# --------------------------------------------------------------------\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,  # for *ResNet* pre‑proc\n",
        "    width_shift_range=0.2,       # Horizontal shift\n",
        "    height_shift_range=0.2,      # Vertical shift\n",
        "    horizontal_flip=True,        # Flip images horizontally\n",
        "    zoom_range=0.2,              # Zoom in/out\n",
        "    fill_mode='nearest',         # Fill in new pixels\n",
        "    rotation_range=20,           # Add some rotation\n",
        ")\n",
        "\n",
        "# Optimize data loading with prefetching and caching\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    dataframe=ex_train_df,  # Labels for training images\n",
        "    directory=str(SOURCE),\n",
        "    x_col='image',          # column that holds the file name\n",
        "    y_col='level',          # column that holds the class string\n",
        "    target_size=(IMG_H, IMG_W),\n",
        "    batch_size=BATCH_TRAIN,\n",
        "    class_mode='categorical',   # one‑hot (shape (batch, 5))\n",
        "    shuffle=True,\n",
        "    seed=42,                  # For reproducibility\n",
        ")\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 2️⃣ Validation generator -- no augmentation\n",
        "# --------------------------------------------------------------------\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "val_gen = val_datagen.flow_from_dataframe(\n",
        "    dataframe=ex_val_df,   # Labels for the validation images\n",
        "    directory=str(SOURCE),\n",
        "    x_col='image',\n",
        "    y_col='level',\n",
        "    target_size=(IMG_H, IMG_W),\n",
        "    batch_size=BATCH_VAL,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Sanity Check\n",
        "ex_x_train, ex_y_train = next(train_gen)\n",
        "ex_x_val,   ex_y_val   = next(val_gen)\n",
        "\n",
        "print(\"TRAIN batch  : \", ex_x_train.shape, ex_y_train.shape)   # should be (32, 512, 512, 3) , (32, 5)\n",
        "print(\"VAL   batch  : \", ex_x_val.shape,   ex_y_val.shape)     # same, but 32 samples if 7025>batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XILWlBpMafg",
        "outputId": "ef5dd63c-d3c7-48da-fdda-45958a403fd1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13958 validated image filenames belonging to 5 classes.\n",
            "Found 3490 validated image filenames belonging to 5 classes.\n",
            "TRAIN batch  :  (64, 512, 512, 3) (64, 5)\n",
            "VAL   batch  :  (64, 512, 512, 3) (64, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check Class Distribution**\n"
      ],
      "metadata": {
        "id": "Ry1JMAnfmQLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Class Distribution\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count class distribution\n",
        "ex_labels_val = val_gen.classes\n",
        "class_counts = np.bincount(ex_labels_val)\n",
        "\n",
        "# Plot distribution\n",
        "plt.bar(range(len(class_counts)), class_counts)\n",
        "plt.xlabel(\"Class Index\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.title(\"Validation Set Class Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3xWfbRnmmQLm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "bac0b612-d41d-47f8-f56c-2a12db36472c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup `ResNet101` Base Network**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4hsAaWRfmQLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup `ResNet101` Base Network\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base = ResNet101(weights='imagenet', include_top=False, input_shape=(IMG_H, IMG_W, 3))\n",
        "base.trainable = False          # freeze layers\n",
        "\n",
        "x = base.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predictions = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "ResNet101_model_512 = models.Model(inputs=base.input, outputs=predictions)\n",
        "\n",
        "# Use mixed precision optimizer\n",
        "optimizer = optimizers.Adam(learning_rate=1e-4)  # Adjusted for mixed precision\n",
        "\n",
        "ResNet101_model_512.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "ziXxejVCM-JX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "482e81cc-03ef-4a6e-ca89-b665ccc6241c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m171446536/171446536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image44C.png)"
      ],
      "metadata": {
        "id": "vMSFZmOW5k-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train Neural Network**"
      ],
      "metadata": {
        "id": "Wi1Fbo8NmQLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Neural Network\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set number of epochs\n",
        "EPOCHS=20\n",
        "\n",
        "# Set Patience\n",
        "PATIENCE=5\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 1️⃣  Start training\n",
        "# ------------------------------------------------------------------------\n",
        "print(f\"-- Training (classification) is starting for {EPOCHS} epochs----------------------------\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Add more optimization parameters\n",
        "history_512 = ResNet101_model_512.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=len(train_gen),\n",
        "    validation_steps=len(val_gen),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-7)\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Record end time\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Print elapsed time\n",
        "print(f\"Elapsed time: {hms_string(elapsed_time)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP4V3MdHNOEO",
        "outputId": "dc766b0f-7777-4804-a7ca-cf1ced6cf0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Training (classification) is starting for 20 epochs----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m  7/219\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:53\u001b[0m 3s/step - accuracy: 0.2053 - loss: 2.3636"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plot Training History**"
      ],
      "metadata": {
        "id": "1pSv_2shmQLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Training History\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pull the metrics\n",
        "ex_val_acc = history_512.history.get('val_accuracy')\n",
        "ex_train_acc = history_512.history.get('accuracy')\n",
        "\n",
        "# --- Find the epoch with the highest validation accuracy -------------\n",
        "# np.argmax returns the index (0‑based). Add 1 if you want to show it as \"epoch 1, 2, …\"\n",
        "best_epoch_idx = np.argmax(ex_val_acc)       # 0‑based index\n",
        "best_epoch_num = best_epoch_idx + 1          # 1‑based for display\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(ex_val_acc, label='val_accuracy')\n",
        "plt.plot(ex_train_acc, label='accuracy')\n",
        "\n",
        "# Vertical line at the best epoch (0‑based index)\n",
        "plt.axvline(best_epoch_idx, color='r', linestyle='--',\n",
        "            label=f'Best epoch (epoch {best_epoch_num})')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training / Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Optional: annotate the exact accuracy value at the best epoch\n",
        "best_ex_val_acc = ex_val_acc[best_epoch_idx]\n",
        "plt.text(best_epoch_idx, best_ex_val_acc,\n",
        "         f'{best_ex_val_acc:.4f}',\n",
        "         va='bottom', ha='right', color='r', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aFm1IkVlwue1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save Model to GDrive**"
      ],
      "metadata": {
        "id": "G9yqR3rQmQLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model to GDrive\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1️⃣  Mount Google Drive (do this only once per session)\n",
        "# --------------------------------------------------------------\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2️⃣  Define the names / paths\n",
        "# --------------------------------------------------------------\n",
        "model_name     = \"ResNet101_model_512\"                    # model object name\n",
        "gdrive_dir     = f\"/content/drive/My Drive/{model_name}\"  # folder on Drive\n",
        "gdrive_file    = f\"{gdrive_dir}.keras\"                    # the file we want to keep\n",
        "\n",
        "local_dir      = f\"/content/{model_name}\"                 # the *local* folder you want to delete\n",
        "local_file     = f\"{local_dir}.keras\"                     # if you saved a single file locally\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3️⃣  Make sure the Drive folder exists\n",
        "# --------------------------------------------------------------\n",
        "os.makedirs(gdrive_dir, exist_ok=True)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4️⃣  Save the model *on* Drive (kept forever)\n",
        "# --------------------------------------------------------------\n",
        "ResNet101_model_512.save(gdrive_file)   # <-- this writes the file into /content/drive/My Drive/\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5️⃣  OPTIONAL: Verify the Drive copy exists\n",
        "# --------------------------------------------------------------\n",
        "print(\"Drive copy present:\", os.path.exists(gdrive_file))\n",
        "!ls ./drive/MyDrive"
      ],
      "metadata": {
        "id": "dLu0bTR4TByG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Diabetic Retinopathy Dataset**\n",
        "\n",
        "The **Diabetic Retinopathy Dataset** used in this lesson was part of a 2015 Kaggle Competition.\n",
        "\n",
        "Here is a summary of the winners and what they did to win this competition.\n",
        "\n",
        "### Winner of the 2015 Kaggle Diabetic Retinopathy Detection competition\n",
        "**Team**: *o_O* (Mathis Antony & Stephan Brüggemann)  \n",
        "**Score**: 0.845 weighted quadratic‑weighted Kappa (private leaderboard)  \n",
        "**Public leaderboard**: 7th place (5.8 k K‑appa)\n",
        "\n",
        "| Item | Details | Source |\n",
        "|------|---------|--------|\n",
        "| **Winning team** | “o_O” (Mathis Antony & Stephan Brüggemann) | 5.8 k K‑appa on the private leaderboard, 7 th place on the public leaderboard【9†L18-L23】 |\n",
        "| **Overall performance** | 0.845 weighted quadratic weighted Kappa (private leaderboard) | 5.8 k K‑appa, 0.845 score【9†L19-L22】 |\n",
        "| **Core architecture** | Two custom 2‑D convolutional nets (Net A & Net B) with a **per‑patient blending network** (Table 2) | 13‑25 | 12‑15 |\n",
        "| **Training framework** | Lasagne + nolearn (Theano) | 10‑11 |\n",
        "| **Image size** | 128 × 128, 256 × 256 and 512 × 512 (large color images, cropped to remove background) | 21‑24 |\n",
        "| **Pre‑training strategy** | *First* train a small network on 128‑pixel images.  Weights are then used to initialise an intermediate‑size network (trained on 256 px) and finally a 512‑pixel network.  Orthogonal initialization for all weights. | 105‑108 |\n",
        "| **Data augmentation** | Translation, stretching, rotation, flipping, colour jitter; per‑channel zero‑mean/unit‑variance scaling; 112/224/448 output sizes for 128/256/512 input images. | 115‑121 |\n",
        "| **Class imbalance handling** | Dynamic resampling: oversample rare classes initially, then gradually reduce; resampling weights \\((1.36, 14.4, 6.64, 40.2, 49.6)\\) → \\((1,2,2,2,2)\\). | 82‑96 |\n",
        "| **Training schedule** | Nesterov momentum with a fixed learning‑rate schedule over 250 epochs; learning rates 0.003 (epoch 0) → 0.00003 (epoch 150); L2 weight decay 0.0005; dropout after convolution and dense layers. | 31‑36, 70‑73 |\n",
        "| **Loss & objective** | Mean‑squared‑error regression (output thresholded at (0.5,1.5,2.5,3.5) to obtain integer grades). | 75‑77 |\n",
        "| **Blending network** | Input: mean & std of the RMSPool layer over 50 augmentations for each eye (µ,σ) + eye‑side indicator; 8193‑input → Dense 32 → Maxout 16 → Dense 32 → Maxout 16; Adam optimiser with a schedule (5 e‑4 → 5 e‑7). | 148‑156, 158‑166 |\n",
        "| **Final ensemble** | Average of the two conv‑net predictions, blended with the patient‑level network; score 0.845 (private) vs 0.824 (no per‑patient blend). | 167‑169 |\n",
        "| **Key design choices that yielded the win** | 1. **Large input resolution** – 512 × 512 (and even 768 × 768 for 0.81 Kappa) to capture micro‑aneurysms. 2. **Stage‑wise pre‑training** – starting from 128 px to 512 px to stabilise training. 3. **Extensive data augmentation & per‑channel normalisation**. 4. **Dynamic resampling** to address class imbalance without a weighted loss. 5. **Per‑patient blending** that aggregates information from both eyes and multiple augmentations. 6. **Ensembling of two independently trained nets**. | 45‑69, 82‑96, 100‑108, 115‑121, 131‑139, 167‑169 |\n",
        "\n",
        "### **Why their approach won**\n",
        "\n",
        "The combination of **large‑resolution images**, staged pre‑training, aggressive augmentation, careful imbalance handling, and per‑patient feature blending allowed the o_O model to achieve the highest weighted quadratic‑weighted κ score in the 2015 competition.\n",
        "\n"
      ],
      "metadata": {
        "id": "HFG4NZGwRfSk"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}