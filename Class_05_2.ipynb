{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEEW13uCtiJ"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/master/Class_05_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BIO 1173: Intro Computational Biology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module 5: Regularization and Dropout**\n",
    "\n",
    "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
    "\n",
    "### Module 5 Material\n",
    "\n",
    "* Part 5.1: Part 5.1: Introduction to Regularization: Ridge and Lasso\n",
    "* **Part 5.2: Using K-Fold Cross Validation with Keras**\n",
    "* Part 5.3: Using L1 and L2 Regularization with Keras to Decrease Overfitting\n",
    "* Part 5.4: Drop Out for Keras to Decrease Overfitting\n",
    "* Part 5.5: Benchmarking Keras Deep Learning Regularization Techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Setup\n",
    "\n",
    "Run the next code cell to load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current working directory is : C:\\Users\\David\\BIO1173_Test\\Class_05_2\n",
      "Disk usage(total=4000108531712, used=1006327681024, free=2993780850688)\n"
     ]
    }
   ],
   "source": [
    "# You MUST run this code cell first\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "path = '/'\n",
    "memory = shutil.disk_usage(path)\n",
    "dirpath = os.getcwd()\n",
    "print(\"Your current working directory is : \" + dirpath)\n",
    "print(\"Disk\", memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seXFCYH4LDUM",
    "outputId": "c05015aa-871e-4779-9265-5ad07e8bf617",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "# You must run this cell second\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "    import requests\n",
    "    gcloud_token = !gcloud auth print-access-token\n",
    "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "    print(gcloud_tokeninfo['email'])\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for this lesson\n",
    "\n",
    "For this lesson we will be using the [Body Performance dataset](https://www.kaggle.com/datasets/kukuroo3/body-performance-data) for the Examples, and the [Multiple Disease dataset](https://www.kaggle.com/datasets/ehababoelnaga/multiple-disease-prediction) for the **Exercises**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body Performance dataset\n",
    "\n",
    "[Body Performance](https://www.kaggle.com/datasets/kukuroo3/body-performance-data)\n",
    "\n",
    "\n",
    "![___](https://biologicslab.co/BIO1173/images/Broadjump.jpg)\n",
    "\n",
    "The [Body Performance dataset](https://www.kaggle.com/datasets/kukuroo3/body-performance-data) was provided by the [Seoul Olympic Games Korea Sports Promotion Foundation](https://www.bigdata-culture.kr/bigdata/user/data_market/detail.do?id=ace0aea7-5eee-48b9-b616-637365d665c1). \n",
    "\n",
    "The dataset has 12 categories of body performance for a relatively large number of men and women (_n_=13,303). To speed-up neural network training, we will generally use only a fraction of the total number subjects. \n",
    "\n",
    "The 12 categories of fitness measurements are:\n",
    "* **age:** 20 ~64\n",
    "* **gender:** M,F\n",
    "* **height_cm:** (If you want to convert to feet, divide by 30.48)\n",
    "* **weight_kg:**\n",
    "* **body fat_%:**\n",
    "* **diastolic:** diastolic blood pressure (min)\n",
    "* **systolic:** systolic blood pressure (min)\n",
    "* **gripForce:**\n",
    "* **sit and bend forward_cm:**\n",
    "* **sit-ups counts:**\n",
    "* **broad jump_cm:**\n",
    "* **class:** A,B,C,D ( A: best) / stratified\n",
    "\n",
    "The output for the command `df.info()` is as follows:\n",
    "~~~text\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 13393 entries, 0 to 13392\n",
    "Data columns (total 12 columns):\n",
    " #   Column                   Non-Null Count  Dtype  \n",
    "---  ------                   --------------  -----  \n",
    " 0   age                      13393 non-null  float64\n",
    " 1   gender                   13393 non-null  object \n",
    " 2   height_cm                13393 non-null  float64\n",
    " 3   weight_kg                13393 non-null  float64\n",
    " 4   body fat_%               13393 non-null  float64\n",
    " 5   diastolic                13393 non-null  float64\n",
    " 6   systolic                 13393 non-null  float64\n",
    " 7   gripForce                13393 non-null  float64\n",
    " 8   sit and bend forward_cm  13393 non-null  float64\n",
    " 9   sit-ups counts           13393 non-null  float64\n",
    " 10  broad jump_cm            13393 non-null  float64\n",
    " 11  class                    13393 non-null  object \n",
    "dtypes: float64(10), object(2)\n",
    "~~~\n",
    "\n",
    "As you can see, the only columns that have string values (type `object`) are `age` and `class`. The remaining columns are all numeric. Since all columns have the same `Non-Null Count` there is no missing data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Disease Prediction Dataset\n",
    "\n",
    "[Multiple Disease Prediction](https://www.kaggle.com/datasets/ehababoelnaga/multiple-disease-prediction?resource=download/)\n",
    "\n",
    "\n",
    "![___](https://biologicslab.co/BIO1173/images/blood_sample.jpg)\n",
    "\n",
    "A blood sample can provide valuable information about disease prediction through various methods such as genetic testing, biomarker analysis, and assessing various blood parameters. Here's why it's important:\n",
    "\n",
    "* **Early Detection:** Blood samples can contain markers that indicate the presence of certain diseases even before symptoms appear. Detecting these markers early can lead to earlier treatment and better outcomes.\n",
    "* **Risk Assessment:** Analyzing blood samples can help assess an individual's risk of developing certain diseases based on genetic predispositions or biomarker patterns. This information can guide preventative measures and lifestyle changes to reduce the risk.\n",
    "* **Personalized Medicine:** Understanding an individual's genetic makeup and biomarker profile can help tailor medical treatments to their specific needs, increasing treatment efficacy and reducing adverse effects.\n",
    "* **Monitoring Disease Progression:** Blood tests can be used to monitor disease progression and response to treatment over time, allowing for adjustments in treatment plans as needed.\n",
    "* **Population Health Management:** Blood sample analysis on a larger scale can provide insights into the prevalence of certain diseases within a population, aiding public health efforts in disease prevention and management.\n",
    "\n",
    "Overall, leveraging blood samples for disease prediction can significantly impact individual health outcomes, public health strategies, and the advancement of personalized medicine.\n",
    "\n",
    "**Description of Multiple Disease Prediction Dataset**\n",
    "\n",
    "This dataset is for the prediction of human diseases based on blood sample values and a panel of clinical assesments taken from 1552 subjects. The last column, `Disease`, list five disease categories: \n",
    "\n",
    "* **Anemia:** Anemia is the condition of not having enough healthy red blood cells or hemoglobin to carry oxygen to the body's tissues. \n",
    "* **Diabetes:** Diabetes is a chronic (long-lasting) condition that affects how your body turns food into energy. With diabetes, your body doesn’t make enough insulin or can’t use it as well as it should. When there isn’t enough insulin or cells stop responding to insulin, too much blood sugar stays in your bloodstream.\n",
    "* **Healthy:** No apparent medical condistion.\n",
    "* **Thalasse:** Thalassemia is an inherited blood disorder that inhibits the production of the protein hemoglobin.  \n",
    "* **Thromboc:** Thrombocytopenia is the medical condition for low blood platelets. Normal platelet counts for adults are between 150,000 and 450,000 platelets per microliter (uL) of blood. Thrombocytopenia is a platelet count below 150,000.\n",
    "\n",
    "**Key Features of the dataset:**\n",
    "\n",
    "The following are the attributes of the Blood Sample dataset:\n",
    "\n",
    "* **Cholesterol:** This is the level of cholesterol in the blood, measured in milligrams per deciliter (mg/dL).\n",
    "* **Hemoglobin:** This is the protein in red blood cells that carries oxygen from the lungs to the rest of the body\n",
    "* **Platelets:** Platelets are blood cells that help with clotting\n",
    "* **White Blood Cells (WBC):** These are cells of the immune system that help fight infections\n",
    "* **Red Blood Cells (RBC):** These are the cells that carry oxygen from the lungs to the rest of the body\n",
    "* **Hematocrit:** This is the percentage of blood volume that is occupied by red blood cells\n",
    "* **Mean Corpuscular Volume (MCV):** This is the average volume of red blood cells\n",
    "* **Mean Corpuscular Hemoglobin (MCH):** This is the average amount of hemoglobin in a red blood cell\n",
    "* **Mean Corpuscular Hemoglobin Concentration (MCHC):** This is the average concentration of hemoglobin in a red blood cell\n",
    "* **Insulin:** This is a hormone that helps regulate blood sugar levels\n",
    "* **BMI (Body Mass Index):** This is a measure of body fat based on height and weight\n",
    "* **Systolic Blood Pressure (SBP):** This is the pressure in the arteries when the heart beats\n",
    "* **Diastolic Blood Pressure (DBP):** This is the pressure in the arteries when the heart is at rest between beats\n",
    "* **Triglycerides:** These are a type of fat found in the blood, measured in milligrams per deciliter (mg/dL)\n",
    "* **HbA1c (Glycated Hemoglobin):** This is a measure of average blood sugar levels over the past two to three months\n",
    "* **LDL (Low-Density Lipoprotein) Cholesterol:** This is the \"bad\" cholesterol that can build up in the arteries\n",
    "* **HDL (High-Density Lipoprotein) Cholesterol:** This is the \"good\" cholesterol that helps remove LDL cholesterol from the arteries\n",
    "* **ALT (Alanine Aminotransferase):** This is an enzyme found primarily in the liver\n",
    "* **AST (Aspartate Aminotransferase):** This is an enzyme found in various tissues including the liver and heart\n",
    "* **Heart Rate:** This is the number of heartbeats per minute (bpm)\n",
    "* **Creatinine:** This is a waste product produced by muscles and filtered out of the blood by the kidneys\n",
    "* **Troponin:** This is a protein released into the bloodstream when there is damage to the heart muscle\n",
    "* **C-reactive Protein (CRP):** This is a marker of inflammation in the body\n",
    "* **Disease:** This indicates whether he has a specific disease or not\n",
    "\n",
    "The data has been standardized using a scaling techique called **_Min-Max Scaling_**. In this procedure, the values have been shifted and rescaled so that they end up ranging between 0 and 1. The following shows the minimum and maximum values used for scaling each category:\n",
    "\n",
    "* **Glucose:** (70, 140),  # mg/dL\n",
    "* **Cholesterol:** (125, 200),  # mg/dL\n",
    "* **Hemoglobin:** (13.5, 17.5),  # g/dL\n",
    "* **Platelets:** (150000, 450000),  # per microliter of blood\n",
    "* **White Blood Cells:** (4000, 11000),  # per cubic millimeter of blood\n",
    "* **Red Blood Cells:** (4.2, 5.4),  # million cells per microliter of blood\n",
    "* **Hematocrit:** (38, 52),  # percentage\n",
    "* **Mean Corpuscular Volume:** (80, 100),  # femtoliters\n",
    "* **Mean Corpuscular Hemoglobin:** (27, 33),  # picograms\n",
    "* **Mean Corpuscular Hemoglobin Concentration:** (32, 36),  # grams per deciliter\n",
    "* **Insulin:** (5, 25),  # microU/mL\n",
    "* **BMI:** (18.5, 24.9),  # kg/m^2\n",
    "* **Systolic Blood Pressure:** (90, 120),  # mmHg\n",
    "* **Diastolic Blood Pressure:** (60, 80),  # mmHg\n",
    "* **Triglycerides:** (50, 150),  # mg/dL\n",
    "* **HbA1c:** (4, 6),  # percentage\n",
    "* **LDL Cholesterol:** (70, 130),  # mg/dL\n",
    "* **HDL Cholesterol:** (40, 60),  # mg/dL\n",
    "* **ALT:** (10, 40),  # U/L\n",
    "* **AST:** (10, 40),  # U/L\n",
    "* **Heart Rate:** (60, 100),  # beats per minute\n",
    "* **Creatinine:** (0.6, 1.2),  # mg/dL\n",
    "* **Troponin:** (0, 0.04),  # ng/mL\n",
    "* **C-reactive Protein:** (0, 3),  # mg/L\n",
    "\n",
    "#### Understanding Min-Max Scaling\n",
    "As an example, consider the column called `Glucose`. According to the information above, the subject with the lowest Glucose measurement had `70 mg/dl` while the subject with the largest Glucose measurement had `140 mg/dl`. After Min-Max scaling, the subject with the minimum measurement now has Glucose=0, while the subject with the maximum measurement now has Glucose=1. All of the remaining subjects have a glucose value somewhere between 0 and 1 in proportion to the original glucose measurement.\n",
    "\n",
    "The output for the command `df.info()` is as follows:\n",
    "~~~text\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 2351 entries, 0 to 2350\n",
    "Data columns (total 25 columns):\n",
    " #   Column                                     Non-Null Count  Dtype  \n",
    "---  ------                                     --------------  -----  \n",
    " 0   Glucose                                    2351 non-null   float64\n",
    " 1   Cholesterol                                2351 non-null   float64\n",
    " 2   Hemoglobin                                 2351 non-null   float64\n",
    " 3   Platelets                                  2351 non-null   float64\n",
    " 4   White Blood Cells                          2351 non-null   float64\n",
    " 5   Red Blood Cells                            2351 non-null   float64\n",
    " 6   Hematocrit                                 2351 non-null   float64\n",
    " 7   Mean Corpuscular Volume                    2351 non-null   float64\n",
    " 8   Mean Corpuscular Hemoglobin                2351 non-null   float64\n",
    " 9   Mean Corpuscular Hemoglobin Concentration  2351 non-null   float64\n",
    " 10  Insulin                                    2351 non-null   float64\n",
    " 11  BMI                                        2351 non-null   float64\n",
    " 12  Systolic Blood Pressure                    2351 non-null   float64\n",
    " 13  Diastolic Blood Pressure                   2351 non-null   float64\n",
    " 14  Triglycerides                              2351 non-null   float64\n",
    " 15  HbA1c                                      2351 non-null   float64\n",
    " 16  LDL Cholesterol                            2351 non-null   float64\n",
    " 17  HDL Cholesterol                            2351 non-null   float64\n",
    " 18  ALT                                        2351 non-null   float64\n",
    " 19  AST                                        2351 non-null   float64\n",
    " 20  Heart Rate                                 2351 non-null   float64\n",
    " 21  Creatinine                                 2351 non-null   float64\n",
    " 22  Troponin                                   2351 non-null   float64\n",
    " 23  C-reactive Protein                         2351 non-null   float64\n",
    " 24  Disease                                    2351 non-null   object \n",
    "dtypes: float64(24), object(1)\n",
    "memory usage: 459.3+ KB\n",
    "~~~\n",
    "\n",
    "As you can see, the only column that is _not_ numeric is `Disease` which has 5 categorical values: `Anemia`, `Diabetes`, `Healthy`, `Thalasse`, and `Thromboc`. Since all columns have the same `Non-Null Count` (_n_=2351), there is no missing data. \n",
    "\n",
    "As mentioned above, the data is **_already scaled_** in the range 0.0-1.0 using the minimum and maximum values for each data type.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.2: Using K-Fold Cross-validation with Keras\n",
    "\n",
    "**_K-fold validation_** is a technique used in machine learning to evaluate the performance and generalization ability of a model. In _K_-fold validation, the original dataset is randomly partitioned into _K_ equal-sized subsets. The model is trained and evaluated _K_ times, with each iteration using a different subset as the validation set and the remaining subsets as the training set. This allows for a more robust evaluation of the model's performance as it reduces the variance that may result from using a single train-test split. The final performance metric is typically averaged over the _K_ iterations for a more reliable estimation of the model's performance.\n",
    "\n",
    "You can use cross-validation for a variety of purposes in predictive modeling:\n",
    "\n",
    "* Generating out-of-sample predictions from a neural network\n",
    "* Estimate a good number of epochs to train a neural network for (early stopping)\n",
    "* Evaluate the effectiveness of certain hyperparameters, such as activation functions, neuron counts, and layer counts\n",
    "\n",
    "Cross-validation uses several folds and multiple models to provide each data segment a chance to serve as both the validation and training set. Figure 5.CROSS shows cross-validation.\n",
    "\n",
    "**Figure 5.CROSS: K-Fold Crossvalidation**\n",
    "![K-Fold Crossvalidation](https://biologicslab.co/BIO1173/images/class_1_kfold.png \"K-Fold Crossvalidation\")\n",
    "\n",
    "It is important to note that each fold will have one model (neural network). To generate predictions for new data (not present in the training set), predictions from the fold models can be handled in several ways:\n",
    "\n",
    "* Choose the model with the highest validation score as the final model.\n",
    "* Preset new data to the five models (one for each fold) and average the result (this is an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning)).\n",
    "* Retrain a new model (using the same settings as the cross-validation) on the entire dataset. Train for as many epochs and with the same hidden layer structure.\n",
    "\n",
    "Generally, I prefer the last approach and will retrain a model on the entire data set once I have selected hyper-parameters. Of course, I will always set aside a final holdout set for model validation that I do not use in any aspect of the training process.\n",
    "\n",
    "## Regression vs Classification _K_-Fold Cross-Validation\n",
    "\n",
    "Regression and classification are handled somewhat differently concerning cross-validation. Regression is the simpler case where you can break up the data set into _K_ folds with little regard for where each item lands. For regression, the data items should fall into the folds as _randomly_ as possible. It is also important to remember that not every fold will necessarily have the same number of data items. It is not always possible for the data set to be evenly divided into _K_ folds. For regression cross-validation, we will use the Scikit-Learn class **KFold**.\n",
    "\n",
    "Cross-validation for classification could also use the **KFold** object; however, this technique would not ensure that the class balance remains the same in each fold as in the original. The balance of classes that a model was trained on must remain the same (or similar) to the training set. Drift in this distribution is one of the most important things to monitor after a trained model has been placed into actual use. Because of this, we want to make sure that the cross-validation itself does not introduce an unintended shift. This technique is called **_stratified sampling_** and is accomplished by using the Scikit-Learn object **StratifiedKFold** in place of **KFold** whenever you use classification. In summary, you should use the following two objects in Scikit-Learn:\n",
    "\n",
    "* **KFold** When dealing with a regression problem.\n",
    "* **StratifiedKFold** When dealing with a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functions for this lesson\n",
    "\n",
    "The code in the cell below creates 2 useful functions for this lesson, `elaspedTime(start,stop)` and `rename_col_by_index(dataframe, index_mapping)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions\n",
    "\n",
    "# Simple function to print out elasped time\n",
    "def elaspedTime(start,end):\n",
    "    # Print out time\n",
    "    seconds = int((end-start))\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    print(\"Elapsed time = %d:%02d:%02d\" % (hour, minutes, seconds))\n",
    "    print()\n",
    "\n",
    "# Simple function to change column name in a dataframe\n",
    "def rename_col_by_index(dataframe, index_mapping):\n",
    "    dataframe.columns = [index_mapping.get(i, col) for i, col in enumerate(dataframe.columns)]\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Sample Regression Predictions with K-Fold Cross-Validation\n",
    "\n",
    "The following code trains the simple dataset using a 5-fold cross-validation. The expected performance of a neural network of the type trained here would be the score for the generated out-of-sample predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-Step 1: Prepare feature vector\n",
    "\n",
    "In the cell below, we prepare a feature vector using the **Body Performance** dataset to predict an individual's weight in kg. This model is set up as a regression problem.\n",
    "\n",
    "The datafile `bodyPerformance.csv` is read from the course HTTPS server to create a DataFrame called `bpBigDF`. To speed training of the neural network, we will only use 15% of the data in `bpBigDF` using the code chunk:\n",
    "~~~text\n",
    "# Only use 15% for neural network\n",
    "bpDF=bpBigDF.sample(frac=0.15)\n",
    "~~~\n",
    "The actual DataFrame used for Example 1 will be `bpDF`. \n",
    "\n",
    "As mentioned above, there are two non-numeric columns, `gender` and `class`. The code below uses `mapping` to convert the letters `M` to the integer `1` and `F` to the integer `0` in the `gender` column. Mapping is also used to convert the letters in the column `class` to integers using this code chunck:\n",
    "~~~text\n",
    "# Map gender\n",
    "mapping = {'M': 1, 'F': 0}\n",
    "bpDF['gender'] = bpDF['gender'].map(mapping)\n",
    "\n",
    "# Map class\n",
    "mapping =  {'A': 0,\n",
    "            'B': 1,\n",
    "            'C': 2,\n",
    "            'D': 3}\n",
    "bpDF['class'] = bpDF['class'].map(mapping)\n",
    "~~~\n",
    "\n",
    "Since the goal of this regression neural network is to predict weight, the column `weight_kg` is dropped when creating a list of column names to be used for the x-values:\n",
    "~~~text\n",
    "# Generate list of columns for x\n",
    "bpX_columns = bpDF.columns.drop('weight_kg')  # weight_kg is y\n",
    "~~~\n",
    "In this example, we will use the `Min-Max` scaler for standardizing values.\n",
    "~~~text\n",
    "# Standardize values with Min-Max\n",
    "for col in bpX_columns:\n",
    "    bpDF[col] = minmax_scale(bpDF[col])\n",
    "~~~\n",
    "Having processed all of the x-values, we can now generate the X feature vector using this code chunk:\n",
    "~~~text\n",
    "# Generate X feature vector\n",
    "bpX = bpDF[bpX_columns].values\n",
    "bpX = np.asarray(bpX).astype('float32')\n",
    "~~~\n",
    "Finally, since this is a regression analysis we **don't** want to One-Hot encode the values in the column `weight_kg` but use them directly:\n",
    "~~~text\n",
    "# Generate Y feature vector\n",
    "bpY = bpDF['weight_kg'].values\n",
    "bpY = np.asarray(bpY).astype('float32')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4651 1.     0.6595 0.4308 0.4937 0.4632 0.713  0.7085 0.4231 0.7559\n",
      "  0.6667]\n",
      " [0.2093 1.     0.642  0.3371 0.4684 0.5158 0.8102 0.6384 0.3846 0.7659\n",
      "  1.    ]\n",
      " [0.6744 0.     0.286  0.7121 0.4304 0.3158 0.2362 0.5314 0.1538 0.3579\n",
      "  1.    ]\n",
      " [0.2558 1.     0.716  0.3884 0.5443 0.5368 0.7339 0.8137 0.4615 0.6455\n",
      "  0.6667]]\n"
     ]
    }
   ],
   "source": [
    "# Example 1-Step 1: Prepare feature vector\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "# Read the data set\n",
    "bpBigDF = pd.read_csv(\n",
    "    \"https://biologicslab.co/BIO1173/data/bodyPerformance.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Only use 15% for neural network\n",
    "bpDF=bpBigDF.sample(frac=0.15)\n",
    "\n",
    "# Map category `gender`\n",
    "mapping = {'M': 1, 'F': 0}\n",
    "bpDF['gender'] = bpDF['gender'].map(mapping)\n",
    "\n",
    "# Map category `class`\n",
    "mapping =  {'A': 0,\n",
    "            'B': 1,\n",
    "            'C': 2,\n",
    "            'D': 3}\n",
    "bpDF['class'] = bpDF['class'].map(mapping)\n",
    "\n",
    "# Generate list of columns for x\n",
    "bpX_columns = bpDF.columns.drop('weight_kg')  # weight_kg is y\n",
    "\n",
    "# Standardize values with Min-Max\n",
    "for col in bpX_columns:\n",
    "    bpDF[col] = minmax_scale(bpDF[col])\n",
    "\n",
    "# Generate X feature vector\n",
    "bpX = bpDF[bpX_columns].values\n",
    "bpX = np.asarray(bpX).astype('float32')\n",
    "\n",
    "# Generate Y feature vector\n",
    "bpY = bpDF['weight_kg'].values\n",
    "bpY = np.asarray(bpY).astype('float32')\n",
    "\n",
    "# Print first 4 values in bpX\n",
    "np.set_printoptions(suppress=True,precision=4)\n",
    "print(bpX[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:\n",
    "~~~text\n",
    "[[0.4651 1.     0.8912 0.2554 0.7373 0.469  0.7895 0.7083 0.5733 0.7972\n",
    "  0.3333]\n",
    " [0.0233 0.     0.4791 0.4892 0.5254 0.1947 0.2684 0.5924 0.36   0.5455\n",
    "  0.6667]\n",
    " [0.0233 0.     0.2824 0.5758 0.5847 0.4602 0.3316 0.8116 0.48   0.6049\n",
    "  0.3333]\n",
    " [0.0698 1.     0.6339 0.1775 0.5339 0.531  0.7474 0.2699 0.5867 0.8357\n",
    "  1.    ]]\n",
    "~~~~\n",
    "\n",
    "These are the Min-Max scaled scores of the 11 fitness measurements for the first 4 individuals in `bpX`. \n",
    "\n",
    "If you re-run this cell, you will get slightly different values due to the fact that we are using only a **_random sample_** of the entire dataset. Each time the cell is run, a different random sample is selected. \n",
    "\n",
    "See if you can figure out the gender of all of these individuals in the output shown above by their Min-Max scores? (HINT: The first record is from a man, the second from a woman)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-Step 2: Out-of-Sample Regression Predictions with K-Fold Cross-Validation\n",
    "\n",
    "Now that we have created our X and Y feature vectors, we are ready to perform 5-fold cross-validation to generate out-of-sample (oos) predictions. For this example, we will use 100 epochs and no early stopping. Later we will see how we can estimate a more optimal epoch count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1 starting...\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Fold score (RMSE): 4.976469993591309\n",
      "Fold #2 starting...\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Fold score (RMSE): 5.076278209686279\n",
      "Fold #3 starting...\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Fold score (RMSE): 5.131648540496826\n",
      "Fold #4 starting...\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Fold score (RMSE): 5.244519233703613\n",
      "Fold #5 starting...\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Fold score (RMSE): 5.0899658203125\n",
      "Final, out of sample score (RMSE): 5.104522705078125 \n",
      "\n",
      "Elapsed time = 0:02:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 1-Step 2: Out-of-Sample Regression Predictions with K-Fold Cross-Validation\n",
    "\n",
    "# Set variables\n",
    "EPOCHS=100 # number of epochs for each loop\n",
    "numK=5     # Set number of K-folds\n",
    "\n",
    "# Record the start time in T_start\n",
    "T_start = time.time()\n",
    "\n",
    "# Specify type of K-fold Cross-Validation\n",
    "kf = KFold(numK, shuffle=True, random_state=42) \n",
    "\n",
    "# Initial arrays for Out Of Samples (oos)\n",
    "oos_y = []    # array to hold actual y-values\n",
    "oos_pred = [] # array to hold predicted y-values\n",
    "\n",
    "# START LOOP HERE -----------------------------------------------#\n",
    "\n",
    "fold = 0 # initialize fold count\n",
    "\n",
    "# Run loop for each fold\n",
    "for train, test in kf.split(bpX):\n",
    "    fold+=1  # increment loop counter\n",
    "    print(f\"Fold #{fold} starting...\")\n",
    "\n",
    "    # Generate this fold's train and test datasets\n",
    "    x_train = bpX[train]\n",
    "    y_train = bpY[train]\n",
    "    x_test = bpX[test]\n",
    "    y_test = bpY[test]\n",
    "\n",
    "    # Build new model for this fold\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=bpX.shape[1], \n",
    "                    activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile model for this fold (regression) \n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer='adam')\n",
    "\n",
    "    # Run model for this fold\n",
    "    model.fit(x_train,y_train,\n",
    "              validation_data=(x_test,y_test),verbose=0,\n",
    "              epochs=EPOCHS)\n",
    "\n",
    "    # Store model predictions\n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "    # oos_y contains fold's actual Y-values\n",
    "    oos_y.append(y_test)\n",
    "    \n",
    "    # oos_pred contains fold's predicted Y-values\n",
    "    oos_pred.append(pred)    \n",
    "\n",
    "    # Measure and print RMSE for this fold\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(f\"Fold score (RMSE): {score}\")\n",
    "\n",
    "# END LOOP HERE -----------------------------------------------#\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "\n",
    "# Actual y-values for all loops\n",
    "oos_y = np.concatenate(oos_y)\n",
    "\n",
    "# Predicted y-values from all loops\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "\n",
    "# Compute Final (Grand) total from all K loops\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(f\"Final, out of sample score (RMSE): {score} \\n\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [oos_y,oos_pred],axis=1 )\n",
    "\n",
    "# Uncomment the next line to write file\n",
    "#oosDF.to_csv(filename_write,index=False)\n",
    "\n",
    "# Record the end time in T_end\n",
    "T_end = time.time()\n",
    "\n",
    "# Print out elapsed time\n",
    "elaspedTime(T_start,T_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fairly large neural network so it make take some time to finish all 5 K-fold traing loops. Please be patient.\n",
    "\n",
    "If your code is correct you should see something similar to the following output:\n",
    "~~~text\n",
    "Fold #1 starting...\n",
    "13/13 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 5.109001159667969\n",
    "Fold #2 starting...\n",
    "13/13 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 5.294778347015381\n",
    "Fold #3 starting...\n",
    "13/13 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 4.638960838317871\n",
    "Fold #4 starting...\n",
    "13/13 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 4.801635265350342\n",
    "Fold #5 starting...\n",
    "13/13 [==============================] - 0s 2ms/step\n",
    "Fold score (RMSE): 4.9324259757995605\n",
    "Final, out of sample score (RMSE): 4.9606804847717285 \n",
    "\n",
    "Elapsed time = 0:01:49\n",
    "~~~\n",
    "\n",
    "As you can see, the data was processed by 5 different neural network models, one model for each _K_ fold. Due to the random nature of the training process, each model performed somewhat differently. \n",
    "\n",
    "In this particular example, third model (Fold #3) had the lowest RMSE (`4.63896`) and therefore was the most accurate. On the other hand, the second model (Fold #2) had the highest RSME score (`5.294778`) and therefore was the least accurate. The `Final` out of sample score, was `4.9324`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-Step 3: Print out Actual and Predicted Y-values\n",
    "\n",
    "So what does a RMSE value like `4.961` mean for this model trained on this dataset? Our goal in Example 1 was to predict the **weight** of individuals given measurements of 11 fitness characteristics. This is a basic _regression_ problem for a neural network. \n",
    "\n",
    "The code in the cell below prints out the actual weights and predicted weights (in kilograms) for all of the \"out-of-sample\" individuals. Out-of-sample refers to data that was _not_ used in the process of developing the neural network model. \n",
    "\n",
    "Using oos data, the accuracy and performance of the model can be evaluated on new, unseen data to assess its generalizability and potential for predicting future outcomes. This helps ensure that the neural network model was not overfitting or performing well only on the data it was trained on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Wt (kg)</th>\n",
       "      <th>Predicted Wt (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.500000</td>\n",
       "      <td>88.168480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.099998</td>\n",
       "      <td>55.621708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>74.698868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.800003</td>\n",
       "      <td>80.698418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>65.199997</td>\n",
       "      <td>70.975533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>60.599998</td>\n",
       "      <td>65.756805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>81.400002</td>\n",
       "      <td>79.140892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>64.900002</td>\n",
       "      <td>65.492760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2009 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Wt (kg)  Predicted Wt (kg)\n",
       "0          88.500000          88.168480\n",
       "1          47.099998          55.621708\n",
       "2          75.000000          74.698868\n",
       "3          80.800003          80.698418\n",
       "...              ...                ...\n",
       "2005       65.199997          70.975533\n",
       "2006       60.599998          65.756805\n",
       "2007       81.400002          79.140892\n",
       "2008       64.900002          65.492760\n",
       "\n",
       "[2009 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1-Step 3: Print out actual and predicted y-values \n",
    "\n",
    "# Rename columns\n",
    "new_column_mapping = {0: 'Actual Wt (kg)', 1: 'Predicted Wt (kg)'}\n",
    "oosDF = rename_col_by_index(oosDF, new_column_mapping)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# Display DataFrame\n",
    "display(oosDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_05_2_Exm1C.png)\n",
    "\n",
    "By inspection you can see that the model's weight predictions are close to, but not exactly the same as, the out-of-sample (oos) individuals. For example, the actual weight of the last individual (2008) was 77.00 kg while the model predicted his weight as 68.98 kg. For this particular individual the difference (i.e. error) is about 8 kg. We should not be too surprised by this amount of since the were know that the Final RMSE value was `5.054`.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "## Standardize Data Twice?\n",
    "\n",
    "Standardizing data twice, first to a range of 0 to 1 and then taking their Z-scores, is not a recommended practice. This is because standardizing data to a specific range (0 to 1) and then calculating Z-scores introduces redundant and unnecessary transformations that can distort the interpretation of the data.\n",
    "\n",
    "When data is standardized to a range of 0 to 1, the original distribution and variability of the data are altered to fit within a specific interval. Subsequently, calculating Z-scores on this already transformed data can lead to incorrect normalization and scaling of the variables.\n",
    "\n",
    "It is more appropriate to choose one standardization method based on the requirements of the analysis. Standardizing the data either to a specific range or to Z-scores alone is typically sufficient for most analytical purposes and helps maintain the integrity of the data without introducing unnecessary complexity or distorting the distribution of the variables.\n",
    "\n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1A: Prepare feature vector**\n",
    "\n",
    "In the cell below prepare a feature vector for the Multiple Disease Prediction dataset for Out-of-Sample _Regression_ with K-Fold Cross-Validation. When preparing your feature vector, keep in mind that your regression neural network will be used to predict `Glucose` levels in the blood. \n",
    "\n",
    "Use the following code chunk to read the data from the course HTTPS server:\n",
    "~~~text\n",
    "# Read the data set\n",
    "mdpBigDF = pd.read_csv(\n",
    "    \"https://biologicslab.co/BIO1173/data/Blood_samples.csv\",\n",
    "    na_values=['NA','?'])\n",
    "~~~\n",
    "Use 60% of `mdpBigDF` to create a the actual DataFrame that you will use. Call this DataFrame`mdpDF`. \n",
    "~~~text\n",
    "# Only use 60% for neural network\n",
    "mdpDF=mdpBigDF.sample(frac=0.60)\n",
    "~~~\n",
    "The only non-numeric column in the Multiple Disease Prediction dataset is `Disease`. You will need to map the five categorical values in this column to integers using the following code chunk:\n",
    "~~~text\n",
    "# Map Diseases\n",
    "mapping =  {'Anemia': 0,\n",
    "            'Diabetes': 1,\n",
    "            'Healthy': 2,\n",
    "            'Thalasse': 3,\n",
    "            'Thromboc': 4}\n",
    "mdpDF['Disease'] = mdpDF['Disease'].map(mapping)\n",
    "~~~\n",
    "\n",
    "Then create a list of columns to be used for generating the x-values by dropping the column `Glucose`--which is the y-value. Call your list `mdpX_columns`. Do **not** standardize the x-values to their Z-scores. The data in the Multiple Disease Prediction dataset has already been standardized to the range 0.0 to 1.0. As described above, applying a second standarization is not considered good practice.\n",
    "\n",
    "Use your list `mdpX_columns` to generate the X feature vector called `mpdX` using the following code chunk: \n",
    "~~~text\n",
    "# Generate X feature vector\n",
    "mdpX = mdpDF[mdpX_columns].values\n",
    "mdpX = np.asarray(mdpX).astype('float32')\n",
    "~~~\n",
    "You will also need to generate the Y feature vector directly from the column `Glucose` using the following code chunk:\n",
    "~~~text\n",
    "# Generate Y feature vector\n",
    "mdpY = mdpDF['Glucose'].values\n",
    "mdpY = np.asarray(mdpY).astype('float32')\n",
    "~~~\n",
    "Finally, print out the x-values for only the first 4 individuals in `mdpX`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1A here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:\n",
    "~~~text\n",
    "[[0.7188 0.2893 0.8843 0.4285 0.3649 0.8499 0.9119 0.044  0.9623 0.6245\n",
    "  0.2501 0.2845 0.1755 0.0946 0.8535 0.1943 0.3111 0.3411 0.8494 0.2628\n",
    "  0.2146 0.9056 0.4891 1.    ]\n",
    " [0.2842 0.3127 0.9912 0.872  0.4886 0.4946 0.8336 0.1907 0.6656 0.252\n",
    "  0.6283 0.4225 0.0297 0.0888 0.7088 0.2313 0.2963 0.7866 0.4691 0.5526\n",
    "  0.1389 0.0176 0.5855 3.    ]\n",
    " [0.4421 0.3317 0.1711 0.9908 0.9924 0.9137 0.88   0.0255 0.9315 0.3856\n",
    "  0.7794 0.3035 0.2239 0.1417 0.3134 0.5512 0.9223 0.4851 0.4863 0.5196\n",
    "  0.0763 0.0732 0.0842 3.    ]\n",
    " [0.2482 0.2956 0.0559 0.0445 0.4161 0.5485 0.3389 0.9069 0.7223 0.2431\n",
    "  0.3694 0.6434 0.0431 0.2762 0.3675 0.4501 0.9894 0.0877 0.318  0.7435\n",
    "  0.2066 0.5948 0.294  0.    ]]\n",
    "~~~\n",
    "\n",
    "Notice that there are no negative values. If you have any negative values in your output, it probably means that you converted your data to Zscores. As explained above, this is not a good idea since the data in the Multiple Disease Prediction dataset has already been standardized to the range 0,1 using `Min-Max` scaling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1B: Out-of-Sample Regression Predictions with K-Fold Cross-Validation**\n",
    "\n",
    "Use the feature vector you just created in **Exercise 1B** to perform a 5-fold cross-validation of out-of-sample predictions of glucose blood levels. Follow the template shown above in Example 1B. Set the number of epochs to 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1B here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similiar to the following output:\n",
    "~~~text\n",
    "Fold #1 starting...\n",
    "9/9 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 0.0006521505420096219\n",
    "Fold #2 starting...\n",
    "9/9 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 3.028195578735904e-07\n",
    "Fold #3 starting...\n",
    "9/9 [==============================] - 0s 2ms/step\n",
    "Fold score (RMSE): 0.00023288458760362118\n",
    "Fold #4 starting...\n",
    "9/9 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 0.0007166583673097193\n",
    "Fold #5 starting...\n",
    "9/9 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 7.3592500484664924e-06\n",
    "Final, out of sample score (RMSE): 0.000445868237875402 \n",
    "\n",
    "Elapsed time = 0:01:23\n",
    "~~~\n",
    "The `Final, out of sample score (RMSE): 0.000445868237875402` in this particular run, appears to be quite small. When it comes to RMSE values, the smaller the better. But let's see how error level looks like in the context of predicting blood glucose levels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1C: Print out actual and predicted y-values**\n",
    "\n",
    "In the cell below, rename the column header of the DataFrame `oosDF` to read `Actual Glucose` and `Predicted Glucose` using the function `rename_col_by_index()`. Once the columns have been renamed, display the DataFrame `oosDF` to see a list of the actual and predicted glucose levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1C here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_05_2_Exe1C.png)\n",
    "\n",
    "By inspection of the output above, you can see the model's predictions of glucose blood levels are very close--or even exactly the same--as the the actual values of the out-of-sample individuals. The Final RMSE value =`0.000445868237875402` indicates the your model is very accurate for predicting glucose blood levels!   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Stratified K-Fold Cross-Validation\n",
    "\n",
    "**_Classification with Stratified K-Fold Cross-Validation_** is a method used to evaluate the performance of a classification model. It involves splitting the dataset into a specified number of folds (_K_) while ensuring that each fold maintains the same proportion of classes as the original dataset (_stratification_).\n",
    "\n",
    "The process works as follows:\n",
    "\n",
    "* The dataset is divided into _K_ equal-sized folds.\n",
    "* For each fold, the model is trained on _K_-1 folds and validated on the remaining fold.\n",
    "* This process is repeated _K_ times, with each fold used as the validation set exactly once.\n",
    "* The performance metrics (such as accuracy, precision, recall) are averaged across all _K_ iterations to provide a robust estimate of the model's performance.\n",
    "\n",
    "Stratified K-Fold Cross-Validation is particularly useful for imbalanced datasets where one class may dominate the others. By ensuring that each fold maintains the class proportions, this technique provides a **_more reliable estimate_** of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2A: Prepare feature vector\n",
    "\n",
    "The following code prepares a feature vector from the Body Performance dataset for classification with stratified _K_-fold cross-validation.  **Stratified** _K_-fold cross-validation is the perferred form with classification data.  This technique ensures that the percentages of each class remain the same across all folds. \n",
    "\n",
    "In Example 2, we want our neural network model to predict the fitness level (`class`) of an individual based on his/her 11 fitness measurements (x-values). \n",
    "\n",
    "As in Example 1A: we need to map categorical values in columns `gender` and `class` to integers. The code is pretty much the same except we will need to drop the column `class`, since this is the y-value. Be careful to never include the y-value in the column list for the x-values.\n",
    "\n",
    "Since this is a **_classification_** model, we need to generate the y-values differently. In particular, we need to One-Hot encode the column `class` as shown in the following code chunk:\n",
    "~~~text\n",
    "# Generate y-values as numpy array\n",
    "dummies = pd.get_dummies(bpDF['class']) # Classification\n",
    "FitClass = dummies.columns\n",
    "bpY= dummies.values\n",
    "bpY = np.asarray(bpY).astype('float32')\n",
    "~~~\n",
    "To double check that the y-values are in the correct shape, the y-values for the first 10 individual in `bpY` are printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Example 2A: Prepare feature vector\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "bpBig = pd.read_csv(\n",
    "    \"https://biologicslab.co/BIO1173/data/bodyPerformance.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Only use 10% for neural network\n",
    "bpDF=bpBig.sample(frac=0.10)\n",
    "\n",
    "# Map gender\n",
    "mapping = {'M': 1, 'F': 0}\n",
    "bpDF['gender'] = bpDF['gender'].map(mapping)\n",
    "\n",
    "# Map class\n",
    "mapping =  {'A': 0,\n",
    "            'B': 1,\n",
    "            'C': 2,\n",
    "            'D': 3}\n",
    "bpDF['class'] = bpDF['class'].map(mapping)\n",
    "\n",
    "# Generate list of columns for x\n",
    "bpX_columns = bpDF.columns.drop('class')\n",
    "\n",
    "# Standardize values with their Z-scores\n",
    "for col in bpX_columns:\n",
    "    bpDF[col] = zscore(bpDF[col])\n",
    "\n",
    "# Generate x-values as numpy array\n",
    "bpX = bpDF[bpX_columns].values\n",
    "bpX = np.asarray(bpX).astype('float32')\n",
    "\n",
    "# Generate y-values as numpy array\n",
    "dummies = pd.get_dummies(bpDF['class']) # Classification\n",
    "FitClass = dummies.columns\n",
    "bpY= dummies.values\n",
    "bpY = np.asarray(bpY).astype('float32')\n",
    "\n",
    "# Print out bpY\n",
    "print(bpY[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:\n",
    "~~~text\n",
    "[[0. 1. 0. 0.]\n",
    " [1. 0. 0. 0.]\n",
    " [1. 0. 0. 0.]\n",
    " [1. 0. 0. 0.]\n",
    " [0. 0. 1. 0.]\n",
    " [0. 0. 1. 0.]\n",
    " [0. 0. 1. 0.]\n",
    " [0. 0. 0. 1.]\n",
    " [0. 0. 1. 0.]\n",
    " [0. 0. 1. 0.]]\n",
    "~~~\n",
    "As you can see, the y-values are One-Hot encoded. Since there are 4 possible fitness classifications, `A`, `B`, `C` and `D`, there are 4 dummy columns. In this particular example, the actual fitness level of the first subject was `B` since he has a `1` in the second column. The next three individuals were in the top fitness category, `A`, since they have a `1` in the first column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2B: Classification with Stratified K-Fold Cross-Validation\n",
    "\n",
    "Once again, the code in the cell below is fairly similar to the code used in Example 1B. The most important difference is the selection of the **stratfied** variable `kf` as shown in this code chunk:\n",
    "~~~text\n",
    "# Cross-validate\n",
    "# Use for StratifiedKFold classification\n",
    "kf = StratifiedKFold(numK, shuffle=True, random_state=42) \n",
    "~~~\n",
    "As mentioned above, **_stratified_ K-fold_ Cross-Validation** should always be used with classification neural networks. Where the different variable `kf` comes into play is at the beginning of the `for` loop:\n",
    "~~~text\n",
    "for train, test in kf.split(bpX,bpDF['class']): \n",
    "~~~\n",
    "Stratification affects sample splitting by ensuring that the proportion of different classes or categories in the dataset is maintained across the training and validation sets. This was **not** done previously in Example 1B where `kf = KFold()`. In the code below, `kf = StratifiedKFold()` instead.\n",
    "\n",
    "As mentioned above, when splitting the data into subsets for training and testing, stratification helps prevent bias and ensures that each subset is representative of the overall dataset in terms of class distribution. By using stratified sampling, the resulting training and validation sets will have a similar distribution of classes as the original dataset. This is especially important in scenarios where the classes are imbalanced, as stratification helps ensure that all classes are adequately represented in both subsets. This approach can lead to more reliable and accurate model evaluation, particularly in classification tasks where the goal is to predict class labels.\n",
    "\n",
    "The neural network model below has an additional feature that was created with this code chunk:\n",
    "~~~text\n",
    "    # Define the checkpoint callback to save the model with the best performance\n",
    "    checkpoint = ModelCheckpoint(f'Model_2_bestFold_{fold}.h5', \n",
    "                    monitor='val_loss', save_best_only=True, \n",
    "                    save_weights_only=True, mode='min', verbose=0)\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1 starting...\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Fold score (accuracy): 0.6455223880597015\n",
      "Fold #2 starting...\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "Fold score (accuracy): 0.6268656716417911\n",
      "Fold #3 starting...\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Fold score (accuracy): 0.6865671641791045\n",
      "Fold #4 starting...\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Fold score (accuracy): 0.6380597014925373\n",
      "Fold #5 starting...\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Fold score (accuracy): 0.6704119850187266\n",
      "Final score (accuracy): 0.6534727408513816 \n",
      "\n",
      "Elapsed time = 0:01:31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 2B: Classification with Stratified K-Fold Cross-Validation\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Set variables\n",
    "EPOCHS=100 # number of epochs for each loop\n",
    "numK=5     # Set number of folds\n",
    "filename_write=\"StratKfoldOosPred.csv\" # Set filename\n",
    "\n",
    "# Record the start time in T_start\n",
    "T_start = time.time()\n",
    "\n",
    "# Cross-validate\n",
    "# Use for StratifiedKFold classification\n",
    "kf = StratifiedKFold(numK, shuffle=True, random_state=42) \n",
    "\n",
    "# Initial arrays to hold Out Of Samples (oos)\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "# START LOOP HERE -----------------------------------#\n",
    "\n",
    "# Must specify y StratifiedKFold for\n",
    "for train, test in kf.split(bpX,bpDF['class']):  \n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold} starting...\")\n",
    "        \n",
    "    # Generate fold's train and test datasets\n",
    "    x_train = bpX[train]\n",
    "    y_train = bpY[train]\n",
    "    x_test = bpX[test]\n",
    "    y_test = bpY[test]\n",
    "    \n",
    "    # Build new model for this fold\n",
    "    model = Sequential()\n",
    "    # Hidden 1\n",
    "    model.add(Dense(50, input_dim=bpX.shape[1], activation='relu')) \n",
    "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(bpY.shape[1],activation='softmax')) # Output\n",
    "\n",
    "    # Compile model for classification\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    # Define the checkpoint callback to save the model with the best performance\n",
    "    checkpoint = ModelCheckpoint(f'Model_2_bestFold_{fold}.h5', \n",
    "                    monitor='val_loss', save_best_only=True, \n",
    "                    save_weights_only=True, mode='min', verbose=0)\n",
    "\n",
    "    # Run model for this fold\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "              verbose=0, callbacks=[checkpoint], epochs=EPOCHS)\n",
    "\n",
    "    # Use model to predict y-values from x_test\n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "    # Save actual y-values \n",
    "    oos_y.append(y_test)\n",
    "    # raw probabilities to chosen class (highest probability)\n",
    "    pred = np.argmax(pred,axis=1) \n",
    "    oos_pred.append(pred)  \n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "# END LOOP HERE -----------------------------------#\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score} \\n\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [oos_pred,oos_y],axis=1 )\n",
    "\n",
    "# Record the end time in T_end\n",
    "T_end = time.time()\n",
    "\n",
    "# Print out elapsed time\n",
    "elaspedTime(T_start,T_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similiar to the following output:\n",
    "~~~text\n",
    "Fold #1 starting...\n",
    "9/9 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 0.6865671641791045\n",
    "Fold #2 starting...\n",
    "9/9 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.6753731343283582\n",
    "Fold #3 starting...\n",
    "9/9 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.7014925373134329\n",
    "Fold #4 starting...\n",
    "9/9 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 0.6305970149253731\n",
    "Fold #5 starting...\n",
    "9/9 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.704119850187266\n",
    "Final score (accuracy): 0.6796116504854369 \n",
    "\n",
    "Elapsed time = 0:01:30\n",
    "~~~\n",
    "Since this is classification our error measure is `accuracy`. For this particular example, the Final accuracy score is `0.68`. Let's see what this means in the context of predicting an individual's fitness level.\n",
    "\n",
    "You should also see that there are now 5 new files in your local directory called `Model_2_bestFold_1.h5` to `Model_2_bestFold_5.h5`. These files are the 5 **_saved models_** that has the best accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2C: Print out actual and predicted y-values\n",
    "\n",
    "So what does a accuracy value of `0.68` mean? Our goal in Example 2 was to predict the fitness level of individuals given measurements of 11 fitness characteristics. This is a basic classification problem for a neural network using tabular data (i.e Pandas DataFrame).\n",
    "\n",
    "The code in the cell below prints out the actual and predicted fitness levels for all of the \"out-of-sample\" individuals. The code uses the function `rename_col_by_index()` to create the appropiate column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual class</th>\n",
       "      <th>Predictions: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual class  Predictions: 0    1    2    3\n",
       "0                1             1.0  0.0  0.0  0.0\n",
       "1                3             0.0  0.0  0.0  1.0\n",
       "2                2             0.0  1.0  0.0  0.0\n",
       "3                3             0.0  0.0  0.0  1.0\n",
       "...            ...             ...  ...  ...  ...\n",
       "1335             2             0.0  0.0  1.0  0.0\n",
       "1336             0             1.0  0.0  0.0  0.0\n",
       "1337             0             0.0  1.0  0.0  0.0\n",
       "1338             2             0.0  0.0  1.0  0.0\n",
       "\n",
       "[1339 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 2C: Print out actual and predicted y-values\n",
    "\n",
    "# Rename columns\n",
    "new_column_mapping = {0: 'Actual class', 1: 'Predictions: 0'}\n",
    "oosDF = rename_col_by_index(oosDF, new_column_mapping)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# Display DataFrame\n",
    "display(oosDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_05_2_Exm2C.png)\n",
    "\n",
    "By inspection you can see that the model's predictions of fitness level are pretty good but not perfect. For example, the model correctly predicted the fitness level for the first two subjects in the example shown above (level 0) but incorrectly predicted the third individual (index 2) has having a fitness level of `2` (B) when in fact, the individual's actual fitness level was `3` (C). The Final accuracy value =`0.68` indicates that the model is pretty good, but not perfect.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2A: Prepare feature vector**\n",
    "\n",
    "In the cell below, write the code to prepare a feature vector for the for the Multiple Disease Prediction dataset for classification with stratified _K_-fold cross-validation. \n",
    "\n",
    "Start by reading the dataset for the course HTTPS server:\n",
    "~~~text\n",
    "# Read the data set\n",
    "mdpBigDF = pd.read_csv(\n",
    "    \"https://biologicslab.co/BIO1173/data/Blood_samples.csv\",\n",
    "    na_values=['NA','?'])\n",
    "~~~\n",
    "\n",
    "Use 60% of the data in `mdpBigDF` for your DataFrame, `mdpDF`:\n",
    "~~~text\n",
    "# Only use 60% for neural network\n",
    "mdpDF=mdpBigDF.sample(frac=0.60)\n",
    "~~~~\n",
    "Use the same mapping of the `Diesease` column as you did in **Exercise 1A**. Remember, do **not** convert your data to Zscores since the data is already standardized.\n",
    "\n",
    "Since this is model will be doing classification, you will need to handle the y-values differently. Use the following code chunk for generating your y-values:\n",
    "~~~text\n",
    "# Generate y-values as numpy array\n",
    "dummies = pd.get_dummies(mdpDF['Disease']) # Classification\n",
    "DiseaseClass = dummies.columns\n",
    "mdpY= dummies.values\n",
    "mdpY = np.asarray(mdpY).astype('float32')\n",
    "~~~\n",
    "Finally, print out the actual disease `classes` (i.e. `mdpY`) for the first 10 subjects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2A here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similiar to the following output:\n",
    "~~~text\n",
    "[[1. 0. 0. 0. 0.]\n",
    " [0. 0. 1. 0. 0.]\n",
    " [0. 0. 1. 0. 0.]\n",
    " [1. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0.]\n",
    " [0. 0. 1. 0. 0.]\n",
    " [0. 1. 0. 0. 0.]\n",
    " [0. 0. 1. 0. 0.]\n",
    " [0. 0. 0. 1. 0.]\n",
    " [0. 0. 0. 0. 1.]]\n",
    "~~~\n",
    "\n",
    "Since there are 5 disease categories:\n",
    "\n",
    "* Anemia   =  0\n",
    "* Diabetes =  1\n",
    "* Healthy  =  2\n",
    "* Thalasse =  3\n",
    "* Thromboc =  4\n",
    "\n",
    "there should be 5 dummy columns.\n",
    "\n",
    "In the specific example shown above, the first individual has `Anemia` since there is a `1` in the first column or the first row, while the second individual is healthy since there is a `1` in the third column of the second row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2B: Classification with Stratified K-Fold Cross-Validation**\n",
    "\n",
    "In the cell below, use the feature vector you created in **Exercise 2A** to predict disease categories in the Multiple Disease Prediction dataset using stratified _K_-fold cross-validation setting _K_=5. Train your model for 100 epochs. \n",
    "\n",
    "Follow the template in Example 2B for building your neural network.\n",
    "\n",
    "Make sure to create a `checkpoint` using the following code chunk:\n",
    "~~~text\n",
    "    # Define the checkpoint callback to save the model with the best performance\n",
    "    checkpoint = ModelCheckpoint(f'Model_2B_bestFold_{fold}.h5', \n",
    "                    monitor='val_loss', save_best_only=True, \n",
    "                    save_weights_only=True, mode='min', verbose=0)\n",
    "~~~\n",
    "and include this `checkpoint` when you run your model:\n",
    "~~~text\n",
    "    # Run model for this fold\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "              verbose=0, callbacks=[checkpoint], epochs=EPOCHS)\n",
    "~~~\n",
    "\n",
    "You should notice that your model will generate five new files in your current directory with the names `Model_2B_bestFold_1.h5` to `Model_2B_bestFold_5.h5`. These are the saved models with the connection weights that generated the lowest `val_loss`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2B here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:\n",
    "~~~text\n",
    "Fold #1 starting...\n",
    "9/9 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 1.0\n",
    "Fold #2 starting...\n",
    "9/9 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 1.0\n",
    "Fold #3 starting...\n",
    "9/9 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 1.0\n",
    "Fold #4 starting...\n",
    "9/9 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 1.0\n",
    "Fold #5 starting...\n",
    "9/9 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 1.0\n",
    "Final score (accuracy): 1.0 \n",
    "\n",
    "Elapsed time = 0:01:29\n",
    "~~~\n",
    "\n",
    "In this particular run, the model was able to achieve **perfect** accuracy with a `Final score (accuracy)= 1.0`. We should expect the model's predictions of the `Disease` class to be perfect, or very close to it when we compare the actual disease class to the predicted disease class, in the **Exercise 2C**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2C: Print out actual and predicted y-values**\n",
    "\n",
    "In the cell below, print out the actual and predicted disease classes. Label your column headers  `Actual Disease Class` and  `Predicted Disease Class`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2C here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_05_2_Exe2C.png)\n",
    "\n",
    "By inspection you can see that the model's predictions of the disease category are extremely good. In the example shown above there we no errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with both a Cross-Validation and a Holdout Set\n",
    "\n",
    "Training with both Cross-Validation and a separate **_Holdout Set_** is useful because it offers a comprehensive approach to model evaluation and validation. Here are the key reasons why using both techniques together is beneficial:\n",
    "\n",
    "* **Cross-Validation:** \n",
    "1. Provides a robust estimate of the model's performance by training and validating the model on multiple subsets of the data.\n",
    "2. Helps in tuning hyperparameters and assessing model generalization by averaging performance across multiple validation sets.\n",
    "3. Reduces the risk of overfitting by using multiple validation sets and ensuring the model's performance is not biased by a single validation set.\n",
    "\n",
    "* **Holdout Set:**\n",
    "1. Offers an additional level of validation by providing a completely unseen dataset for final model evaluation.\n",
    "2. Mimics real-world scenarios where the model needs to perform well on new, unseen data.\n",
    "3. Provides a final checkpoint to ensure that the model's performance on the Holdout Set aligns with the expected performance based on Cross-Validation results.\n",
    "\n",
    "By combining Cross-Validation for model training, tuning, and initial validation, with a Holdout Set for final model evaluation, practitioners can ensure that their model is well-optimized, generalizes well to unseen data, and performs as expected in real-world applications. If you have a considerable amount of data, it is always valuable to set aside a holdout set before you cross-validate. This holdout set will be the final evaluation before using your model for its real-world use. Figure 5. HOLDOUT shows this division.\n",
    "\n",
    "**Figure 5. HOLDOUT: Cross-Validation and a Holdout Set**\n",
    "![Cross Validation and a Holdout Set](https://biologicslab.co/BIO1173/images/class_3_hold_train_val.png \"Cross-Validation and a Holdout Set\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3A: Prepare feature vector\n",
    "\n",
    "The code in the cell below creates a feature vector the Body Performance dataset for regression. In this example, the model will try to predict the `systolic` blood pressure of individuals. The code is very similiar to the code used in Example 1A. Since we will be performing regression, the y-values will **not** be One-Hot encoded.\n",
    "\n",
    "Since we need additional data for the holdout set, the fraction of `bpBigDF` used for the analysis will be increased from 15% to 20%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 99. 136. 140. 135. 128. 143. 146. 137. 132. 128.]\n"
     ]
    }
   ],
   "source": [
    "# Example 3A: Prepare feature vector\n",
    "\n",
    "# Read the data set\n",
    "bpBigDF = pd.read_csv(\n",
    "    \"https://biologicslab.co/BIO1173/data/bodyPerformance.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Increase to 20% for holdout set\n",
    "bpDF=bpBigDF.sample(frac=0.20)\n",
    "\n",
    "# Map gender\n",
    "mapping = {'M': 1, 'F': 0}\n",
    "bpDF['gender'] = bpDF['gender'].map(mapping)\n",
    "\n",
    "# Map class\n",
    "mapping =  {'A': 0,\n",
    "            'B': 1,\n",
    "            'C': 2,\n",
    "            'D': 3}\n",
    "bpDF['class'] = bpDF['class'].map(mapping)\n",
    "\n",
    "# Generate list of columns for x\n",
    "bpX_columns = bpDF.columns.drop('systolic')  # 'class'\n",
    "\n",
    "# Standardize values with their Z-scores\n",
    "for col in bpX_columns:\n",
    "    bpDF[col] = zscore(bpDF[col])\n",
    "\n",
    "# Generate x-values as numpy array\n",
    "bpX = bpDF[bpX_columns].values\n",
    "bpX = np.asarray(bpX).astype('float32')\n",
    "\n",
    "# Generate y-values as numpy array\n",
    "# Do NOT One-Hot encoding with Regression\n",
    "bpY = bpDF['systolic'].values\n",
    "bpY = np.asarray(bpY).astype('float32')\n",
    "\n",
    "# Print y-values\n",
    "print(bpY[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:\n",
    "~~~text\n",
    "[124. 129. 121. 137. 112. 147. 116. 127. 115. 116.]\n",
    "~~~\n",
    "These are the actual `systolic` blood pressure measurements (in mmHg) for the first 10 subjects in `bpY`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3B: Training with both a Cross-Validation and a Holdout Set \n",
    "\n",
    "Now that the data has been preprocessed, we are ready to build the neural network and train the neural network. The code chunk that creates the additional holdout set is:\n",
    "~~~text\n",
    "# Keep a 10% holdout\n",
    "bpX_main, bpX_holdout, bpY_main, bpY_holdout = train_test_split(    \n",
    "    bpX, bpY, test_size=0.10) \n",
    "~~~\n",
    "During the `for` loop, the datasets `bpX_main` and `bpY_main` are split again into test and training sets with this code chunk:\n",
    "~~~text\n",
    "    # Generate this fold's train and test datasets\n",
    "    x_train = bpX_main[train]\n",
    "    y_train = bpY_main[train]\n",
    "    x_test = bpX_main[test]\n",
    "    y_test = bpY_main[test]\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold #1...\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "Fold score (RMSE): 10.775425910949707\n",
      "Starting Fold #2...\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "Fold score (RMSE): 10.332239151000977\n",
      "Starting Fold #3...\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "Fold score (RMSE): 10.509686470031738\n",
      "Starting Fold #4...\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Fold score (RMSE): 10.549328804016113\n",
      "Starting Fold #5...\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "Fold score (RMSE): 12.115436553955078\n",
      "\n",
      "Cross-validated score (RMSE): 10.875533103942871\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Holdout score (RMSE): 10.59890079498291\n",
      "Elapsed time = 0:02:16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 3B: Training with both a Cross-Validation and a Holdout Set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Set variables\n",
    "EPOCHS=100 # number of epochs for each loop\n",
    "numK=5     # Set number of K-folds\n",
    "\n",
    "# Record the start time in T_start\n",
    "T_start = time.time()\n",
    "\n",
    "# Keep a 10% holdout\n",
    "bpX_main, bpX_holdout, bpY_main, bpY_holdout = train_test_split(    \n",
    "    bpX, bpY, test_size=0.10) \n",
    "\n",
    "# Initial arrays for Out Of Samples (oos)\n",
    "oos_y = []    # array to hold actual y-values\n",
    "oos_pred = [] # array to hold predicted y-values\n",
    "\n",
    "# Cross-validate\n",
    "kf = KFold(numK)\n",
    "\n",
    "fold = 0 # initialize fold count\n",
    "\n",
    "# START LOOP HERE -----------------------------------#\n",
    "\n",
    "# Run loop for each fold\n",
    "for train, test in kf.split(bpX_main):        \n",
    "    fold+=1\n",
    "    print(f\"Starting Fold #{fold}...\")\n",
    "\n",
    "    # Generate this fold's train and test datasets\n",
    "    x_train = bpX_main[train]\n",
    "    y_train = bpY_main[train]\n",
    "    x_test = bpX_main[test]\n",
    "    y_test = bpY_main[test]\n",
    "\n",
    "    # Build new model for this fold\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=bpX.shape[1], activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile model for regression\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # # Run model for this fold\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "              verbose=0,epochs=EPOCHS)\n",
    "    \n",
    "     # Use model to predict y-values from x_test\n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "    # Save actual y-values \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred) \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(f\"Fold score (RMSE): {score}\")\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print()\n",
    "print(f\"Cross-validated score (RMSE): {score}\")    \n",
    "\n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat([oos_y,oos_pred],axis=1 )\n",
    "\n",
    "# Write the cross-validated prediction (from the last neural network)\n",
    "# THIS IS THE FIRST TIME THE HOLDOUT DATA IS USED!\n",
    "holdout_pred = model.predict(bpX_holdout)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(holdout_pred,bpY_holdout))\n",
    "print(f\"Holdout score (RMSE): {score}\")    \n",
    "\n",
    "# Record the end time in T_end\n",
    "T_end = time.time()\n",
    "\n",
    "# Print out elapsed time\n",
    "elaspedTime(T_start,T_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:\n",
    "~~~text\n",
    "Starting Fold #1...\n",
    "16/16 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 11.849387168884277\n",
    "Starting Fold #2...\n",
    "16/16 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 11.288235664367676\n",
    "Starting Fold #3...\n",
    "16/16 [==============================] - 0s 2ms/step\n",
    "Fold score (RMSE): 10.869893074035645\n",
    "Starting Fold #4...\n",
    "16/16 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 10.248887062072754\n",
    "Starting Fold #5...\n",
    "16/16 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 9.961965560913086\n",
    "\n",
    "Cross-validated score (RMSE): 10.865667343139648\n",
    "9/9 [==============================] - 0s 2ms/step\n",
    "Holdout score (RMSE): 11.717198371887207\n",
    "Elapsed time = 0:02:09\n",
    "~~~\n",
    "\n",
    "In the example shown above, the RMSE for the **_holdout_** data was `11.717`. It should be noted that the data \"held back\" in the holdout set was **never** seen by any of the 5 separate neural network models (one model for each fold). Only after the networks were fully trained were they exposed to the holdout data. This mimics real-world scenarios where the model needs to perform well on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3C: Print out actual and predicted y-values\n",
    "\n",
    "The code in the cell below prints out the actual and predicted systolic blood pressure of the subjects in the holdout set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Systolic Pressure (mmHg)</th>\n",
       "      <th>Predicted Systolic Pressure (mmHg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111.0</td>\n",
       "      <td>122.738640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137.0</td>\n",
       "      <td>134.768951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123.0</td>\n",
       "      <td>129.864639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.0</td>\n",
       "      <td>134.051117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>134.0</td>\n",
       "      <td>107.484818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>120.0</td>\n",
       "      <td>120.928993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>147.0</td>\n",
       "      <td>117.389870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>133.0</td>\n",
       "      <td>135.984360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Systolic Pressure (mmHg)  Predicted Systolic Pressure (mmHg)\n",
       "0                               111.0                          122.738640\n",
       "1                               137.0                          134.768951\n",
       "2                               123.0                          129.864639\n",
       "3                               136.0                          134.051117\n",
       "...                               ...                                 ...\n",
       "2407                            134.0                          107.484818\n",
       "2408                            120.0                          120.928993\n",
       "2409                            147.0                          117.389870\n",
       "2410                            133.0                          135.984360\n",
       "\n",
       "[2411 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 3C: Print out actual and predicted y-values\n",
    "\n",
    "# Rename columns\n",
    "new_column_mapping = {0: 'Actual Systolic Pressure (mmHg)', 1: 'Predicted Systolic Pressure (mmHg)'}\n",
    "oosDF = rename_col_by_index(oosDF, new_column_mapping)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# Display DataFrame\n",
    "display(oosDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_05_2_Exm3C.png)\n",
    "\n",
    "By inspection you can see that the model's predictions for systolic blood pressure are not as accurate as might be desired. The RMSE for the **_holdout_** data in this particular run was `11.717` or about 10%.  So while the model did pretty good for the first subject on the list above (index `0`), the prediction for the last subject (index `2410`) was not very close. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3A: Prepare feature vector**\n",
    "\n",
    "In the cell below, write the code to prepare a feature vector for the for the Multiple Disease Prediction dataset for regression with stratified K-fold cross-validation and a holdout set. Use 80% of the data for your DataFrame, `mdpDF`, to compensate for the extra holdout data. \n",
    "~~~text\n",
    "# Use 80% for neural network\n",
    "mdpDF=mdpBigDF.sample(frac=0.80)\n",
    "~~~\n",
    "\n",
    "Use the same mapping of the `Disease` column as you did in Exercise 1A. The goal of your neural network will be to predict the body mass index (`BMI`), so you will need to drop that column when making your list, `mdpX_columns`, that holds the names of the columns to be included when generating your x-values. \n",
    "\n",
    "As above, do _not_ standardize the x data to their Zscores.\n",
    "\n",
    "Since this is model will be doing regression, use `mdpY=mdpDF[`BMI`].values` when creating the y-values using the following code chunk:\n",
    "~~~text\n",
    "# Generate y-values as numpy array\n",
    "mdpY = mdpDF['BMI'].values\n",
    "mdpY = np.asarray(mdpY).astype('float32')\n",
    "~~~\n",
    "\n",
    "Finally, print out the y-values for the first 10 subjects using the following code chunk:\n",
    "~~~text\n",
    "# Print y-values\n",
    "print(mdpY[0:10])\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3A here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:\n",
    "~~~text\n",
    "[0.142  0.0718 0.8393 0.497  0.019  0.6797 0.4039 0.5901 0.1415 0.651 ]\n",
    "~~~\n",
    "These are the standardized `BMI` values for the first 10 subjects in `mdpY`. If we know the minimum and maximal of the actual `BMI` measurements, _before_ they were standardized, we can reverse the process to set the actual, unstandardized `BMI` value. The code in the cell below shows how to \"reverse\" the standarization of the first `BMI` value in the output shown above, `0.1414939`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardize BMI Value: 0.1414939 is equal to the original BMI value: 19.40556096\n"
     ]
    }
   ],
   "source": [
    "# Convert standardized number back into their original non-standardized value\n",
    "\n",
    "# create a simple function\n",
    "def convert_from_0_to_1(value, min_val, max_val):\n",
    "    return value * (max_val - min_val) + min_val\n",
    "\n",
    "# The min, max BMI values were: 18.5 and 24.9 \n",
    "min_val = 18.5  # Minimum original value before standardization\n",
    "max_val = 24.9  # Maximum original value before standardization\n",
    "\n",
    "# Assign standardize value to reverse\n",
    "stand_value = 0.1414939  # First y-value in output\n",
    "\n",
    "# Call function and print out value\n",
    "original_value = convert_from_0_to_1(stand_value, min_val, max_val)\n",
    "print(f\"Standardize BMI Value: {stand_value} is equal to the original BMI value: {original_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following output:\n",
    "~~~text\n",
    "Standardize BMI Value: 0.1414939 is equal to the original BMI value: 19.40556096\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3B: Training with both a Cross-Validation and a Holdout Set**\n",
    "\n",
    "In the cell below, write the code to create and train a regression neural network with both a Cross-Validation and a Holdout Set using the feature vector you created in **Exercise 3A**. Set the number of _K_-folds to `5` and the number of epochs to `100`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3B here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see something similiar to following output:\n",
    "~~~text\n",
    "Starting Fold #1...\n",
    "11/11 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 2.8767874027835205e-05\n",
    "Starting Fold #2...\n",
    "11/11 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 6.265888259804342e-06\n",
    "Starting Fold #3...\n",
    "11/11 [==============================] - 0s 2ms/step\n",
    "Fold score (RMSE): 0.00013639968528877944\n",
    "Starting Fold #4...\n",
    "11/11 [==============================] - 0s 2ms/step\n",
    "Fold score (RMSE): 1.5171485756582115e-06\n",
    "Starting Fold #5...\n",
    "11/11 [==============================] - 0s 1ms/step\n",
    "Fold score (RMSE): 0.0023843529634177685\n",
    "\n",
    "Cross-validated score (RMSE): 0.0010675085941329598\n",
    "6/6 [==============================] - 0s 2ms/step\n",
    "Holdout score (RMSE): 0.0026710291858762503\n",
    "Elapsed time = 0:01:38\n",
    "~~~\n",
    "\n",
    "The `Holdout score (RMSE): 0.0026710291858762503` that was obtained in this particular run, means the model is very accurate due to the low RMSE value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3C: Print out actual and predicted y-values**\n",
    "\n",
    "In the cell below, print out the actual and predicted y-values from the holdout set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3C here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see something similar to the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_05_2_Exe3C.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lesson Turn-in**\n",
    "\n",
    "When you have completed all of the code cells, and run them in sequential order (the last code cell should be number 22), use the **File --> Print.. --> Save to PDF** to generate a PDF of your JupyterLab notebook. Save your PDF as `Class_05_2.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
