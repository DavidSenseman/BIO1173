{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEEW13uCtiJ"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/master/Class_05_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BIO 1173: Intro Computational Biology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module 5: Regularization and Dropout**\n",
    "\n",
    "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
    "\n",
    "### Module 5 Material\n",
    "\n",
    "* Part 5.1: Part 5.1: Introduction to Regularization: Ridge and Lasso\n",
    "* Part 5.2: Using K-Fold Cross Validation with Keras\n",
    "* **Part 5.3: Using L1 and L2 Regularization with Keras to Decrease Overfitting**\n",
    "* Part 5.4: Drop Out for Keras to Decrease Overfitting\n",
    "* Part 5.5: Benchmarking Keras Deep Learning Regularization Techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKQylnEiLDUM"
   },
   "source": [
    "### Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n",
    "  Running the following code will map your GDrive to ```/content/drive```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seXFCYH4LDUM",
    "outputId": "c05015aa-871e-4779-9265-5ad07e8bf617"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Setup\n",
    "\n",
    "Run the next code cell to load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You MUST run this code cell first\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "path = '/'\n",
    "memory = shutil.disk_usage(path)\n",
    "dirpath = os.getcwd()\n",
    "print(\"Your current working directory is : \" + dirpath)\n",
    "print(\"Disk\", memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for this lesson\n",
    "\n",
    "For this lesson we will be using the [Obesity Prediction Dataset](https://www.kaggle.com/datasets/mrsimple07/obesity-prediction) for the Examples and the [Body Performance Dataset](https://www.kaggle.com/datasets/kukuroo3/body-performance-data) for the **Exercises**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obesity Prediction Dataset\n",
    "\n",
    "The **_Obesity Prediction dataset_** provides comprehensive information on individuals' demographic characteristics, physical attributes, and lifestyle habits, aiming to facilitate the analysis and prediction of obesity prevalence. \n",
    "\n",
    "The 7 categories of obesity/demographics measurements are:\n",
    "\n",
    "* **Age:** The age of the individual, expressed in years (Mean=49.9 yrs +/- 18.1)\n",
    "* **Gender:** The gender of the individual coded `Male` and `Female`\n",
    "* **Height:** The height of the individual measured in centimeters (Mean=170 cm +/- 10.3)\n",
    "* **Weight:** The weight of the individual measured in kilograms (Mean=71.2 kg +/- 15.5)\n",
    "* **BMI:** Body mass index, a calculated metric derived from the individual's weight and height (Mean=24.9 +/- 6.19)\n",
    "* **PhysicalActivityLevel:** This variable quantifies the individual's level of physical activity (Mean=2.53 +/- 1.12) \n",
    "* **ObesityCategory:** Categorization of individuals based on their BMI into different obesity categories\n",
    " \n",
    "The output from `opDF.info` is:\n",
    "~~~text\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 1000 entries, 0 to 999\n",
    "Data columns (total 7 columns):\n",
    " #   Column                 Non-Null Count  Dtype  \n",
    "---  ------                 --------------  -----  \n",
    " 0   Age                    1000 non-null   int64  \n",
    " 1   Gender                 1000 non-null   object \n",
    " 2   Height                 1000 non-null   float64\n",
    " 3   Weight                 1000 non-null   float64\n",
    " 4   BMI                    1000 non-null   float64\n",
    " 5   PhysicalActivityLevel  1000 non-null   int64  \n",
    " 6   ObesityCategory        1000 non-null   object \n",
    "dtypes: float64(3), int64(2), object(2)\n",
    "memory usage: 54.8+ KB\n",
    "~~~\n",
    "As you can see, two columns, `Age` and `ObesityCategory`, are non-numeric and will need to be converted into numeric values. Since all columns have the same `Non-Null Count` (_n_=1000) there is no missing data. \n",
    "\n",
    "The output from `opDF['ObesityCategory'].value_counts()` is as follows:\n",
    "~~~text\n",
    "ObesityCategory\n",
    "Normal weight    371\n",
    "Overweight       295\n",
    "Obese            191\n",
    "Underweight      143\n",
    "Name: count, dtype: int64\n",
    "~~~\n",
    "As you can see, the column `ObesityCategory` has four categorical values.\n",
    "\n",
    "The output from `opDF['PhysicalActivityLevel'].value_counts()` is as follows:\n",
    "~~~text\n",
    "PhysicalActivityLevel\n",
    "4    259\n",
    "3    255\n",
    "2    247\n",
    "1    239\n",
    "Name: count, dtype: int64\n",
    "~~~\n",
    "\n",
    "There are four different activity levels, ranging from 1 to 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body Performance dataset\n",
    "\n",
    "[Body Performance](https://www.kaggle.com/datasets/kukuroo3/body-performance-data)\n",
    "\n",
    "For the Examples in this lesson, we will be using the [Body Performance dataset](https://www.kaggle.com/datasets/kukuroo3/body-performance-data) provided by the [Seoul Olympic Games Korea Sports Promotion Foundation](https://www.bigdata-culture.kr/bigdata/user/data_market/detail.do?id=ace0aea7-5eee-48b9-b616-637365d665c1). \n",
    "\n",
    "This dataset has 12 categories of body performance for a relatively large number of men and women (_n_=13,303). To speed-up the training of neural networks in the Examples, we will only use a fraction of the total number. \n",
    "\n",
    "The 12 categories of fitness measurements are:\n",
    "* **age:** 20 ~64\n",
    "* **gender:** M,F\n",
    "* **height_cm:** (If you want to convert to feet, divide by 30.48)\n",
    "* **weight_kg:**\n",
    "* **body fat_%:**\n",
    "* **diastolic:** diastolic blood pressure (min)\n",
    "* **systolic:** systolic blood pressure (min)\n",
    "* **gripForce:**\n",
    "* **sit and bend forward_cm:**\n",
    "* **sit-ups counts:**\n",
    "* **broad jump_cm:**\n",
    "* **class:** A,B,C,D ( A: best) / stratified\n",
    "\n",
    "The output for the command `df.info()` is as follows:\n",
    "~~~text\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 13393 entries, 0 to 13392\n",
    "Data columns (total 12 columns):\n",
    " #   Column                   Non-Null Count  Dtype  \n",
    "---  ------                   --------------  -----  \n",
    " 0   age                      13393 non-null  float64\n",
    " 1   gender                   13393 non-null  object \n",
    " 2   height_cm                13393 non-null  float64\n",
    " 3   weight_kg                13393 non-null  float64\n",
    " 4   body fat_%               13393 non-null  float64\n",
    " 5   diastolic                13393 non-null  float64\n",
    " 6   systolic                 13393 non-null  float64\n",
    " 7   gripForce                13393 non-null  float64\n",
    " 8   sit and bend forward_cm  13393 non-null  float64\n",
    " 9   sit-ups counts           13393 non-null  float64\n",
    " 10  broad jump_cm            13393 non-null  float64\n",
    " 11  class                    13393 non-null  object \n",
    "dtypes: float64(10), object(2)\n",
    "~~~\n",
    "\n",
    "As you can see, all but two columns, `age` and `class`, are numeric. Since all columns have the same `Non-Null Count` there is no missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functions for this lesson\n",
    "\n",
    "The code in the cell below creates 2 useful functions for this lesson, `elaspedTime(start,stop)` and `rename_col_by_index(dataframe, index_mapping)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions\n",
    "\n",
    "# Simple function to print out elasped time\n",
    "def elaspedTime(start,end):\n",
    "    # Print out time\n",
    "    seconds = int((end-start))\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    print(\"Elapsed time = %d:%02d:%02d\" % (hour, minutes, seconds))\n",
    "    print()\n",
    "\n",
    "# Simple function to change column name in a dataframe\n",
    "def rename_col_by_index(dataframe, index_mapping):\n",
    "    dataframe.columns = [index_mapping.get(i, col) for i, col in enumerate(dataframe.columns)]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.3: L1 and L2 Regularization to Decrease Overfitting\n",
    "\n",
    "L1 and L2 regularization are two common regularization techniques that can reduce the effects of overfitting [[Cite:ng2004feature]](http://cseweb.ucsd.edu/~elkan/254spring05/Hammon.pdf). These algorithms can either work with an objective function or as a part of the backpropagation algorithm. In both cases, the regularization algorithm is attached to the training algorithm by adding an objective. \n",
    "\n",
    "## L1 Regularization\n",
    "In the context of a neural network with L1 regularization, the objective function typically consists of two main components: the original loss function and the L1 regularization term. The objective function serves as a measure that the optimization algorithm aims to minimize during the training process.\n",
    "\n",
    "The objective function with L1 regularization can be represented as:\n",
    "\n",
    "`Objective function = Loss function + λ * L1 regularization term`\n",
    "\n",
    "where:\n",
    "\n",
    "* **Loss function:** The original loss function used to evaluate the performance of the neural network on the training data, such as the cross-entropy loss or mean squared error.\n",
    "* **λ (lambda):** The regularization parameter that controls the strength of the L1 regularization penalty.\n",
    "* **L1 regularization term:** The sum of absolute values of the weights in the neural network.\n",
    "\n",
    "The addition of the L1 regularization term to the objective function encourages sparsity in the weights of the neural network by penalizing large weights. This helps prevent overfitting and can lead to a simpler and more interpretable model. The trade-off between minimizing the loss function and reducing the magnitude of the weights is controlled by the regularization parameter λ.\n",
    "\n",
    "During the training process, the neural network adjusts its weights by minimizing the composite objective function, striking a balance between fitting the training data well (minimizing the loss function) and reducing model complexity (L1 regularization).\n",
    "\n",
    "These algorithms work by adding a weight penalty to the neural network training. This penalty encourages the neural network to keep the weights to small values. Both L1 and L2 calculate this penalty differently. You can add this penalty calculation to the calculated gradients for gradient-descent-based algorithms, such as backpropagation. The penalty is negatively combined with the objective score for objective-function-based training, such as simulated annealing.\n",
    "\n",
    "\n",
    "## L1 vs L2 Regularization\n",
    "Both L1 and L2 work similarily in that they penalize the size of the weight, but in significantly different ways. L2 will force the weights into a pattern similar to a Gaussian distribution while the L1 will force the weights into a pattern similar to a Laplace distribution, as demonstrated in the following figure.\n",
    "\n",
    "![L1 vs L2](https://biologicslab.co/BIO1173/images/class_9_l1_l2.png \"L1 vs L2\")\n",
    "\n",
    "As you can see, L1 algorithm is more tolerant of weights further from 0, whereas the L2 algorithm is less tolerant. We will highlight other important differences between L1 and L2 in the following sections. You also need to note that both L1 and L2 count their penalties based only on weights; they do not count penalties on bias values. Keras allows [l1/l2 to be directly added to your network](http://tensorlayer.readthedocs.io/en/stable/modules/cost.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: L1 Regularization of a classification neural network\n",
    "\n",
    "In Example 1, L1 regularization will be demonstrated using the Obesity Prediction dataset and a classification neural network that will predict the Obesity Category of individuals. To make coding easier to follow, Example 1 has been broken down into 3 steps labeled \"A\", \"B\" and \"C\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1A: Create feature vector\n",
    "\n",
    "The code in the cell below reads the Obesity Prediction dataset, `obesity_prediction.csv` from the course HTTPS server and and creates a new DataFrame called `opDF`. The column `Gender` is mapped with the string `Male` being mapped to `0` and `Female` mapped to `1`. The columns `Age`, `Height`, `Weight` and `BMI` are standardized to their Zscores. Since `ObesityCategory` is the y-value for this neural network, it is dropped when generating the list with the names of the columns to be used for the x-values (`opX_columns`). \n",
    "\n",
    "Since we will be building a neural network for **_classification_** we need to One-Hot encode the column `ObesityCategory` using the following code chunk:\n",
    "~~~text\n",
    "# One-Hot encode the column containing the y-values\n",
    "dummies = pd.get_dummies(opDF['ObesityCategory']) # Classification\n",
    "ObCategories = dummies.columns\n",
    "opY = dummies.values\n",
    "opY = np.asarray(opY).astype('float32')\n",
    "~~~\n",
    "\n",
    "Finally, the cell prints out the categorical values (names) that were One-Hot encoded using the \"starred\" print statement:\n",
    "~~~text\n",
    "# Print y categorical names\n",
    "print(*ObCategories)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 1A; Create feature vector\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "opDF = pd.read_csv(\n",
    "    \"https://biologicslab.co/BIO1173/data/obesity_prediction.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Map Gender\n",
    "mapping =  {'Male': 0,\n",
    "            'Female': 1}\n",
    "opDF['Gender'] = opDF['Gender'].map(mapping)\n",
    "\n",
    "# Standardize ranges\n",
    "opDF['Age'] = zscore(opDF['Age'])\n",
    "opDF['Height'] = zscore(opDF['Height'])\n",
    "opDF['Weight'] = zscore(opDF['Weight'])\n",
    "opDF['BMI'] = zscore(opDF['BMI'])\n",
    "\n",
    "# Map ObesityCategory\n",
    "#mapping =  {'Underweight': 0,\n",
    "#            'Normal weight': 1,\n",
    "#            'Overweight': 2,\n",
    "#            'Obese': 3}\n",
    "#opDF['ObesityCategory'] = opDF['ObesityCategory'].map(mapping)\n",
    "\n",
    "# Generate list of columns for x\n",
    "opX_columns = opDF.columns.drop('ObesityCategory')  # \n",
    "\n",
    "# Generate x-values as numpy array\n",
    "opX = opDF[opX_columns].values\n",
    "opX = np.asarray(opX).astype('float32')\n",
    "\n",
    "# One-Hot encode the column containing the y-values\n",
    "dummies = pd.get_dummies(opDF['ObesityCategory']) # Classification\n",
    "ObCategories = dummies.columns\n",
    "opY = dummies.values\n",
    "opY = np.asarray(opY).astype('float32')\n",
    "\n",
    "# Print y categorical names\n",
    "print(*ObCategories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following output:\n",
    "~~~text\n",
    "Normal weight Obese Overweight Underweight\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1B: L1 Regularization to Decrease Overfitting \n",
    "\n",
    "We now create a Keras network with L1 regression. \n",
    "\n",
    "The specific Keras code chunk that adds L1 regularization is the following:\n",
    "~~~text\n",
    "activity_regularizer=regularizers.l1(1e-4)\n",
    "~~~\n",
    "It should be noted that the L1 regularizer is added to each hidden layer, but **not** to the output layer:\n",
    "~~~text\n",
    "# Hidden 1\n",
    "    model.add(Dense(50, input_dim=opX.shape[1], \n",
    "            activation='relu',\n",
    "            activity_regularizer=regularizers.l1(1e-4))) \n",
    "    # Hidden 2\n",
    "    model.add(Dense(25, activation='relu', \n",
    "                    activity_regularizer=regularizers.l1(1e-4))) \n",
    "     # Output\n",
    "    model.add(Dense(opY.shape[1],activation='softmax'))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 1B: L1 Regularization to Decrease Overfitting\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Set variables\n",
    "EPOCHS=100 # number of epochs for each loop\n",
    "numK=5     # Set number of K-folds\n",
    "\n",
    "# Record the start time in T_start\n",
    "T_start = time.time()\n",
    "\n",
    "# Cross-validate using KFold\n",
    "kf = KFold(numK, shuffle=True, random_state=42)\n",
    "    \n",
    "# Initialize arrays\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "\n",
    "# Initialize fold \n",
    "fold = 0\n",
    "\n",
    "# Start loop here ---------------------------------#\n",
    "\n",
    "for train, test in kf.split(opX):\n",
    "    fold+=1   # increment fold\n",
    "    print(f\"Starting Fold #{fold}...\")\n",
    "\n",
    "    # Split data for this fold\n",
    "    x_train = opX[train]\n",
    "    y_train = opY[train]\n",
    "    x_test = opX[test]\n",
    "    y_test = opY[test]\n",
    "    \n",
    "    #kernel_regularizer=regularizers.l2(0.01),\n",
    "\n",
    "    # Create new model for this fold\n",
    "    model = Sequential()\n",
    "    # Hidden 1\n",
    "    model.add(Dense(50, input_dim=opX.shape[1], \n",
    "            activation='relu',\n",
    "            activity_regularizer=regularizers.l1(1e-4))) \n",
    "    # Hidden 2\n",
    "    model.add(Dense(25, activation='relu', \n",
    "                    activity_regularizer=regularizers.l1(1e-4))) \n",
    "     # Output\n",
    "    model.add(Dense(opY.shape[1],activation='softmax'))\n",
    "    # Compile model for this fold\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    # Train model for this fold\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "              verbose=0,epochs=EPOCHS)\n",
    "    \n",
    "    # Use model to make predictions  \n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "    # Add actual y-values for the data used this fold\n",
    "    oos_y.append(y_test)\n",
    "    # raw probabilities to chosen class (highest probability)\n",
    "    pred = np.argmax(pred,axis=1) \n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "# End loop ----------------------------------------------------#\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [oos_pred, oos_y],axis=1 )\n",
    "\n",
    "# Uncomment the next line to print file\n",
    "#oosDF.to_csv(filename_write,index=False)\n",
    "\n",
    "# Record the end time in T_end\n",
    "T_end = time.time()\n",
    "\n",
    "# Print out elapsed time\n",
    "elaspedTime(T_start,T_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see something similar to following output:\n",
    "~~~text\n",
    "Starting Fold #1...\n",
    "7/7 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.955\n",
    "Starting Fold #2...\n",
    "7/7 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.985\n",
    "Starting Fold #3...\n",
    "7/7 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.965\n",
    "Starting Fold #4...\n",
    "7/7 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.975\n",
    "Starting Fold #5...\n",
    "7/7 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.97\n",
    "Final score (accuracy): 0.97\n",
    "Elapsed time = 0:01:10\n",
    "~~~\n",
    "The `Final score (accuracy): 0.97` is very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1C: Print out actual and predicted y-values\n",
    "\n",
    "The code in the cell below prints out the predicted and the actual Obesity Categories for the \"out-of-sample\" individuals. As mentioned previously, \"out-of-sample\" refers to data that was _not_ used in the process of developing the neural network model. It is only used to evaluate the accuracy and performance of the model on new, unseen data to assess its generalizability and potential for predicting future outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1C: Print out actual and predicted y-values \n",
    "\n",
    "# Rename columns\n",
    "new_column_mapping = {0: 'Predicted Ob Class', 1: 'Actual: 0'}\n",
    "oosDF = rename_col_by_index(oosDF, new_column_mapping)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# Display DataFrame\n",
    "display(oosDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_05_3_Exm1C.png)\n",
    "\n",
    "By inspection of the output above, you can see the model's predictions of the Obesity Category are very good for the out-of-sample individuals as would be expected with a `Final score (accuracy): 0.97`. In the output shown above, there were no errors in the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 1: L1 Regularization of a classification neural network**\n",
    "\n",
    "For **Exercise 1**, you are to use the Body Performance dataset and build a classification neural network that will predict the fitness `class` of individuals. To make coding easier, **Exercise 1** has been broken down into 3 steps labeled \"A\", \"B\" and \"C\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1A: Create feature vector**\n",
    "\n",
    "In the cell below, read the Body Performance dataset, `bodyPerformance.csv` from the course HTTPS server and and create a new DataFrame called `bpBigDF`. Since this is a fairly large dataset, you can speed up training time by only using a part of it. Use this code chunk to create a DataFrame with only 20% of the samples:\n",
    "~~~text\n",
    "bpDF=bpBigDF.sample(frac=0.20)\n",
    "~~~\n",
    "\n",
    "You need to map the column `gender` with the categorical values `M` and `F` to integers.  \n",
    "\n",
    "You should also standardize some, but not all of the other numeric values using this code chunk:\n",
    "~~~text\n",
    "# Standardize ranges\n",
    "bpDF['age'] = zscore(bpDF['age'])\n",
    "bpDF['height_cm'] = zscore(bpDF['height_cm'])\n",
    "bpDF['weight_kg'] = zscore(bpDF['weight_kg'])\n",
    "bpDF['diastolic'] = zscore(bpDF['diastolic'])\n",
    "bpDF['systolic'] = zscore(bpDF['systolic'])\n",
    "bpDF['gripForce'] = zscore(bpDF['gripForce'])\n",
    "~~~\n",
    "\n",
    "Since you are building a classification neural network to predict `class`, you will need to drop that column when creating your list of X columns:\n",
    "~~~text\n",
    "# Generate list of columns for x\n",
    "bpX_columns = bpDF.columns.drop('class')  # class is y-value \n",
    "~~~\n",
    "Using this list, you can generate the x values for your model using the following code chunk:\n",
    "~~~text\n",
    "# Generate x-values as numpy array\n",
    "bpX = bpDF[bpX_columns].values\n",
    "bpX = np.asarray(bpX).astype('float32')\n",
    "~~~\n",
    "\n",
    "Since this is a classification neural network, you will also need to One-Hot encode the column `class` using the following code chunk:\n",
    "~~~text\n",
    "# One-Hot encode the column containing the y-values\n",
    "dummies = pd.get_dummies(bpDF['class']) # Classification\n",
    "BpCategories = dummies.columns\n",
    "bpY = dummies.values\n",
    "bpY = np.asarray(bpY).astype('float32')\n",
    "~~~\n",
    "\n",
    "Finally, prints out the categorical values (names), `BpCategories` that were One-Hot encoded, using the \"starred\" print statement:\n",
    "~~~text\n",
    "# Print y categorical names\n",
    "print(*ObCategories)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1A here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following output:\n",
    "~~~text\n",
    "A B C D\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1B: L1 Regularization to Decrease Overfitting** \n",
    "\n",
    "In the cell below, create a Keras network with L1 regression to predict the fitness `class` in the Body Performance Dataset using the feature vector that you prepared in **Exercise 1A**. The code in Example 1B should act as your template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1B here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see something similar to following output:\n",
    "~~~text\n",
    "Starting Fold #1...\n",
    "17/17 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 0.6567164179104478\n",
    "Starting Fold #2...\n",
    "17/17 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 0.6007462686567164\n",
    "Starting Fold #3...\n",
    "17/17 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 0.6156716417910447\n",
    "Starting Fold #4...\n",
    "17/17 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 0.6455223880597015\n",
    "Starting Fold #5...\n",
    "17/17 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 0.6448598130841121\n",
    "Final score (accuracy): 0.6326987681970885\n",
    "Elapsed time = 0:02:44\n",
    "~~~\n",
    "The `Final score (accuracy): 0.6326987681970885` is not especially accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1C: Print out actual and predicted y-values**\n",
    "\n",
    "In the cell below, print out the predicted and the actual Fitness `class` for the out-of-sample individuals. Label your columns using the following code chunk:\n",
    "~~~text\n",
    "# Rename columns\n",
    "new_column_mapping = {0: 'Predicted Fitness Class', 1: 'Actual: 0'}\n",
    "oosDF = rename_col_by_index(oosDF, new_column_mapping)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1C here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_05_3_Exe1C.png)\n",
    "\n",
    "By inspection of the output above, you can see the model's predictions of the fitness `class` is not perfect for the out-of-sample individuals. This should not come as a big surprise given a `Final score (accuracy): 0.6327`. \n",
    "\n",
    "In the output shown above, there were some errors in the model's predictions. The model correctly predicted the `class` level for 6 of the individuals, but made incorrect predictions for 2 subjects, `index 2675` and `index 2677`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 2: L2 Regularization of a classification neural network**\n",
    "\n",
    "L2 regularization might generate better results than L1 regularization under the following conditions:\n",
    "\n",
    "* **Feature Correlation:** When features are highly correlated, L2 regularization tends to perform better than L1 regularization. L2 regularization encourages sparse coefficients but does not force them to zero, allowing correlated features to share the regularization penalty more evenly.\n",
    "* **Data Noise:** In the presence of noisy data, L2 regularization can be more effective at smoothing out the noise due to its tendency to distribute the penalty more uniformly across all weights. L2 regularization helps prevent individual noisy data points from disproportionately influencing the model.\n",
    "* **Model Stability:** L2 regularization often leads to more stable and well-conditioned models compared to L1 regularization. L2 regularization prevents the weights from growing excessively large, which can improve the numerical stability of the optimization process and enhance generalization performance.\n",
    "* **Small Dataset:** When working with a small dataset, L2 regularization can help prevent overfitting by providing smoother and more continuous solutions. L2 regularization penalizes large weights more gently than L1 regularization, making it more suitable for avoiding overfitting in smaller datasets.\n",
    "* **Uniform Impact on All Weights:** If the goal is to ensure that all weights have some level of regularization, rather than inducing sparsity, L2 regularization is preferred. L2 regularization treats all weights equally, promoting a more balanced impact on the model parameters.\n",
    "\n",
    "In summary, L2 regularization often outperforms L1 regularization in scenarios where feature correlation, data noise, model stability, small dataset size, or a uniform impact on all weights are important considerations for achieving better results and improved generalization performance.\n",
    "\n",
    "For **Exercise 2**, you are to again use the Body Performance dataset and build a classification neural network that will predict the fitness `class` of individuals. As before, **Exercise 2** has been broken down into 3 steps labeled \"A\", \"B\" and \"C\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2A: Create feature vector**\n",
    "\n",
    "In the cell below create a feature vector for the Body Performance dataset. You should use **exactly** the same code that you wrote for **Exercise 1B**. As above, only use 20% of the dataset for your neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2A here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following output:\n",
    "~~~text\n",
    "A B C D\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2B: L1 Regularization to Decrease Overfitting** \n",
    "\n",
    "In the cell below, create a Keras network with L2 regression. The code for **Exercise 2B** should be _identical_ to the code you wrote for **Exercise 1B** with only one difference. To enable L2 regularization you will need to make the following code changes. \n",
    "\n",
    "Change the line:\n",
    "~~~text\n",
    "activity_regularizer=regularizers.l1(1e-4)\n",
    "~~~\n",
    "to read:\n",
    "~~~text\n",
    "kernel_regularizer=regularizers.l2(0.01))) \n",
    "~~~\n",
    "It is somewhat hard to spot the difference. Can you see what is different?\n",
    "\n",
    "As above, the L2 regularizer must be added to each hidden layer, but not to the output layer:\n",
    "~~~text\n",
    "    # Hidden 1\n",
    "    model.add(Dense(50, input_dim=bpX.shape[1], \n",
    "            activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01))) \n",
    "    # Hidden 2\n",
    "    model.add(Dense(25, activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(0.01))) \n",
    "    # Output\n",
    "    model.add(Dense(bpY.shape[1],activation='softmax'))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2B here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see something similar to following output:\n",
    "~~~text\n",
    "Starting Fold #1...\n",
    "17/17 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 0.5746268656716418\n",
    "Starting Fold #2...\n",
    "17/17 [==============================] - 0s 1ms/step\n",
    "Fold score (accuracy): 0.5783582089552238\n",
    "Starting Fold #3...\n",
    "17/17 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.6026119402985075\n",
    "Starting Fold #4...\n",
    "17/17 [==============================] - 1s 2ms/step\n",
    "Fold score (accuracy): 0.5522388059701493\n",
    "Starting Fold #5...\n",
    "17/17 [==============================] - 0s 2ms/step\n",
    "Fold score (accuracy): 0.5887850467289719\n",
    "Final score (accuracy): 0.5793206420306084\n",
    "Elapsed time = 0:02:47\n",
    "\n",
    "~~~\n",
    "The `Final score (accuracy): 0.5793206420306084` is not that much of an improvement over the `0.632698768197088` score obtained with L1 Regularization in **Exercise 1B**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2C: Print out actual and predicted y-values**\n",
    "\n",
    "In the cell below, print out the predicted and the actual Fitness `class` for the \"out-of-sample\" individuals. Label your columns using the following code chunk:\n",
    "~~~text\n",
    "# Rename columns\n",
    "new_column_mapping = {0: 'Predicted Fitness Class', 1: 'Actual: 0'}\n",
    "oosDF = rename_col_by_index(oosDF, new_column_mapping)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2C here\n",
    "\n",
    "# Rename columns\n",
    "new_column_mapping = {0: 'Predicted Fitness Class', 1: 'Actual: 0'}\n",
    "oosDF = rename_col_by_index(oosDF, new_column_mapping)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# Display DataFrame\n",
    "display(oosDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_05_3_Exe1C.png)\n",
    "\n",
    "By inspection of the output above, you can see the model's predictions of the fitness `class` is not perfect for the out-of-sample individuals. This should not come as a big surprise given a `Final score (accuracy): 0.6327`. \n",
    "\n",
    "In the output shown above, there were some errors in the model's predictions. The model correctly predicted the `class` level for 6 of the individuals, but made incorrect predictions for 2 subjects, `index 2675` and `index 2677`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lesson Turn-in**\n",
    "\n",
    "When you have completed all of the code cells, and run them in sequential order (the last code cell should be number 12), not counting the optional File Clean-up below), use the **File --> Print.. --> Save to PDF** to generate a PDF of your JupyterLab notebook. Save your PDF as `Class_05_3.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
