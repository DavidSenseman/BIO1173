{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXvXZ2IF5M+2a1VfJ8KLae",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/main/Class_05_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZVwSpdbE3Y"
      },
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExN-OzpYbE3Y"
      },
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4imk1kbE3Y"
      },
      "source": [
        "##### **Module 5: Natural Language Processing**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Biology, Health and the Environment](https://sciences.utsa.edu/bhe/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "### Module 4 Material\n",
        "\n",
        "* **Part 5.1: Introduction to Hugging Face**\n",
        "* Part 5.2: Hugging Face Tokenizers\n",
        "* Part 5.3: Hugging Face Datasets\n",
        "* Part 5.4: Training Hugging Face models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_-lPkxLbE3Z"
      },
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. By running this code cell, you will map your GDrive to /content/drive and print out your Google GMAIL address. Your Instructor will use your GMAIL address to verify the author of this class lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seXFCYH4LDUM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# You must run this cell first\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    Colab = True\n",
        "    print(\"Note: Using Google CoLab\")\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"**WARNING**: Your GMAIL address was **not** printed in the output below.\")\n",
        "    print(\"**WARNING**: You will NOT receive credit for this lesson.\")\n",
        "    Colab = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see the following output except your GMAIL address should appear on the last line.\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image01B.png)\n",
        "\n",
        "If your GMAIL address does not appear your lesson will **not** be graded."
      ],
      "metadata": {
        "id": "xG3_sXTDfyjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Runtime type for Class_05_1\n",
        "\n",
        "For this lesson GPU hardware accelerations is **optional**. Your lesson will defintely run faster with GPU acceleration, but the lesson can be completed only a \"cpu\" runtime. If you decide to use GPU acceleration, the **T4 GPU** would be fine."
      ],
      "metadata": {
        "id": "lj4YNYc0PdkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **YouTube Introduction to Hugging Face**\n",
        "\n",
        "Run the next cell to see short introduction to Hugging Face. This is a suggested, but optional, part of the lesson."
      ],
      "metadata": {
        "id": "QDQzWK1HR7lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "video_id = \"GLO5FZzfrS0\"\n",
        "\n",
        "HTML(f\"\"\"\n",
        "<iframe width=\"560\" height=\"315\"\n",
        "  src=\"https://www.youtube.com/embed/{video_id}\"\n",
        "  title=\"YouTube video player\"\n",
        "  frameborder=\"0\"\n",
        "  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
        "  allowfullscreen\n",
        "  referrerpolicy=\"strict-origin-when-cross-origin\"> </iframe>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "1OPgX17uRZ7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "32658d78-73e2-48c4-e492-c09f861aa8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<iframe width=\"560\" height=\"315\"\n",
              "  src=\"https://www.youtube.com/embed/GLO5FZzfrS0\"\n",
              "  title=\"YouTube video player\"\n",
              "  frameborder=\"0\"\n",
              "  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
              "  allowfullscreen\n",
              "  referrerpolicy=\"strict-origin-when-cross-origin\"> </iframe>\n"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to Hugging Face**\n",
        "\n",
        "**Hugging Face** is a company renowned for its pioneering work in the realm of Natural Language Processing (NLP). Established in 2016, Hugging Face has become synonymous with making cutting-edge NLP technologies more accessible to developers, researchers, and organizations. The company's commitment to open-source development has fostered a vibrant community, which plays a pivotal role in the rapid advancements of the field.\n",
        "\n",
        "Central to Hugging Face's acclaim is the Transformers library. This Python library provides an extensive collection of pre-trained models that span a wide range of NLP tasks, from text classification and tokenization to language modeling and translation. Some of the most groundbreaking models like BERT, GPT-2, T5, and RoBERTa can be effortlessly accessed and deployed through this library.\n",
        "\n",
        "A notable feature of the Transformers library is its user-friendly API. With just a few lines of code, one can:\n",
        "\n",
        "* Load a pre-trained model.\n",
        "* Tokenize input text.\n",
        "* Obtain model predictions or embeddings.\n",
        "* Fine-tune the model on a specific task.\n",
        "\n",
        "This ease of use, combined with comprehensive documentation and tutorials, makes it an invaluable tool for both NLP newcomers and seasoned professionals.\n",
        "\n",
        "Another significant contribution from Hugging Face is the Model Hub, a platform where researchers and developers can share, discover, and use NLP models. The hub promotes collaboration, ensuring that state-of-the-art models are easily available to the wider community. It's not uncommon to see models from recent research papers promptly available on the hub, ready for real-world applications.\n",
        "\n",
        "Tokenization, the process of converting text into tokens, is a fundamental step in NLP. Recognizing its importance, Hugging Face introduced the Tokenizers library, which provides a fast and efficient way to tokenize massive datasets without compromising on accuracy. Its compatibility with the Transformers library ensures seamless integration between tokenization and modeling.\n",
        "\n",
        "Democratization of NLP: By making advanced models and tools accessible, Hugging Face has democratized NLP, enabling even small teams or individual developers to harness the power of state-of-the-art models.\n",
        "\n",
        "Rapid Prototyping: The ease with which one can deploy models means that ideas can be tested and iterated upon swiftly, accelerating the pace of NLP advancements.\n",
        "\n",
        "Community and Collaboration: The open-source ethos of Hugging Face has cultivated a community that collaborates, contributes, and ensures that the field remains vibrant and progressive.\n",
        "\n",
        "In the ever-evolving landscape of NLP, Hugging Face stands out as a beacon of innovation, accessibility, and collaboration. Whether you are a researcher pushing the boundaries of what's possible, a developer aiming to integrate NLP into an application, or an enthusiast eager to learn, Hugging Face provides the tools and resources to realize those ambitions. As we delve deeper into this book, we will frequently use the Hugging Face platform to illustrate concepts, implement solutions, and explore the vast possibilities of NLP.\n",
        "\n"
      ],
      "metadata": {
        "id": "wVWCWSJurbIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using Python with Hugging Face**\n",
        "\n",
        "Transformers have become a mainstay of natural language processing. This module will examine the [Hugging Face](https://huggingface.co/) Python library for natural language processing, bringing together pretrained transformers, data sets, tokenizers, and other elements. Through the Hugging Face API, you can quickly begin using sentiment analysis, entity recognition, language translation, summarization, and text generation.\n",
        "\n",
        "Colab does not install Hugging face by default. Whether installing Hugging Face directly into a local computer or utilizing it through Colab, the following commands will install the library.\n",
        "\n",
        "Normally, when you use `pip` to install a package, a lot of information is printed out to show what subpackages were installed. We have prevented this by\n",
        "adding the text `> /dev/` after the `!pip install <package>`. Technically, this code `redirects` the standard output (in this case your Colab notebook) to a device called `null`. `/dev/null` is a special file that discards all data written to it. It is often used as a \"black hole\" for unwanted output or error messages, such as the output of commands that are meant to be silent or hidden.\n"
      ],
      "metadata": {
        "id": "5A4aEEHas1hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log into Hugging Face\n",
        "\n",
        "Run the next code cell to log into your Hugging Face account using your `HF_Token` stored in your Colab Secrets. You may have to grant access to your Colab Secrets."
      ],
      "metadata": {
        "id": "IxlcLtTWf09r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log into Hugging Face.\n",
        "\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Get the token from Colab Secrets and log in\n",
        "try:\n",
        "    hf_token = userdata.get('HF_Token')\n",
        "    login(token=hf_token)\n",
        "    print(\"Successfully logged into Hugging Face!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error logging into Hugging Face: {e}\")\n"
      ],
      "metadata": {
        "id": "QbSA8mZzfLHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your `HF_Token` is correctly stored in your Colab Secrets, you should see the following output:\n",
        "\n",
        "```text\n",
        "Successfully logged into Hugging Face!\n",
        "```\n",
        "\n",
        "Information how to obtain your `HF_Token` and store it in your Colab Secrets has already been provided to you. If you are haven't trouble getting it to work, please see the course Instructor or a TA.  "
      ],
      "metadata": {
        "id": "4kUtVwsAgpPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Hugging Face Libraries\n",
        "\n",
        "Run the next code cell to install the Hugging Face libraries needed for this lesson."
      ],
      "metadata": {
        "id": "P4vC0d23ws-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Hugging Face libraries\n",
        "\n",
        "!pip install -q transformers\n",
        "!pip install -q transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "9nChFrxHrYsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should _not_ see any output."
      ],
      "metadata": {
        "id": "10TTpU1dE-ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have Hugging Face installed, the following sections will demonstrate how to apply Hugging Face to a variety of everyday tasks. After this introduction, the remainder of this module will take a deeper look at several specific NLP tasks applied to Hugging Face."
      ],
      "metadata": {
        "id": "qBvhLL_JtBT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP Sentiment Analysis**\n",
        "\n",
        "**Sentiment analysis** is a subfield of natural language processing (NLP) that focuses on identifying and categorizing the emotional tone or sentiment of a piece of text, such as a review, a social media post, or an article. The task of sentiment analysis involves analyzing the words and phrases in a given text to determine whether they are positive, negative, or neutral in nature, and assigning a numerical score or label to the overall sentiment of the text.\n",
        "\n",
        "Sentiment analysis can be applied to various domains such as social media monitoring, customer feedback analysis, product review analysis, and advertising campaign evaluation. It can help organizations to identify trends and patterns in customer opinion, detect fake reviews, and optimize their marketing strategies by understanding the emotions of their target audience.\n",
        "\n",
        "### What is sentiment analysis?\n",
        "\n",
        "Sentiment analysis is a subfield of natural language processing (NLP) that focuses on identifying and categorizing the emotional tone or sentiment of a piece of text, such as a review, a social media post, or an article. The task of sentiment analysis involves analyzing the words and phrases in a given text to determine whether they are positive, negative, or neutral in nature, and assigning a numerical score or label to the overall sentiment of the text.\n",
        "\n",
        "Sentiment analysis can be applied to various domains such as social media monitoring, customer feedback analysis, product review analysis, and advertising campaign evaluation. It can help organizations to identify trends and patterns in customer opinion, detect fake reviews, and optimize their marketing strategies by understanding the emotions of their target audience.\n",
        "\n",
        "The process of sentiment analysis typically involves several steps, including:\n",
        "\n",
        "1. Text Preprocessing: This step involves cleaning and normalizing the text data to prepare it for analysis. This may include removing stop words, punctuation, and converting all text to lowercase.\n",
        "2. Tokenization: This step involves breaking down the text into smaller units called tokens, which can be individual words or phrases.\n",
        "3. Sentiment Detection: This step involves analyzing the sentiment of each token in the text using techniques such as machine learning, deep learning, or rule-based approaches.\n",
        "4. Aggregation: This step involves combining the sentiment scores of all tokens to obtain the overall sentiment score of the text.\n",
        "\n",
        "Sentiment analysis can be performed using various techniques such as:\n",
        "\n",
        "1. **Rule-Based Approach:** This approach involves defining a set of rules to classify words or phrases as positive, negative, or neutral based on their meanings and context.\n",
        "2. **Machine Learning:** This approach involves training a machine learning model on a dataset of labeled text to learn the patterns and relationships between words and sentiment.\n",
        "3. **Deep Learning:** This approach involves using deep neural networks to analyze the complex patterns in text data and learn the relationships between words, phrases, and sentiment.\n",
        "\n",
        "Sentiment analysis uses natural language processing, text analysis, computational linguistics, and biometrics to identify the tone of written text. Passages of written text can be into simple binary states of positive or negative tone. More advanced sentiment analysis might classify text into additional categories: sadness, joy, love, anger, fear, or surprise.\n"
      ],
      "metadata": {
        "id": "HYqyqMEWtFct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1 - Step 1: Load Text for Sentiment Analyis\n",
        "\n",
        "To demonstrate sentiment analysis, we begin by loading Shakespeare's 18th sonnet:\n",
        "\n",
        "> Shall I compare thee to a summer's day?  \n",
        "> Thou art more lovely and more temperate:  \n",
        "> Rough winds do shake the darling buds of May,  \n",
        "> And summer's lease hath all too short a date:  \n",
        "> Sometime too hot the eye of heaven shines,  \n",
        "> And often is his gold complexion dimm'd;  \n",
        "> And every fair from fair sometimes declines,  \n",
        "> By chance or nature's changing course untrimm'd;  \n",
        "> But thy eternal summer shall not fade  \n",
        "> Nor lose possession of that fair thou owest;  \n",
        "> Nor shall Death brag thou wander'st in his shade,  \n",
        "> When in eternal lines to time thou growest.\n",
        "\n",
        "What do you think Shakespear's sentiment was when he wrote this sonnet? In particular, is Shakespear being **positive** or **negative**?\n",
        "\n",
        "Let's find out using **sentiment analysis**."
      ],
      "metadata": {
        "id": "Mm-Lhvv5Igr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Step 1 we read the text file \"sonnet_18.txt\" from the course file server using the `urlopen()` command. The text is stored in a variable called `eg_text_1` (\"Example text 1\")."
      ],
      "metadata": {
        "id": "Tb1oZHikGgw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1 - Step 1: Load text\n",
        "\n",
        "from urllib.request import urlopen\n",
        "\n",
        "# Read sample text, a poem\n",
        "URL = \"https://biologicslab.co/BIO1173/data/sonnet_18.txt\"\n",
        "f = urlopen(URL)\n",
        "eg_text_1 = f.read().decode(\"utf-8\")\n",
        "\n",
        "# Print out text\n",
        "print(eg_text_1)"
      ],
      "metadata": {
        "id": "XcLwqoeWtLS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct your should see the following output\n",
        "\n",
        "```text\n",
        "Shall I compare thee to a summer's day?\n",
        "Thou art more lovely and more temperate:\n",
        "Rough winds do shake the darling buds of May,\n",
        "And summer's lease hath all too short a date:\n",
        "Sometime too hot the eye of heaven shines,\n",
        "And often is his gold complexion dimm'd;\n",
        "And every fair from fair sometimes declines,\n",
        "By chance or nature's changing course untrimm'd;\n",
        "But thy eternal summer shall not fade\n",
        "Nor lose possession of that fair thou owest;\n",
        "Nor shall Death brag thou wander'st in his shade,\n",
        "When in eternal lines to time thou growest.\n",
        "```\n",
        "\n",
        "In the next step, we will use this poem by William Shakespear for our sentiment analysis."
      ],
      "metadata": {
        "id": "5obxgSSN6NLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, you have to preprocess text into embeddings or other vector forms before presentation to a neural network. Hugging Face provides a pipeline that simplifies this process greatly. The pipeline allows you to pass regular Python strings to the transformers and return standard Python values.\n",
        "\n",
        "We begin by loading a text-classification model. We can specify which model to use, by passing the model parameter, such as:\n",
        "\n",
        "```\n",
        "pipe = pipeline(model=\"roberta-large-mnli\")\n",
        "```\n",
        "\n",
        "**RoBERTa-large-MNLI** is a fine-tuned version of the RoBERTa large model, which is a transformer-based language model developed by Facebook AI. RoBERTa itself is an optimized version of BERT (Bidirectional Encoder Representations from Transformers) and is trained on a large corpus of English text using a masked language modeling (MLM) objective.\n",
        "\n",
        "The code in Example 1 - Step 2 loads a model pipeline and a model for sentiment analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "mah5UesgtQRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1 - Step 2: Load Model Pipeline\n",
        "\n",
        "This code in the cell below uses the `transformers library` to create a pipeline for natural language inference (NLI) tasks. The pipeline function takes a model name as an argument, which in this case is \"roberta-large-mnli\". This specific model is a variant of the `RoBERTa model` that has been pre-trained on a large dataset of text and can perform NLI tasks such as question answering or natural language inference.\n",
        "\n",
        "The pipeline function returns an instance of a Pipeline class from the transformers library, which is a high-level API for interacting with NLP models. The returned pipeline object has methods for various NLI tasks such as question answering, natural language inference, and text classification.\n",
        "\n",
        "In this specific case, the code is creating a pipeline for natural language inference tasks using the \"roberta-large-mnli\" model. This means that it can be used to perform NLI tasks such as determining the meaning of a sentence or question given some context. The Pipeline object returned by the pipeline function will have methods for performing these tasks, such as predict and score, which can be used to make predictions on new input data and evaluate the performance of the model."
      ],
      "metadata": {
        "id": "yK4WlOW8JWSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1 - Step 2: Load model pipeline\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import pipeline, logging\n",
        "\n",
        "# Suppress the warning (optional)\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# Specify the model for the pipeline\n",
        "model_name = \"roberta-large-mnli\"\n",
        "\n",
        "# Create classification pipeline\n",
        "classifier = pipeline(\"text-classification\", model=model_name)\n",
        "\n",
        "# Verify the pipeline\n",
        "print(classifier)\n"
      ],
      "metadata": {
        "id": "b0U82wm0ivZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "```text\n",
        "<transformers.pipelines.text_classification.TextClassificationPipeline object at 0x798446116fc0>\n",
        "```"
      ],
      "metadata": {
        "id": "TZXVtJNBJrK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now display the sentiment analysis results as a `Pandas` DataFrame.\n"
      ],
      "metadata": {
        "id": "KSs2hJvjtax8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1 - Step 3: Run Sentiment Analysis on Text\n",
        "\n",
        "We can now display the sentiment analysis results with a Pandas dataframe."
      ],
      "metadata": {
        "id": "gpzyqVCYLZni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1 - Step 3: Run sentiment analysis on text\n",
        "\n",
        "# Create variable to hold sentiment analysis\n",
        "sentiment_outputs = classifier(eg_text_1)\n",
        "\n",
        "# Display output in a Pandas DataFrame\n",
        "pd.DataFrame(sentiment_outputs)\n"
      ],
      "metadata": {
        "id": "iKQqnKlxtcNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image03F.png)"
      ],
      "metadata": {
        "id": "MDNJJ40MR4Qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, our sentiment analysis considered the tone of Sonnet 18 as being `NEUTRAL` with a `score` of 0.68.\n",
        "\n",
        "Shakespeare's Sonnet 18 is generally considered to have positive and admiring sentiment. The sonnet praises the subject, comparing them to a summer's day and highlighting their eternal beauty and the impermanence of natural beauty.\n",
        "\n",
        "So why did we get only a `NEUTRAL` rating?\n",
        "\n",
        "Sentiment analysis models like **`RoBERTa-large-MNLI`** work by analyzing the text and classifying it based on the presence of positive, negative, or neutral sentiments. Shakespeare's `Sonnet 18` (\"Shall I compare thee to a summer's day?\") is a complex and nuanced piece of literature, which can make it challenging for an AI model to accurately classify its sentiment.\n",
        "\n",
        "Several factors could have contributed to the neutral sentiment classification:\n",
        "\n",
        "1. **Language and Style:** Shakespeare's language and poetic style are intricate, with a mix of positive imagery and more neutral or descriptive language. This complexity might have led the model to classify the overall sentiment as neutral.\n",
        "\n",
        "2. **Ambiguity:** The sonnet contains elements of praise and admiration, but it also discusses the transience of beauty and the passage of time, which might have contributed to a more balanced or neutral sentiment score.\n",
        "\n",
        "3. **Contextual Understanding:** AI models might struggle with understanding the full context and emotional depth of the text. They might miss subtleties that human readers would easily pick up on.\n",
        "\n",
        "The `0.6795 score` indicates that the model is fairly confident in its neutral classification, but it doesn't mean the text lacks positive sentiment. It just means that the model detected a more balanced mix of sentiments overall."
      ],
      "metadata": {
        "id": "O9fRS1Dltjpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1 - Step 1: Load Text for Sentiment Analyis**\n",
        "\n",
        "For **Exercise 1**, use Shakespear's Sonnet 66.\n",
        "\n",
        "**Sonnet 66**\n",
        "\n",
        "> Tired with all these, for restful death I cry:  \n",
        "> As, to behold desert a beggar born,  \n",
        "> And needy nothing trimmed in jollity,  \n",
        "> And purest faith unhappily forsworn,  \n",
        "> And gilded honor shamefully misplaced,  \n",
        "> And maiden virtue rudely strumpeted,  \n",
        "> And right perfection wrongfully disgraced,  \n",
        "> And strength by limping sway disablèd,  \n",
        "> And art made tongue-tied by authority,  \n",
        "> And folly, doctor-like, controlling skill,   \n",
        "> And simple truth miscalled simplicity,  \n",
        "> And captive good attending captain ill.  \n",
        ">   Tired with all these, from these would I be gone,  \n",
        ">   Save that, to die, I leave my love alone.  \n",
        "\n",
        "\n",
        "Here is the `URL` to download this poem:\n",
        "\n",
        "```text\n",
        "URL = \"https://biologicslab.co/BIO1173/data/sonnet_66.txt\"\n",
        "```\n",
        "\n",
        "Call your text **`ex_text_1`** and print out `ex_test_1` at the end of the code cell.\n"
      ],
      "metadata": {
        "id": "Lx3GWspDz-FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 1 - Step 1 here\n",
        "\n"
      ],
      "metadata": {
        "id": "WnFCZoeEz-FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct your should see the following output\n",
        "\n",
        "```text\n",
        "Tired with all these, for restful death I cry:\n",
        "As, to behold desert a beggar born,\n",
        "And needy nothing trimmed in jollity,\n",
        "And purest faith unhappily forsworn,\n",
        "And gilded honor shamefully misplaced,\n",
        "And maiden virtue rudely strumpeted,\n",
        "And right perfection wrongfully disgraced,\n",
        "And strength by limping sway disablèd,\n",
        "And art made tongue-tied by authority,\n",
        "And folly, doctor-like, controlling skill,\n",
        "And simple truth miscalled simplicity,\n",
        "And captive good attending captain ill.\n",
        " Tired with all these, from these would I be gone,\n",
        " Save that, to die, I leave my love alone.\n",
        " ```"
      ],
      "metadata": {
        "id": "j-e53kar6_0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1 - Step 2: Load Model Pipeline**\n",
        "\n",
        "In the cell below create the pipeline for your sentiment analysis. You can reuse the code in Example 1 - Step 2 with the following modification. Instead of using the `\"roberta-large-mnli\"` model, change your model to the following:\n",
        "\n",
        "```text\n",
        "\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "```\n",
        "\n",
        "The **`distilbert-base-uncased-finetuned-sst-2-english`** model is a lightweight, 66 M‑parameter transformer that was distilled from BERT‑base and fine‑tuned on the Stanford Sentiment Treebank (SST‑2) for binary sentiment classification. Using an uncased WordPiece tokenizer and a 512‑token limit, the model maps input text to a pair of logits (positive/negative) through a simple linear head on the [CLS] token; applying a softmax gives the sentiment probability. It achieves roughly 93 % accuracy on SST‑2, matching full BERT‑base while running about twice as fast and using half the memory, making it ideal for quick sentiment inference on English text in production settings."
      ],
      "metadata": {
        "id": "mhpsgipYz-FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 1 - Step 2 here\n",
        "\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "MlGTY7_A_PAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image01F.png)"
      ],
      "metadata": {
        "id": "JIPcEWZeQleg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1 - Step 3: Run Sentiment Analysis on Text**\n",
        "\n",
        "In the cell below write the code to run and display the sentiment analysis on your **`ex_text_1`**."
      ],
      "metadata": {
        "id": "5o9W8dU2z-FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 1 - Step 3 here\n",
        "\n"
      ],
      "metadata": {
        "id": "a_TMdprsz-FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image04G.png)"
      ],
      "metadata": {
        "id": "stcQ0NbtVAeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shakespeare's Sonnet 66 indeed carries a much darker tone compared to Sonnet 18. Here are a few reasons why the sentiment analysis model might have given it a strong negative sentiment classification:\n",
        "\n",
        "1. **Tone and Themes:** Sonnet 66 delves into themes of despair, disillusionment, and a profound sense of weariness with the world's injustices. The recurring motifs of frustration and longing for rest likely contributed significantly to the negative sentiment score.\n",
        "\n",
        "2. **Language and Imagery:** The sonnet is filled with negative imagery and phrases expressing dissatisfaction and lamentation. Such language naturally skews towards a negative sentiment classification by the model.\n",
        "\n",
        "3. **Emotional Weight:** The emotional heaviness and the poet’s voice reflecting societal corruption and personal sorrow might resonate strongly with the AI model’s parameters for negative sentiment.\n",
        "\n",
        "The score of `0.995` indicates an almost complete certainty by the model that the sentiment is negative, which aligns well with the sonnet’s content and tone."
      ],
      "metadata": {
        "id": "59yGe0_gzrlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NLP Entity Tagging**\n",
        "\n",
        "**Entity tagging**, also known as named entity recognition (NER), is a process in natural language processing (NLP) where entities such as names of people, organizations, locations, dates, and other specific items are identified and classified within a text. Here’s how it works:\n",
        "\n",
        "1. **Identification:** The model scans the text to find mentions of entities. For example, in the sentence \"Microsoft was founded by Bill Gates in 1975,\" the entities are \"Microsoft,\" \"Bill Gates,\" and \"1975.\"\n",
        "\n",
        "2. **Classification:** Once identified, the entities are classified into predefined categories, such as:\n",
        "\n",
        "- **Person:** Names of individuals (e.g., \"Bill Gates\")\n",
        "\n",
        "- **Organization:** Names of companies, institutions, etc. (e.g., \"Microsoft\")\n",
        "\n",
        "- **Location:** Names of places (e.g., \"Seattle\")\n",
        "\n",
        "- **Date/Time:** Specific dates or times (e.g., \"1975\")\n",
        "\n",
        "- **Others:** Such as events, quantities, monetary values, etc.\n",
        "\n",
        "Entity tagging is widely used in various applications like information extraction, search engines, and enhancing the accuracy of machine translation. It helps in structuring unstructured text data, making it easier to analyze and extract meaningful insights.\n",
        "\n",
        "Entity tagging is the process that takes source text and finds parts of that text that represent entities, such as one of the following:\n",
        "\n",
        "* Location (LOC)\n",
        "* Organizations (ORG)\n",
        "* Person (PER)\n",
        "* Miscellaneous (MISC)\n",
        "\n",
        "The code in Example 2 requests a \"named entity recognizer\" (ner) and processes the specified text."
      ],
      "metadata": {
        "id": "8sUPYLZktncz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2 - Step 1: Entity Tagging\n",
        "\n",
        "The code in the cell below creates a variable, `eg_text_2` with the name of a famous molecular biologist, `James Watson` in the United States."
      ],
      "metadata": {
        "id": "8xs1j0xLZjV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - Step 1: Entity tagging\n",
        "\n",
        "# Specify text\n",
        "eg_text_2 = \"James Watson was a molecular biologist who lived in the United States.\"\n",
        "\n",
        "# Create one pipeline instance for each task\n",
        "classifier = pipeline(\"text-classification\", model=\"roberta-large-mnli\")\n",
        "ner_tagger   = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
        "\n",
        "# Classification\n",
        "print(classifier(eg_text_2))     # MNLI style entailment / contradiction / neutral\n",
        "\n",
        "# NER\n",
        "print(ner_tagger(eg_text_2))\n"
      ],
      "metadata": {
        "id": "ANvzEcwp-Lot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image02G.png)"
      ],
      "metadata": {
        "id": "y6Rupj35XQi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2 - Step 2: Review the Results\n",
        "\n",
        "The code in the next cell let us view the results stored in the `Pandas` DataFrame.  As you can see in the output, the person (`PER`) is `James Watson` and the location (`LOC`) is the `United States`."
      ],
      "metadata": {
        "id": "mPxC6XUets6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - Step 2: Review results\n",
        "\n",
        "# Define outputs\n",
        "outputs = ner_tagger(eg_text_2)\n",
        "\n",
        "# Display Output DataFrame\n",
        "pd.DataFrame(outputs)\n"
      ],
      "metadata": {
        "id": "WjCl_Ak2twgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image03G.png)"
      ],
      "metadata": {
        "id": "pxspeNp4YEZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your entity tagging pipeline has successfully identified and classified \"James Watson\" as a person and \"United States\" as a location with very high confidence."
      ],
      "metadata": {
        "id": "ddJJCnyuZbm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2 - Step 1: Entity Tagging**\n",
        "\n",
        "In the cell below create a variable, `ex_text_2` with the name of another famous molecular biologist, `Francis Crick` in the `United Kingdom`."
      ],
      "metadata": {
        "id": "bYxKAJB9aGAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 2 - Step 1 here\n",
        "\n"
      ],
      "metadata": {
        "id": "3Ao9ttxkaGAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "```text\n",
        "[{'label': 'NEUTRAL', 'score': 0.6580846905708313}]\n",
        "[{'entity_group': 'PER', 'score': np.float32(0.99934936), 'word': 'Francis Crick', 'start': 0, 'end': 13}, {'entity_group': 'LOC', 'score': np.float32(0.9994767), 'word': 'United Kingdom', 'start': 57, 'end': 71}]\n",
        "```"
      ],
      "metadata": {
        "id": "nF-xVBgoaGAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2 - Step 2: Review the Results**\n",
        "\n",
        "In the cell below write the code to define and review the results of your **`ex_text_2`**."
      ],
      "metadata": {
        "id": "_2C0y73aaGAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 2 - Step 2: here\n"
      ],
      "metadata": {
        "id": "wCBjXGXdaGAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image05G.png)"
      ],
      "metadata": {
        "id": "WOkmwOTYaGAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your entity tagging pipeline has successfully identified and classified \"Francis Crick\" as a person and \"United Kingdom\" as a location with very high confidence."
      ],
      "metadata": {
        "id": "U8uPVF8CaGAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NLP Question Answering**\n",
        "\n",
        "**Question Answering (QA)** is a powerful NLP task that involves providing precise answers to questions based on a given reference text. This capability is incredibly useful in various applications, such as information retrieval, and educational tools.\n",
        "\n",
        "Here's a quick rundown of how QA works:\n",
        "\n",
        "1. **Reference Text:** A passage or document from which the answer can be extracted.\n",
        "\n",
        "2. **Question:** A specific query related to the reference text.\n",
        "\n",
        "3. **Answer Extraction:** The NLP model processes the reference text to find the exact segment that answers the question.\n",
        "\n",
        "#### **Use Cases for a Computational Biologist**\n",
        "\n",
        "For a computational biologist, “QA analysis” usually refers to **question‑answering** systems that can interrogate large biological data sets, literature corpora, and simulation outputs.  Below are practical ways the technology can be applied in a research or industrial setting.\n",
        "\n",
        "| Use Case | What the QA system does | Typical inputs | Typical outputs | Why it matters |\n",
        "|----------|------------------------|----------------|-----------------|----------------|\n",
        "| **Literature mining & summarization** | Reads PubMed, bioRxiv, and review articles to answer specific biological questions (e.g., “Which genes are co‑expressed with *TP53* in breast cancer?”). | Natural‑language query + optional PMID set | Short answer, evidence sentences, citation list | Speeds up hypothesis generation and keeps investigators up‑to‑date. |\n",
        "| **Protocol & pipeline verification** | Checks whether computational workflows (e.g., variant‑calling pipelines) meet best‑practice standards or regulatory requirements. | Pipeline description, code, test logs | Pass/fail verdict, compliance report | Helps avoid costly downstream errors and accelerates reproducibility. |\n",
        "| **Clinical data interrogation** | Answers clinical questions from electronic health records or multi‑omics datasets (“What is the probability that a patient with X mutation will respond to drug Y?”). | Structured patient data, genomic profiles | Risk score, confidence interval, relevant literature | Supports precision‑medicine decisions. |\n",
        "| **Drug‑target & repurposing discovery** | Queries databases (DrugBank, ChEMBL) to find potential new targets or off‑target effects. | Chemical structure or name, target protein | List of candidate targets, predicted affinity scores | Narrows experimental screening lists. |\n",
        "| **Ontology & annotation assistance** | Maps free‑text notes or sequence motifs to controlled vocabularies (GO, MeSH). | Raw text, protein FASTA | Curated annotations, suggested terms | Improves data standardization for downstream analysis. |\n",
        "| **Model validation & debugging** | Interrogates machine‑learning models to expose decision pathways (“Why did the model predict a splice‑site mutation is benign?”). | Model, input features, intermediate activations | Explanatory text, feature importance, counter‑factuals | Enhances trust and aids model refinement. |\n",
        "| **Educational & training support** | Answers students’ queries during bioinformatics courses (e.g., “Explain the difference between UTRs and introns”). | Student question | Concise, citation‑backed answer | Lowers the learning curve for new trainees. |\n",
        "\n",
        "#### **How it typically works**\n",
        "1. **Indexing** – Textual resources (papers, databases, logs) are pre‑processed and stored in a vector‑search index.  \n",
        "2. **Query processing** – The user’s natural‑language question is encoded into a vector and matched against the index.  \n",
        "3. **Answer generation** – The system extracts the most relevant passages, optionally runs a language‑model head to paraphrase or synthesize an answer, and tags the answer with evidence citations.  \n",
        "4. **Human‑in‑the‑loop** – Domain experts review the answer; feedback is fed back into the model for continual improvement.\n",
        "\n",
        "By integrating QA analysis into the computational biology workflow, researchers can dramatically reduce the time spent on literature reviews, data curation, and pipeline troubleshooting, allowing more focus on discovery and hypothesis testing.\n"
      ],
      "metadata": {
        "id": "d5rdGwmvt04K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build QA Pipeline\n",
        "\n",
        "The code in the cell below builds a **Questioning Answering (QA)** pipeline."
      ],
      "metadata": {
        "id": "QghFY-IXLuIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build pipeline\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Build the question‑answering pipeline (GPU is auto‑selected if available)\n",
        "qa_pipe = pipeline(\n",
        "    task=\"question-answering\",\n",
        "    model=\"distilbert-base-uncased-distilled-squad\",  # any QA‑ready model works\n",
        ")\n",
        "\n",
        "print(\" QA pipeline is ready!\")\n"
      ],
      "metadata": {
        "id": "r6cIl19QLu0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image06G.png)"
      ],
      "metadata": {
        "id": "bb2PCSKy5A3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3: Generate QA Result\n",
        "\n",
        "The code in the cell below uses our `QA Pipeline` to ask the question\n",
        "\n",
        "```text\n",
        "\"what shall fade\"\n",
        "```\n",
        "The `context` of this question is Shakespear's `Sonnet 18` stored in `eg_text_1` that we created above in `Example 1`."
      ],
      "metadata": {
        "id": "Xz5wnIkW0iod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: Generate QA result\n",
        "\n",
        "# Define the context and the question you want answered\n",
        "context = eg_text_1  # Sonnet 18 from Example 1\n",
        "\n",
        "# Define the question\n",
        "question = \"what shall fade\"\n",
        "\n",
        "# Run the QA model\n",
        "result = qa_pipe(question=question, context=context)\n",
        "\n",
        "# Pretty‑print the answer\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer  : {result['answer']}\")\n",
        "print(f\"Score   : {result['score']:.4f}\")\n",
        "print(f\"Start   : {result['start']}  End: {result['end']}\")\n"
      ],
      "metadata": {
        "id": "d6ofbDKO0jQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "```text\n",
        "Question: what shall fade\n",
        "Answer  : eternal summer\n",
        "Score   : 0.3792\n",
        "Start   : 367  End: 381\n",
        "```\n",
        "\n",
        "With a `Score = 0.38`, Hugging Face `distilbert-base-uncased-distilled-squad` model is not especially confident that `external summer` is the correct answer to our question `what will fade` in Shakespear's Sonnet 18."
      ],
      "metadata": {
        "id": "b8H3VTUx3paM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3: Generate QA Result**\n",
        "\n",
        "The following is a famous quotation by the molecular geneticist James Watson as the forward to _Discovering the Brain_ by Sandra Ackerman.\n",
        "\n",
        "```type\n",
        "\"The brain is the last and grandest biological frontier,\"\n",
        "\"the most complex thing we have yet discovered in our universe.\"\n",
        "\"It contains hundreds of billions of cells interlinked through \"\n",
        "\"trillions of connections. The brain boggles the mind.\"\n",
        "```\n",
        "\n",
        "For **Exercise 3** you are to use Watson's quote as the `context`. The easiest way to do this is to `copy-and-paste` the quotation into space between the two parantheses as follows:\n",
        "\n",
        "```text\n",
        "Watson_quotation = (\n",
        "\"The brain is the last and grandest biological frontier,\"\n",
        "\"the most complex thing we have yet discovered in our universe.\"\n",
        "\"It contains hundreds of billions of cells interlinked through \"\n",
        "\"trillions of connections. The brain boggles the mind.\"\n",
        ")  \n",
        "```\n",
        "You will need to assign the `context` to your `Watson_quotation using this code:\n",
        "\n",
        "```text\n",
        "# Assign quotation to content\n",
        "content=Watson_quotation\n",
        "```\n",
        "Finally, for your question, use this text:\n",
        "\n",
        "```type\n",
        "\"how many connections in the brain\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "jb7TZNa5BN33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 here\n",
        "\n"
      ],
      "metadata": {
        "id": "ngvBTs726nxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "```text\n",
        "Question: how many connections in the brain\n",
        "Answer  : trillions\n",
        "Score   : 0.5811\n",
        "Start   : 179  End: 188\n",
        "```\n"
      ],
      "metadata": {
        "id": "PpU_4gq26nxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------\n",
        "\n",
        "### **What does the `score` field mean in Hugging Face QA pipelines?**\n",
        "\n",
        "When a question‑answering model returns a span, it also returns a\n",
        "`score`.  The score is **not a hard probability** of correctness, but\n",
        "the model’s internal confidence that the chosen start‑and‑end tokens\n",
        "are the right answer.\n",
        "\n",
        "#### **How it is computed**\n",
        "1. The model outputs *start* and *end* logits for every token in the\n",
        "   context.  \n",
        "2. A softmax is applied to each set of logits → probabilities that sum\n",
        "   to 1.  \n",
        "3. The pipeline picks the span \\([s, e]\\) that maximises  \n",
        "   \\( P_{\\text{start}}(s) \\times P_{\\text{end}}(e) \\).  \n",
        "   This product is the `score`.\n",
        "\n",
        "#### **Interpreting a score**\n",
        "| Score range | Rough meaning | What to do |\n",
        "|-------------|---------------|------------|\n",
        "| < 0.3 | Very low confidence | Treat the answer as unreliable; re‑phrase the question or add more context. |\n",
        "| ≈ 0.5 | Moderate confidence | The answer is plausible but not guaranteed; double‑check if accuracy matters. |\n",
        "| > 0.8 | High confidence | The answer is likely correct; you can use it as is. |\n",
        "\n",
        "> **Caveat** – Hugging Face models are *not* calibrated to produce true\n",
        "> probabilities.  Use the score to **rank or filter** results, not as an\n",
        "> absolute correctness metric.\n",
        "\n",
        "-------------------------------\n"
      ],
      "metadata": {
        "id": "sfDLm-qyM716"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NLP Language Translation**\n",
        "\n",
        "**Language Translation** is a fascinating and practical application of natural language processing (NLP). It involves converting text from one language into another while preserving the original meaning, context, and nuances.\n",
        "\n",
        "Hugging Face provides powerful pre-trained models for language translation. Here is a list of the popular models:\n",
        "\n",
        "#### **List of Translators Used by Hugging Face**\n",
        "\n",
        "Hugging Face offers a variety of translation models for different language pairs. Here are some popular ones:\n",
        "\n",
        "1. **MarianMT Models**: These models support translation between multiple language pairs. For example:\n",
        "   - `Helsinki-NLP/opus-mt-en-de`: English to German\n",
        "   - `Helsinki-NLP/opus-mt-en-fr`: English to French\n",
        "   - `Helsinki-NLP/opus-mt-en-es`: English to Spanish\n",
        "\n",
        "2. **T5 Models**: These models can be fine-tuned for translation tasks. For example:\n",
        "   - `t5-small`: A smaller version of the T5 model that can be fine-tuned for translation.\n",
        "   - `t5-large`: A larger version of the T5 model with more parameters for better performance.\n",
        "\n",
        "3. **mBART Models**: These models are designed for multilingual translation tasks. For example:\n",
        "   - `facebook/mbart-large-50-many-to-many-mmt`: A multilingual model that supports translation between 50 languages.\n",
        "\n",
        "4. **M2M100 Models**: These models are designed for many-to-many translation tasks. For example:\n",
        "   - `facebook/m2m100_418M`: A model that supports translation between 100 languages.\n",
        "\n",
        "You can find more translation models and explore their capabilities on the [Hugging Face Models page](https://huggingface.co/models?search=translate).\n"
      ],
      "metadata": {
        "id": "Kq2yoUGGuD1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install `sacremoses` package\n",
        "\n",
        "Before we can start translating, we need to install the `sacremoses` package.\n",
        "The `sacremoses` package is a Python port of the `Moses tokenizer`, `truecaser`, and `normalizer`. It provides tools for text preprocessing, which are essential for various natural language processing (NLP) tasks. Here are some key features of sacremoses:\n",
        "\n",
        "**Tokenizer:** The Moses tokenizer splits text into tokens (words, punctuation, etc.) while handling special characters and preserving the original meaning. For example, it can tokenize sentences with unusual symbols and punctuation.\n",
        "\n",
        "**Detokenizer:** The Moses detokenizer reverses the tokenization process, converting tokens back into a coherent sentence.\n",
        "\n",
        "**Truecaser:** The Moses truecaser adjusts the casing of words in a text to match typical usage patterns. It can be trained on a large corpus to learn the correct casing for words.\n",
        "\n",
        "Google Colab doesn't normally include the `sacremoses` package but you can add it by running the following code cell."
      ],
      "metadata": {
        "id": "82F8ZG8ej7Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install sacremoses package\n",
        "\n",
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "tiKsGDwGgsit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image08G.png)"
      ],
      "metadata": {
        "id": "6rEo499NAT85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 4 - Step 1: Select Translator\n",
        "\n",
        "In this example we will use the `\"Helsinki-NLP/opus-mt-en-de\"` model. The **`Helsinki-NLP/opus-mt-en-de`** model is a powerful tool for translating text from English to German. Developed by the Language Technology Research Group at the University of Helsinki, this model is part of the `OPUS-MT` project, which provides open translation services for various language pairs"
      ],
      "metadata": {
        "id": "rDkYgglxf8B_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4 - Step 1: Setup translator\n",
        "\n",
        "# Select translator\n",
        "translator = pipeline(\"translation_en_to_de\",\n",
        "                      model=\"Helsinki-NLP/opus-mt-en-de\")\n"
      ],
      "metadata": {
        "id": "7JROV9iruGq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image09G.png)"
      ],
      "metadata": {
        "id": "1Dk7gaStAlni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 4 - Step 2: Translate Text\n",
        "\n",
        "The following code translates Watson's quotation (`Watson_quotation`) that was used in **Exercise 3** into German.\n"
      ],
      "metadata": {
        "id": "fmWyexSduQf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4 - Step 2 Translate text\n",
        "\n",
        "import textwrap\n",
        "from transformers import pipeline\n",
        "\n",
        "# Normalize the text by removing extra spaces\n",
        "normalized_text = ' '.join(Watson_quotation.split())\n",
        "\n",
        "# Print the normalized text with proper wrapping\n",
        "wrapped_text = textwrap.fill(normalized_text, width=50)\n",
        "print(wrapped_text)\n",
        "\n",
        "# Print spacer\n",
        "print(\"\\n\")\n",
        "\n",
        "# Perform translation\n",
        "outputs = translator(Watson_quotation, clean_up_tokenization_spaces=True, min_length=100)\n",
        "\n",
        "# Get the translated text\n",
        "translated_text = outputs[0]['translation_text']\n",
        "\n",
        "# Remove excessive dots (e.g., ellipses)\n",
        "cleaned_text = translated_text.rstrip('.')\n",
        "\n",
        "# Break the cleaned text into separate lines\n",
        "wrapped_text = textwrap.fill(cleaned_text, width=50)\n",
        "\n",
        "print(wrapped_text)\n"
      ],
      "metadata": {
        "id": "WKg_Ivc4iZ4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "```text\n",
        "The brain is the last and grandest biological\n",
        "frontier,the most complex thing we have yet\n",
        "discovered in our universe.It contains hundreds of\n",
        "billions of cells interlinked through trillions of\n",
        "connections. The brain boggles the mind.\n",
        "\n",
        "\n",
        "Das Gehirn ist die letzte und großartigste\n",
        "biologische Grenze, die komplexeste Sache, die wir\n",
        "noch in unserem Universum entdeckt haben.Es\n",
        "enthält Hunderte von Milliarden Zellen, die durch\n",
        "Billionen von Verbindungen miteinander verbunden\n",
        "sind.Das Gehirn verdreht den Geist.Das Gehirn ist\n",
        "in der Lage, das Gehirn zu verschmelzen, und das\n",
        "Gehirn ist in der Lage, das Gehirn zu\n",
        "verschmelzen, indem es seine Zellen und Zellen\n",
        "miteinander verschränkt, indem es seine Zellen\n",
        "ineinander verschränkt\n",
        "```\n",
        "#### **Applications of Text Translation in Biomedical Contexts**\n",
        "\n",
        "The ability to translate text into different languages offers significant value in biomedical research, healthcare, and public health. Here are some key applications:\n",
        "\n",
        "##### 1. **Global Research Collaboration**\n",
        "- Enables researchers worldwide to access scientific literature published in different languages\n",
        "- Facilitates collaboration between international research teams\n",
        "- Helps disseminate findings from non-English speaking research institutions\n",
        "\n",
        "##### 2. **Clinical Documentation**\n",
        "- Translates patient records for healthcare providers treating international patients\n",
        "- Supports medical tourism where patients seek treatment in foreign countries\n",
        "- Assists in transferring medical histories across borders\n",
        "\n",
        "##### 3. **Public Health Communication**\n",
        "- Translates health advisories and guidelines during disease outbreaks (e.g., COVID-19)\n",
        "- Makes vaccination information accessible to diverse populations\n",
        "- Helps communicate drug safety warnings globally\n",
        "\n",
        "##### 4. **Drug Development & Regulatory Compliance**\n",
        "- Translates clinical trial documentation for multinational studies\n",
        "- Supports regulatory submissions to agencies in different countries (FDA, EMA, PMDA)\n",
        "- Enables analysis of adverse event reports from global pharmacovigilance databases\n",
        "\n",
        "##### 5. **Patient Care & Accessibility**\n",
        "- Provides translated discharge instructions and medication guides\n",
        "- Improves informed consent processes for non-native speakers\n",
        "- Supports telemedicine consultations across language barriers\n",
        "\n",
        "##### 6. **Literature Mining & Meta-Analysis**\n",
        "- Allows inclusion of non-English studies in systematic reviews\n",
        "- Reduces language bias in meta-analyses\n",
        "- Expands the evidence base for clinical guidelines\n",
        "\n",
        "---\n",
        "\n",
        "#### ⚠️ **Important Caveat**\n",
        "\n",
        "Note that in your output above, the German translation shows **repetition and degradation** toward the end:\n",
        "\n",
        "> *\"Das Gehirn ist in der Lage, das Gehirn zu verschmelzen...\"* (repeated phrases)\n",
        "\n",
        "This is a common issue with neural machine translation when using the `min_length` parameter, which forces the model to generate more text than the content warrants. For biomedical applications, **accuracy is critical**, so:\n",
        "\n",
        "- Avoid forcing minimum lengths that exceed the natural translation length\n",
        "- Always have translations reviewed by qualified human translators for clinical use\n",
        "- Consider using specialized biomedical translation models for technical content\n",
        "\n"
      ],
      "metadata": {
        "id": "TWMWrvIZjCeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** If you get an error message it might be a consequence of Example 4 using your code from **Exercise 3** above."
      ],
      "metadata": {
        "id": "zDhGR3LTXpwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NLP Summarization**\n",
        "\n",
        "**Summarization** is a key NLP task that involves condensing a longer text into a shorter version while preserving the main ideas and important details. There are two primary types of summarization:\n",
        "\n",
        "1. **Extractive Summarization:** This method involves selecting and extracting key sentences or phrases from the original text. The selected sentences are then combined to form a summary. It's like creating a highlight reel of the text.\n",
        "\n",
        "2. **Abstractive Summarization:** This method involves generating new sentences that capture the essence of the original text. It requires the model to understand the context and rephrase the content in a concise manner. This approach is more challenging but can produce more natural and coherent summaries.\n",
        "\n",
        "Summarization is an NLP task that summarizes a more lengthy text into just a few sentences.\n",
        "\n",
        "#### **Use Cases**\n",
        "\n",
        "**NLP summarization**—both extractive and the more recent abstractive methods powered by transformer architectures such as BERT, T5, and GPT—automatically condenses long documents into concise, coherent overviews while preserving key information. In computational biology, this capability is indispensable for navigating the deluge of biomedical literature and data reports. Researchers employ summarization to generate rapid literature reviews, extract essential findings from high‑throughput genomics, proteomics, and metabolomics papers, and produce concise summaries of experimental protocols or clinical trial outcomes. Additionally, summarization helps distill complex pathway and interaction network descriptions, create short reports of multi‑omics integration results, and aid in hypothesis generation by highlighting novel associations across datasets. By reducing manual curation effort, summarization accelerates discovery pipelines, improves reproducibility, and supports evidence‑based decision‑making in genomics, drug discovery, and personalized medicine."
      ],
      "metadata": {
        "id": "NjEAp1jguJvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup the Text Summarizer\n",
        "\n",
        "Run the code in the next cell to setup the summarizer pipeline."
      ],
      "metadata": {
        "id": "GxKHqQ_0wZE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup summarizer pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")"
      ],
      "metadata": {
        "id": "QZzc0c-pwj4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image10G.png)"
      ],
      "metadata": {
        "id": "jxIMRh_3qQv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 5 - Step 1: Input Text\n",
        "\n",
        "The code in the cell below creates a variable called `eg_text3` that contains the text to be summarized. This text is a discussion of the **CRISPER-Cas9 gene editing technology**."
      ],
      "metadata": {
        "id": "RySRVoR6oo-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 5 - Step 1: Input Text\n",
        "\n",
        "\n",
        "# Input the text to be summarized\n",
        "eg_text3 = \"\"\"\n",
        "CRISPR-Cas9 gene editing technology represents one of the most significant\n",
        "breakthroughs in molecular biology since the discovery of the DNA double helix.\n",
        "This revolutionary tool allows scientists to make precise modifications to the\n",
        "genetic code of virtually any organism, opening unprecedented possibilities\n",
        "for treating genetic diseases, developing new therapies, and advancing our\n",
        "understanding of fundamental biological processes. The technology has transformed\n",
        "biomedical research and holds immense promise for clinical applications.\n",
        "\n",
        "The CRISPR system was originally discovered as a natural defense mechanism in\n",
        "bacteria, where it functions to protect against viral infections by recognizing\n",
        "and destroying foreign genetic material. Scientists Jennifer Doudna and Emmanuelle\n",
        "Charpentier recognized the potential of this system for targeted genome editing\n",
        "and developed it into a versatile laboratory tool, work for which they were\n",
        "awarded the Nobel Prize in Chemistry in 2020. The system consists of two key\n",
        "components: a guide RNA that directs the machinery to the specific DNA sequence\n",
        "of interest, and the Cas9 protein that acts as molecular scissors to cut the\n",
        "DNA at the targeted location.\n",
        "\n",
        "The implications for treating genetic diseases are profound. Conditions caused\n",
        "by single-gene mutations, such as sickle cell disease, cystic fibrosis, and\n",
        "Huntington's disease, are prime candidates for CRISPR-based therapies. In\n",
        "December 2023, the first CRISPR-based treatment received regulatory approval\n",
        "for sickle cell disease and beta-thalassemia, marking a historic milestone in\n",
        "medicine. This therapy works by editing patients' own blood stem cells to\n",
        "produce fetal hemoglobin, which compensates for the defective adult hemoglobin\n",
        "responsible for the disease.\n",
        "\n",
        "Cancer treatment represents another promising application of CRISPR technology.\n",
        "Researchers are using gene editing to enhance CAR-T cell therapy, in which\n",
        "patients' immune cells are modified to recognize and attack cancer cells.\n",
        "CRISPR allows scientists to make multiple genetic modifications simultaneously,\n",
        "improving the persistence and effectiveness of these therapeutic cells while\n",
        "reducing the risk of adverse reactions. Clinical trials are underway for\n",
        "various blood cancers and solid tumors.\n",
        "\n",
        "Beyond direct therapeutic applications, CRISPR has become an indispensable\n",
        "research tool for understanding disease mechanisms. Scientists can create\n",
        "precise disease models by introducing specific mutations into cells or\n",
        "laboratory animals, allowing them to study how genetic changes lead to\n",
        "pathology. High-throughput CRISPR screens enable researchers to systematically\n",
        "knock out genes across the entire genome to identify those essential for\n",
        "particular biological processes or drug responses.\n",
        "\n",
        "The technology continues to evolve rapidly. Base editing and prime editing\n",
        "represent next-generation approaches that can make precise single-letter\n",
        "changes to DNA without creating double-strand breaks, potentially reducing\n",
        "off-target effects and expanding the range of treatable mutations. Researchers\n",
        "are also developing CRISPR systems that target RNA rather than DNA, offering\n",
        "temporary modifications that might be preferable for certain applications.\n",
        "\n",
        "Ethical considerations surrounding CRISPR technology remain subjects of intense\n",
        "debate. The 2018 announcement that a researcher had created gene-edited human\n",
        "embryos that were brought to term sparked international condemnation and renewed\n",
        "calls for strict oversight of germline editing. While somatic cell editing\n",
        "affects only the individual patient, modifications to eggs, sperm, or embryos\n",
        "would be inherited by future generations, raising profound questions about\n",
        "consent, equity, and unintended consequences. Scientific organizations worldwide\n",
        "have called for moratoriums on clinical germline editing until safety and\n",
        "ethical frameworks can be established.\n",
        "\n",
        "Delivery of CRISPR components to target tissues remains a significant technical\n",
        "challenge, particularly for in vivo applications. Viral vectors, lipid\n",
        "nanoparticles, and other delivery systems each have advantages and limitations\n",
        "in terms of efficiency, tissue specificity, and immunogenicity. Overcoming\n",
        "these barriers is essential for expanding CRISPR therapies beyond blood\n",
        "disorders to conditions affecting the brain, heart, and other organs.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "em2NSdN2uIiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should _not_ see any output."
      ],
      "metadata": {
        "id": "-XcJMuSq0364"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 5 - Step 2: Print Summary\n",
        "\n",
        "The following code uses the pipeline created above to summarize `eg_text3` and print out the summary."
      ],
      "metadata": {
        "id": "7jafTxh5uiUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 5 - Step 2: Print output\n",
        "\n",
        "import textwrap\n",
        "from transformers import pipeline\n",
        "\n",
        "# Send text to summarizer\n",
        "outputs = summarizer(eg_text3, max_length=500, min_length=200,\n",
        "                     clean_up_tokenization_spaces=True)\n",
        "\n",
        "# Get the summary text\n",
        "summary_text = outputs[0]['summary_text']\n",
        "\n",
        "# Break the summary into separate lines\n",
        "wrapped_summary = textwrap.fill(summary_text, width=80)\n",
        "\n",
        "# Print the wrapped summary\n",
        "print(wrapped_summary)\n"
      ],
      "metadata": {
        "id": "kKErV4rrsYjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see something _similar_ to the following output:\n",
        "\n",
        "```text\n",
        " CRISPR-Cas9 gene editing technology represents one of the most significant\n",
        "breakthroughs in molecular biology since the discovery of the DNA double helix.\n",
        "The technology has transformed biomedical research and holds immense promise for\n",
        "clinical applications. The implications for treating genetic diseases are\n",
        "profound. Conditions caused by single-gene mutations, such as sickle cell\n",
        "disease, cystic fibrosis, and Huntington's disease, are prime candidates for\n",
        "CRisPR-based therapies. CRISpr has become an indispensable research tool for\n",
        "understanding disease mechanisms. The technology continues to evolve rapidly. It\n",
        "continues to be an indispensable research tool to understand disease mechanisms,\n",
        "especially for in vivo applications. It is also an indispensable tool for\n",
        "scientists to create disease models by introducing specific mutations into cells\n",
        "or animals, allowing them to study how genetic changes lead to pathology. It\n",
        "remains a critical question about the safety and ethical considerations\n",
        "surrounding CRispr technology. The 2018 announcement that a researcher had\n",
        "created gene-edited human\n",
        "```\n",
        "\n",
        "#### **The Value of Text Summarization for Biomedical Professionals**\n",
        "\n",
        "Text summarization using Natural Language Processing (NLP) offers significant benefits for researchers, clinicians, and other professionals working in biomedical fields. Here are the key advantages:\n",
        "\n",
        "##### 1. **Managing Information Overload**\n",
        "- Over 1 million new articles are added to PubMed annually\n",
        "- Biomedical professionals cannot read every relevant publication in full\n",
        "- Automated summarization condenses lengthy papers into digestible key points\n",
        "- Enables researchers to quickly assess whether a full article warrants detailed reading\n",
        "\n",
        "##### 2. **Accelerating Literature Reviews**\n",
        "- Systematic reviews require screening thousands of abstracts and papers\n",
        "- Summarization tools can extract core findings from multiple studies rapidly\n",
        "- Reduces the time needed to identify relevant research for meta-analyses\n",
        "- Helps maintain comprehensive coverage without sacrificing efficiency\n",
        "\n",
        "##### 3. **Clinical Decision Support**\n",
        "- Physicians need quick access to current evidence at the point of care\n",
        "- Summarized clinical guidelines and research findings support faster decision-making\n",
        "- Reduces cognitive load during time-sensitive patient encounters\n",
        "- Helps translate lengthy clinical trial results into actionable insights\n",
        "\n",
        "##### 4. **Drug Discovery & Development**\n",
        "- Pharmaceutical researchers must review vast patent and scientific literature\n",
        "- Summarization assists in competitive intelligence and prior art searches\n",
        "- Condenses regulatory documents and clinical trial reports\n",
        "- Speeds up identification of potential drug targets and safety signals\n",
        "\n",
        "##### 5. **Grant Writing & Reporting**\n",
        "- Researchers can quickly synthesize background literature for proposals\n",
        "- Simplifies creation of progress reports and executive summaries\n",
        "- Helps distill complex findings for non-specialist audiences and funding agencies\n",
        "\n",
        "##### 6. **Medical Education**\n",
        "- Students can grasp essential concepts from dense textbook chapters\n",
        "- Summarized case studies facilitate efficient learning\n",
        "- Supports continuing medical education by condensing new developments\n",
        "\n",
        "---\n",
        "\n",
        "##### ⚠️ **Important Considerations**\n",
        "\n",
        "While summarization is powerful, biomedical professionals should be aware of limitations:\n",
        "\n",
        "| Concern | Recommendation |\n",
        "|---------|----------------|\n",
        "| Loss of nuance | Verify critical details in the original source |\n",
        "| Potential inaccuracies | Human review remains essential for clinical applications |\n",
        "| Context dependency | Medical terminology may be misinterpreted by general models |\n",
        "| Bias in training data | Use domain-specific biomedical models when possible |\n",
        "\n",
        "---\n",
        "\n",
        "##### **Conclusion**\n",
        "\n",
        "Text summarization represents a valuable tool for managing the ever-growing volume of biomedical literature. When used appropriately alongside human expertise, it can enhance productivity, support evidence-based practice, and accelerate scientific discovery.\n"
      ],
      "metadata": {
        "id": "h-oxry-zrVBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 5 - step 1: Input Text**\n",
        "\n",
        "In the cell below, write the code to input `ex_text3`. Use this code snippet  that contains a discussion of the **Human Microbiome**:\n",
        "\n",
        "```python\n",
        "eg_text3 = \"\"\"\n",
        "The human microbiome represents one of the most fascinating and rapidly evolving\n",
        "areas of biomedical research in the twenty-first century. This complex ecosystem\n",
        "of trillions of microorganisms, including bacteria, viruses, fungi, and other\n",
        "microscopic life forms, resides throughout the human body, with the greatest\n",
        "concentration found in the gastrointestinal tract. These microbial communities\n",
        "are not merely passive inhabitants; they play crucial roles in human health,\n",
        "disease prevention, and even mental well-being.\n",
        "\n",
        "Research has demonstrated that the gut microbiome influences numerous physiological\n",
        "processes, including digestion, metabolism, immune system development, and\n",
        "protection against pathogenic organisms. The bacteria in our intestines help\n",
        "break down complex carbohydrates, synthesize essential vitamins such as vitamin K\n",
        "and certain B vitamins, and produce short-chain fatty acids that provide energy\n",
        "to colon cells. This symbiotic relationship between humans and their microbial\n",
        "partners has evolved over millions of years, resulting in a finely tuned system\n",
        "that benefits both host and microbe.\n",
        "\n",
        "The connection between the gut microbiome and the immune system is particularly\n",
        "noteworthy. Approximately seventy percent of the body's immune cells reside in\n",
        "the gut-associated lymphoid tissue, where they constantly interact with and\n",
        "respond to the microbial environment. This interaction helps train the immune\n",
        "system to distinguish between harmful pathogens and beneficial or neutral\n",
        "organisms. Disruptions to the microbiome, known as dysbiosis, have been linked\n",
        "to various autoimmune conditions, including inflammatory bowel disease,\n",
        "rheumatoid arthritis, and type 1 diabetes.\n",
        "\n",
        "Perhaps most intriguing is the emerging understanding of the gut-brain axis,\n",
        "a bidirectional communication network linking the gastrointestinal tract and\n",
        "the central nervous system. The microbiome produces neurotransmitters such as\n",
        "serotonin, dopamine, and gamma-aminobutyric acid, which can influence mood,\n",
        "cognition, and behavior. Studies have shown correlations between specific\n",
        "microbial profiles and conditions such as depression, anxiety, and autism\n",
        "spectrum disorder, opening new avenues for therapeutic intervention.\n",
        "\n",
        "The therapeutic potential of microbiome manipulation has generated considerable\n",
        "interest in the medical community. Fecal microbiota transplantation has proven\n",
        "remarkably effective in treating recurrent Clostridioides difficile infections,\n",
        "with success rates exceeding ninety percent. Researchers are now investigating\n",
        "whether similar approaches might benefit patients with inflammatory bowel disease,\n",
        "metabolic syndrome, and neurological disorders. Additionally, the development of\n",
        "targeted probiotics and prebiotics offers promise for more precise microbiome\n",
        "modulation.\n",
        "\n",
        "Advances in sequencing technology have revolutionized our ability to study the\n",
        "microbiome. High-throughput sequencing methods allow researchers to identify\n",
        "and quantify the thousands of microbial species present in a single sample,\n",
        "while metagenomic approaches provide insights into the functional capabilities\n",
        "of these communities. Machine learning algorithms are increasingly being applied\n",
        "to microbiome data to identify disease biomarkers and predict treatment responses.\n",
        "\n",
        "Despite remarkable progress, significant challenges remain in microbiome research.\n",
        "The complexity and variability of microbial communities across individuals makes\n",
        "it difficult to define a healthy microbiome. Factors such as diet, geography,\n",
        "age, medications, and genetics all influence microbial composition, complicating\n",
        "efforts to establish causal relationships between specific microbes and health\n",
        "outcomes. Standardization of sample collection, processing, and analysis methods\n",
        "is essential for ensuring reproducibility across studies.\n",
        "\"\"\"\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "_urpVADqrzSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 5 - Step 1 here\n",
        "\n"
      ],
      "metadata": {
        "id": "NNBq7hDhrzSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should _not_ see any output."
      ],
      "metadata": {
        "id": "_mR2qwjd1EAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 5 - Step 2: Print Summary**\n",
        "\n",
        "In the cell below, write the code to summarize the text in `ex_text3`and then print out this summary."
      ],
      "metadata": {
        "id": "XLygntbYrzSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 5 - Step 2 here\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xMPvRs_NrzSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see somethiog _similar_ to the following output:\n",
        "```text\n",
        "Summary:\n",
        "\n",
        " The human microbiome represents one of the most fascinating and rapidly\n",
        "evolving areas of biomedical research in the twenty-first century. Microbiome is\n",
        "a complex ecosystem of trillions of microorganisms, including bacteria, viruses,\n",
        "fungi, and other microorganisms. Microbes play crucial roles in human health,\n",
        "disease prevention, and even mental well-being. Disruptions to the microbiome,\n",
        "known as dysbiosis, have been linked  to autoimmune conditions, including\n",
        "inflammatory bowel disease,  heumatoid arthritis, and type 1 diabetes. Fecal\n",
        "microbiota transplantation has proven reporably effective in treating recurrent\n",
        "Clostridioides difficile infections, with success rates exceeding ninety\n",
        "percent. The microbiome produces neurotransmitters such as serotonin, dopamine,\n",
        "and gamma-aminobutyric acid, which can influence mood, behavior, and behavior.\n",
        "Machine learning algorithms are increasingly being applied to microbiome data to\n",
        "identify disease biomarkers and predict treatment responses. The development of\n",
        "probiotics and prebiotics offers promise\n",
        "```"
      ],
      "metadata": {
        "id": "I_VM47g8vX9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NLP Text Generation**\n",
        "\n",
        "**Text generation** is a fundamental and powerful capability in natural language processing (NLP), and Hugging Face provides several models that excel in this area. Here's why text generation is important and how it is utilized:\n",
        "\n",
        "1. **Creative Writing:** Text generation models can help authors, poets, and scriptwriters generate new content, brainstorm ideas, or even complete unfinished pieces. This can significantly boost creativity and productivity.\n",
        "\n",
        "2. **Conversational Agents:** Text generation models are used to create chatbots and virtual assistants that can engage in natural and meaningful conversations with users. These models can provide customer support, answer queries, and even offer companionship.\n",
        "\n",
        "3. **Content Creation:** Businesses and content creators use text generation to produce articles, social media posts, product descriptions, and more. This helps in maintaining a consistent flow of content and saves time.\n",
        "\n",
        "4. **Language Translation:** Text generation plays a crucial role in machine translation, where models generate translated text from one language to another, ensuring that the meaning and nuances are preserved.\n",
        "\n",
        "5. **Summarization:** As mentioned earlier, text generation models can summarize lengthy documents into concise summaries, making it easier to digest large volumes of information quickly.\n",
        "\n",
        "6. **Code Generation:** Developers use text generation models to assist in coding by generating code snippets, documenting code, or even completing functions based on prompts.\n",
        "\n",
        "7. **Educational Tools:** Text generation can be used to create educational content, generate quizzes, provide explanations, and even tutor students in various subjects.\n",
        "\n",
        "Hugging Face offers several powerful models for text generation, such as GPT-3, BERT, T5, and more. These models leverage large-scale pre-training on diverse datasets to understand and generate human-like text."
      ],
      "metadata": {
        "id": "ptrnxK9auo_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Generator Pipeline\n",
        "\n",
        "Run the code in the cell below to set up a pipeline to generate text."
      ],
      "metadata": {
        "id": "OtKI4PiNulDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Generator Pipeline\n",
        "\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "def setup_pipeline():\n",
        "    try:\n",
        "        # Check if CUDA is available\n",
        "        if torch.cuda.is_available():\n",
        "            device = 0  # Use first GPU\n",
        "            print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "            print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
        "            print(\"Using GPU for text generation\")\n",
        "        else:\n",
        "            device = -1\n",
        "            print(\"No GPU found. Using CPU for text generation\")\n",
        "\n",
        "        # Setup pipeline\n",
        "        generator = pipeline(\"text-generation\",\n",
        "                           model=\"openai-community/gpt2\",\n",
        "                           device=device)\n",
        "\n",
        "        return generator\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing pipeline: {e}\")\n",
        "        print(\"Falling back to CPU\")\n",
        "        return pipeline(\"text-generation\",\n",
        "                       model=\"openai-community/gpt2\",\n",
        "                       device=-1)\n",
        "\n",
        "# Initialize the pipeline\n",
        "generator = setup_pipeline()\n"
      ],
      "metadata": {
        "id": "Kh_1MimLWN0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image11G.png)"
      ],
      "metadata": {
        "id": "AfXlDQTUvEjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 6: Generate New Text\n",
        "\n",
        "The code in the cell below generates additional text after the end of Shakespear's `Sonnet 18`.\n"
      ],
      "metadata": {
        "id": "MMHsEEF4uwQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 6 - Step 2: Generate New Text\n",
        "\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from urllib.request import urlopen\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# Setup pipeline with explicit model specification\n",
        "eg_generator = pipeline(\"text-generation\",\n",
        "                     model=\"openai-community/gpt2\",\n",
        "                     device=device)\n",
        "\n",
        "# Read sample text, a poem\n",
        "URL = \"https://biologicslab.co/BIO1173/data/sonnet_18.txt\"\n",
        "f = urlopen(URL)\n",
        "eg_text = f.read().decode(\"utf-8\")\n",
        "\n",
        "# Print original text\n",
        "print(\"\\nOriginal Text:---------------------- \\n\")\n",
        "print(eg_text)\n",
        "print(\"\\nGenerated Text:------------------- \\n\")\n",
        "\n",
        "# Fix the warnings by using max_new_tokens instead of max_length\n",
        "# Also add truncation and other parameters to avoid warnings\n",
        "outputs = eg_generator(eg_text,\n",
        "                    max_new_tokens=200,  # Use this instead of max_length\n",
        "                    num_return_sequences=1,\n",
        "                    truncation=True,  # Explicitly enable truncation\n",
        "                    do_sample=True,   # Enable sampling for better generation\n",
        "                    temperature=0.7,  # Control randomness (0.0 to 1.0)\n",
        "                    top_k=50,         # Top-k sampling\n",
        "                    top_p=0.95)       # Nucleus sampling\n",
        "\n",
        "eg_generated_text = outputs[0]['generated_text']\n",
        "print(eg_generated_text)\n"
      ],
      "metadata": {
        "id": "6clt-mBiWuKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to this output.\n",
        "\n",
        "```text\n",
        "\n",
        "Original Text:----------------------\n",
        "\n",
        "Shall I compare thee to a summer's day?\n",
        "Thou art more lovely and more temperate:\n",
        "Rough winds do shake the darling buds of May,\n",
        "And summer's lease hath all too short a date:\n",
        "Sometime too hot the eye of heaven shines,\n",
        "And often is his gold complexion dimm'd;\n",
        "And every fair from fair sometimes declines,\n",
        "By chance or nature's changing course untrimm'd;\n",
        "But thy eternal summer shall not fade\n",
        "Nor lose possession of that fair thou owest;\n",
        "Nor shall Death brag thou wander'st in his shade,\n",
        "When in eternal lines to time thou growest.\n",
        "\n",
        "Generated Text:-------------------\n",
        "\n",
        "Shall I compare thee to a summer's day?\n",
        "Thou art more lovely and more temperate:\n",
        "Rough winds do shake the darling buds of May,\n",
        "And summer's lease hath all too short a date:\n",
        "Sometime too hot the eye of heaven shines,\n",
        "And often is his gold complexion dimm'd;\n",
        "And every fair from fair sometimes declines,\n",
        "By chance or nature's changing course untrimm'd;\n",
        "But thy eternal summer shall not fade\n",
        "Nor lose possession of that fair thou owest;\n",
        "Nor shall Death brag thou wander'st in his shade,\n",
        "When in eternal lines to time thou growest.\n",
        "And in eternal lines to time thou growest.\n",
        "And in eternal lines to time thou grewest.\n",
        "And in eternal lines to time thou grewest.\n",
        "But thy eternal summer shall not fade.\n",
        "                                          \n",
        "```\n",
        "NOTE: If your rerun the code several times, you will generate quite different outputs!"
      ],
      "metadata": {
        "id": "ShIXZvnKvCiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comparison of Original vs. Generated Text**\n",
        "\n",
        "The following is an analysis of the Original Text (Sonnet 18) and the Generated Text (shown above) by `OpenAI's` **`ChatGPT-4o`** model.\n",
        "\n",
        "##### **1. Fidelity to Original**\n",
        "- **Original Text**: Maintains Shakespeare’s iambic pentameter, rhyme scheme (ABAB CDCD EFEF GG), and thematic focus on eternal beauty and poetic immortality.\n",
        "- **Generated Text**: The first 12 lines are identical to the original, but the continuation breaks from the sonnet structure and introduces new, loosely connected ideas.\n",
        "\n",
        "##### **2. Coherence and Structure**\n",
        "- **Original**: Cohesive and logically structured argument about the enduring nature of the subject’s beauty.\n",
        "- **Generated**: Becomes repetitive and structurally disorganized. Phrases like “the boy shall be called, as he is now” are repeated without clear poetic or thematic purpose.\n",
        "\n",
        "##### **3. Style and Language**\n",
        "- **Original**: Rich in metaphor (“eye of heaven,” “eternal summer”), elevated diction, and poetic devices.\n",
        "- **Generated**: Attempts poetic language but lacks the sophistication and precision of Shakespeare. The metaphors are simpler and less evocative (“sun and moon are the sweetest kisses of love”).\n",
        "\n",
        "##### **4. Thematic Depth**\n",
        "- **Original**: Explores themes of beauty, mortality, and the power of poetry to preserve.\n",
        "- **Generated**: Shifts toward themes of identity and romantic roles but without clear development or philosophical insight.\n",
        "\n",
        "#### **5. Creativity and Originality**\n",
        "- **Generated Text**: Shows an attempt to emulate poetic style and extend the theme, but the repetition and lack of clarity suggest limitations in the model’s understanding of poetic form and nuance.\n",
        "\n",
        "#### **Summary Table**\n",
        "\n",
        "| Aspect              | Original Text                  | Generated Text                          |\n",
        "|---------------------|--------------------------------|------------------------------------------|\n",
        "| Structure           | Sonnet form, 14 lines          | Starts as sonnet, then diverges          |\n",
        "| Language            | Elevated, metaphorical         | Poetic attempt, but repetitive           |\n",
        "| Coherence           | Logical and thematic unity     | Fragmented and repetitive                |\n",
        "| Creativity          | Masterful and timeless         | Imitative, with limited poetic insight   |\n",
        "\n",
        "---\n",
        "\n",
        "It should be noted that the newest Frontier LLM models from companies such as **Google**, **OpenAI** and **Anthropic** could probably do a considerably better job.\n"
      ],
      "metadata": {
        "id": "a7p6SSPuvo1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the text generation output continued far beyond the original Sonnet 18, incorporating additional and somewhat repetitive lines. This can happen with generative models when they attempt to create content based on a given prompt."
      ],
      "metadata": {
        "id": "-y4t8mQZxzwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 6: Generate New Text**\n",
        "\n",
        "In the cell below, write the code to generate additional text after the end of Shakespear's `Sonnet 66`.\n"
      ],
      "metadata": {
        "id": "k7TYBRZ_2veF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 6 - Step 2: Generate New Text\n",
        "\n"
      ],
      "metadata": {
        "id": "0WkorSUx2veF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something _similar_ to this output.\n",
        "\n",
        "```text\n",
        "\n",
        "Original Text:----------------------\n",
        "\n",
        "Tired with all these, for restful death I cry:\n",
        "As, to behold desert a beggar born,\n",
        "And needy nothing trimmed in jollity,\n",
        "And purest faith unhappily forsworn,\n",
        "And gilded honor shamefully misplaced,\n",
        "And maiden virtue rudely strumpeted,\n",
        "And right perfection wrongfully disgraced,\n",
        "And strength by limping sway disablèd,\n",
        "And art made tongue-tied by authority,\n",
        "And folly, doctor-like, controlling skill,\n",
        "And simple truth miscalled simplicity,\n",
        "And captive good attending captain ill.\n",
        " Tired with all these, from these would I be gone,\n",
        " Save that, to die, I leave my love alone.\n",
        "\n",
        "Generated Text:-------------------\n",
        "\n",
        "Tired with all these, for restful death I cry:\n",
        "As, to behold desert a beggar born,\n",
        "And needy nothing trimmed in jollity,\n",
        "And purest faith unhappily forsworn,\n",
        "And gilded honor shamefully misplaced,\n",
        "And maiden virtue rudely strumpeted,\n",
        "And right perfection wrongfully disgraced,\n",
        "And strength by limping sway disablèd,\n",
        "And art made tongue-tied by authority,\n",
        "And folly, doctor-like, controlling skill,\n",
        "And simple truth miscalled simplicity,\n",
        "And captive good attending captain ill.\n",
        " Tired with all these, from these would I be gone,\n",
        " Save that, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these, to die, I leave my love alone.\n",
        "And in these\n",
        "```\n",
        "NOTE: If your rerun the code several times, you will generate quite different outputs! Therefore it is highly unlikely that your Generated Text will be anything like this example."
      ],
      "metadata": {
        "id": "TZTTYip92veG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Biomedical Named Entity Recognition (NER)**\n",
        "\n",
        "An important use case for the Hugging Face NLP pipelines in biomedicine is **Named Entity Recognition (NER)** using a biomedical-specific model.\n",
        "\n",
        "\n",
        "#### **Why This Example Works Well**\n",
        "\n",
        "| Advantage | Description |\n",
        "|-----------|-------------|\n",
        "| **Highly Practical** | Extracting entities from text is a real-world task in clinical and research settings |\n",
        "| **Visually Compelling** | Results clearly show identified drugs, diseases, genes, etc. |\n",
        "| **Domain-Specific** | Uses a model trained specifically on biomedical literature |\n",
        "| **Builds on Previous Examples** | Shows a different pipeline task beyond classification, translation, and summarization |\n",
        "\n"
      ],
      "metadata": {
        "id": "mWVG7gUM6WrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 7 - Step 1: Create NER Pipeline\n",
        "\n",
        "The code in the next cell generates a NER pipeline called `pubmed_pipeline` using the `d4data/biomedical-ner-all` model. The `d4data/biomedical-ner-all model` is a specialized Named Entity Recognition (NER) tool hosted on Hugging Face. It is designed to extract structured biomedical concepts (like diseases, symptoms, and medications) from unstructured text, such as PubMed abstracts or clinical notes.\n",
        "\n",
        "This model acts as a **processing engine**. You would build a pipeline that fetches text from PubMed (the input) and feeds it into this model to automatically tag and extract specific medical terms (the output)."
      ],
      "metadata": {
        "id": "YsziPY_B7O2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create NER Pipeline\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "pubmed_pipeline = pipeline(\n",
        "    \"ner\",\n",
        "    model=\"d4data/biomedical-ner-all\",\n",
        "    aggregation_strategy=\"simple\"\n",
        ")"
      ],
      "metadata": {
        "id": "OHVJqw-77JWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image12G.png)"
      ],
      "metadata": {
        "id": "DY_BBXjNU0YX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 7 - Step 2: Perform Named Entity Recognition (NER)\n",
        "\n",
        "\n",
        "Example 7 shows how to use a Hugging Face NLP pipeline to automatically identify and extract biomedical entities from clinical text.\n",
        "\n",
        "##### **What the Code Does**\n",
        "\n",
        "1. **Defines Input Text**: A sample clinical trial description is stored in `eg_biomedical_text`, containing information about a cancer treatment study including drug names, dosages, diseases, and adverse events.\n",
        "\n",
        "2. **Extracts Entities**: The `pubmed_pipeline()` function (a pre-configured NER pipeline) processes the text and identifies biomedical entities such as:\n",
        "   - Drug names (pembrolizumab, carboplatin, paclitaxel)\n",
        "   - Diseases (non-small cell lung cancer, pneumonitis)\n",
        "   - Dosages (200 mg)\n",
        "   - Administration routes (intravenously)\n",
        "   - Adverse events (fatigue, nausea)\n",
        "\n",
        "3. **Displays Results**: The code loops through each identified entity and prints:\n",
        "   - The extracted word/phrase\n",
        "   - Its entity category (e.g., Drug, Disease, Dosage)\n",
        "   - A confidence score indicating how certain the model is about the classification\n",
        "\n",
        "##### **Why This Matters**\n",
        "\n",
        "Named Entity Recognition transforms unstructured clinical text into structured, actionable data. This capability is essential for tasks such as mining medical literature, parsing electronic health records, and supporting pharmacovigilance activities.\n"
      ],
      "metadata": {
        "id": "4hT8deaSTgSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 7: Biomedical Named Entity Recognition (NER)\n",
        "\n",
        "# Set Clean Word Distance\n",
        "WORD_DISTANCE=25\n",
        "\n",
        "# Input clinical trial description\n",
        "eg_clinical_text = \"\"\"\n",
        "A phase III randomized controlled trial evaluated the efficacy of pembrolizumab\n",
        "in combination with chemotherapy for patients with metastatic non-small cell\n",
        "lung cancer. Patients received 200 mg of pembrolizumab intravenously every\n",
        "three weeks along with carboplatin and paclitaxel. Results showed that the\n",
        "combination therapy significantly improved progression-free survival compared\n",
        "to chemotherapy alone. Common adverse events included fatigue, nausea, and\n",
        "immune-related pneumonitis. The study was conducted at Memorial Sloan Kettering\n",
        "Cancer Center and MD Anderson Cancer Center.\n",
        "\"\"\"\n",
        "\n",
        "# Extract biomedical entities\n",
        "entities = pubmed_pipeline(eg_clinical_text)\n",
        "\n",
        "# Display results\n",
        "print(\"Extracted Disease Entities:\\n\")\n",
        "for entity in entities:\n",
        "    word = entity['word'].strip()\n",
        "    # Skip punctuation, short words, and phrases that start with common non-disease words\n",
        "    skip_starts = ['the ', 'a ', 'in ', 'and ', 'after ', 'for ', ', ', '. ', 'last ']\n",
        "    if len(word) > 3 and not any(word.lower().startswith(s) for s in skip_starts):\n",
        "        # Clean up apostrophe spacing (e.g., \"Alzheimer ' s\" → \"Alzheimer's\")\n",
        "        clean_word = word.replace(\" ' \", \"'\")\n",
        "        print(f\"{clean_word:<{WORD_DISTANCE}} → {entity['entity_group']:{WORD_DISTANCE}} (confidence: {entity['score']:.2f})\")"
      ],
      "metadata": {
        "id": "yV9UMvos6YIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see something _similar_ to the following output:\n",
        "\n",
        "```text\n",
        "Extracted Disease Entities:\n",
        "\n",
        "phase iii                 → Detailed_description      (confidence: 0.96)\n",
        "random                    → Diagnostic_procedure      (confidence: 0.94)\n",
        "controlled trial          → Diagnostic_procedure      (confidence: 0.92)\n",
        "##mb                      → Medication                (confidence: 0.73)\n",
        "##rolizumab               → Medication                (confidence: 0.89)\n",
        "chemotherapy              → Medication                (confidence: 1.00)\n",
        "metastatic                → Detailed_description      (confidence: 0.77)\n",
        "lung                      → Biological_structure      (confidence: 1.00)\n",
        "200 mg                    → Dosage                    (confidence: 1.00)\n",
        "##mb                      → Medication                (confidence: 0.76)\n",
        "##rol                     → Medication                (confidence: 0.98)\n",
        "##izumab                  → Medication                (confidence: 0.70)\n",
        "intra                     → Administration            (confidence: 1.00)\n",
        "##ven                     → Administration            (confidence: 0.99)\n",
        "##ously                   → Administration            (confidence: 0.91)\n",
        "every three weeks         → Dosage                    (confidence: 0.98)\n",
        "##bo                      → Medication                (confidence: 0.93)\n",
        "##platin                  → Medication                (confidence: 0.97)\n",
        "##lita                    → Medication                (confidence: 0.93)\n",
        "therapy                   → Medication                (confidence: 0.69)\n",
        "progression               → Diagnostic_procedure      (confidence: 0.36)\n",
        "chemotherapy              → Medication                (confidence: 1.00)\n",
        "immune                    → Detailed_description      (confidence: 0.99)\n",
        "memorial sloan kettering cancer center → Nonbiological_location    (confidence: 1.00)\n",
        "```\n",
        "#### **Interpreting the NER Output**\n",
        "\n",
        "##### **Understanding the Results**\n",
        "\n",
        "The output shows biomedical entities extracted from the clinical trial text. Each line displays:\n",
        "- **The extracted text** (word or phrase)\n",
        "- **Entity category** (what type of biomedical concept it represents)\n",
        "- **Confidence score** (0.00 to 1.00, where 1.00 = 100% confident)\n",
        "\n",
        "\n",
        "##### **Entity Categories Explained**\n",
        "\n",
        "| Category | Description | Examples from Output |\n",
        "|----------|-------------|---------------------|\n",
        "| **Medication** | Drugs and therapeutic agents | chemotherapy, carboplatin, paclitaxel |\n",
        "| **Dosage** | Drug amounts and frequencies | 200 mg, every three weeks |\n",
        "| **Administration** | How medication is given | intravenously |\n",
        "| **Disease_disorder** | Medical conditions | pneumonitis (shown as \"p\") |\n",
        "| **Biological_structure** | Body parts and organs | lung |\n",
        "| **Diagnostic_procedure** | Tests and trial methods | controlled trial |\n",
        "| **Detailed_description** | Qualifiers and descriptors | phase iii, metastatic, immune |\n",
        "| **Nonbiological_location** | Institutions and places | Memorial Sloan Kettering Cancer Center |\n",
        "\n",
        "##### **Understanding Tokenization Artifacts**\n",
        "\n",
        "You'll notice fragmented words with `##` symbols (e.g., `pe`, `##mb`, `##rolizumab`). This is due to **subword tokenization**:\n",
        "\n",
        "- The model breaks unknown or complex words into smaller pieces\n",
        "- `##` indicates a continuation of the previous token\n",
        "- **pembrolizumab** → `pe` + `##mb` + `##rolizumab`\n",
        "- **carboplatin** → `car` + `##bo` + `##platin`\n",
        "- **intravenously** → `intra` + `##ven` + `##ously`\n",
        "\n",
        "This is normal behavior for transformer models but can make output harder to read.\n",
        "\n",
        "##### **Confidence Score Interpretation**\n",
        "\n",
        "| Score Range | Interpretation |\n",
        "|-------------|----------------|\n",
        "| **0.90 - 1.00** | High confidence – reliable classification |\n",
        "| **0.70 - 0.89** | Moderate confidence – likely correct |\n",
        "| **Below 0.70** | Lower confidence – may need verification |\n",
        "\n",
        "Examples from output:\n",
        "- ✅ `chemotherapy → Medication (1.00)` – Very reliable\n",
        "- ✅ `200 mg → Dosage (1.00)` – Very reliable\n",
        "- ⚠️ `therapy → Medication (0.69)` – Less certain\n",
        "- ⚠️ `progression → Diagnostic_procedure (0.36)` – Low confidence\n"
      ],
      "metadata": {
        "id": "Uz_C3fnK8VKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 7 - Step 1: Create NER Pipeline**\n",
        "\n",
        "In the next cell below, write the code to generate a NER pipeline called `disease_pipeline` that uses the `alvaroalon2/biobert_diseases_ner` model."
      ],
      "metadata": {
        "id": "edkuQ0cGYPLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 7 - Step 1 here\n",
        "\n"
      ],
      "metadata": {
        "id": "vocN2g06XtCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image13G.png)"
      ],
      "metadata": {
        "id": "YV07A8HwcCRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 7 - Step 2: Perform Named Entity Recognition (NER)**\n",
        "\n",
        "Use this code for your clinical description\n",
        "\n",
        "```python\n",
        "# Input clinical description\n",
        "ex_clinical_text = \"\"\"\n",
        "The patient presented with a complex medical history including type 2 diabetes\n",
        "mellitus, hypertension, and chronic kidney disease. Previous diagnoses included\n",
        "rheumatoid arthritis and major depressive disorder. Family history was significant\n",
        "for Alzheimer's disease in the mother and coronary artery disease in the father.\n",
        "The patient was recently evaluated for suspected Parkinson's disease after\n",
        "experiencing tremors and bradykinesia. Additionally, the patient has a history\n",
        "of asthma and was treated for pneumonia last winter. Laboratory results raised\n",
        "concerns for possible hepatitis C infection, pending confirmatory testing.\n",
        "\n",
        "\"\"\"\n",
        "```\n",
        "**CODE HINTS:**\n",
        "1. Make sure to use your `disease_pipeline` when you extract entities from the `ex_clinical_text`.\n"
      ],
      "metadata": {
        "id": "JsKKQ0JtWeF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 7 - Step 2 here\n",
        "\n"
      ],
      "metadata": {
        "id": "htmm2w4-WeF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see something _similar_ to the following output:\n",
        "\n",
        "```text\n",
        "\n",
        "Extracted Disease Entities:\n",
        "\n",
        "type 2 diabetes mellitus  → DISEASE                   (confidence: 1.00)\n",
        "hypertension              → DISEASE                   (confidence: 0.98)\n",
        "chronic kidney disease    → DISEASE                   (confidence: 1.00)\n",
        "rheumatoid arthritis      → DISEASE                   (confidence: 1.00)\n",
        "depressive disorder       → DISEASE                   (confidence: 1.00)\n",
        "Alzheimer's disease       → DISEASE                   (confidence: 1.00)\n",
        "coronary artery disease   → DISEASE                   (confidence: 0.99)\n",
        "Parkinson's disease       → DISEASE                   (confidence: 1.00)\n",
        "tremors                   → DISEASE                   (confidence: 1.00)\n",
        "bradykinesia              → DISEASE                   (confidence: 1.00)\n",
        "asthma                    → DISEASE                   (confidence: 0.97)\n",
        "pneumonia                 → DISEASE                   (confidence: 1.00)\n",
        "hepatitis C infection     → DISEASE                   (confidence: 1.00)\n",
        "```\n",
        "#### **Summary of Disease Recognition Results**\n",
        "\n",
        "###### **Overview**\n",
        "\n",
        "The BioBERT disease NER model successfully processed the clinical text and identified multiple disease entities. However, the output reveals an important issue with the model's entity boundary detection.\n",
        "\n",
        "##### **Diseases Successfully Identified**\n",
        "\n",
        "The model correctly recognized the following diseases in the patient with high confidence:\n",
        "\n",
        "| Disease | Confidence |\n",
        "|---------|------------|\n",
        "| Type 2 diabetes mellitus | 1.00 |\n",
        "| Hypertension | 0.98 |\n",
        "| Chronic kidney disease | 1.00 |\n",
        "| Rheumatoid arthritis | 1.00 |\n",
        "| Depressive disorder | 1.00 |\n",
        "| Alzheimer's disease | 1.00 |\n",
        "| Coronary artery disease | 0.99 |\n",
        "| Parkinson's disease | 1.00 |\n",
        "| Tremors | 1.00 |\n",
        "| Bradykinesia | 1.00 |\n",
        "| Asthma | 0.97 |\n",
        "| Pneumonia | 1.00 |\n",
        "| Hepatitis C infection | 1.00 |\n",
        "\n",
        "##### **Conclusion**\n",
        "\n",
        "The model **successfully identified all major diseases** in the clinical text.\n"
      ],
      "metadata": {
        "id": "JJpGLdT1WeF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lesson Turn-In**\n",
        "\n",
        "When you have completed and run all of the code cells, use the `File --> Print.. --> Microsoft Print to PDF` to generate your PDF if you are running `MS Windows`. If you have a Mac, use the `File --> Print.. --> Save as PDF`\n",
        "\n",
        "In either case, save your PDF as Copy of Class_05_1.lastname.pdf where lastname is your last name, and upload the file to Canvas."
      ],
      "metadata": {
        "id": "pwesIKw7THkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lizard Tail**\n",
        "\n",
        "## **Apple Mac Studio with M3 Ultra**\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/Mac_Studio.jpg)\n",
        "\n",
        "The Mac Studio is a small-form-factor workstation computer developed and marketed by Apple Inc. It is one of four desktop computers in the Mac lineup, sitting above the consumer-range Mac Mini and iMac, and positioned below the Mac Pro. It is configurable with either the M4 Max or M3 Ultra system on a chip.\n",
        "\n",
        "## On-Line Purchase\n",
        "\n",
        "If you are looking for a new computer to do a little homework, surf the web or run Large Language Models locally, you can't go wrong buying the **Apple Mac Studio with M3 Ultra**\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_05/class_05_1_image21A.png)\n",
        "\n",
        "### **Why the Mac Studio Ultra with M3 Is Useful for Running LLMs Locally**\n",
        "\n",
        "#### 🔧 Key Hardware Advantages\n",
        "\n",
        "##### 1. M3 Ultra Chip Architecture\n",
        "- Combines two M3 Max chips, offering **up to 32 CPU cores and 80 GPU cores**.\n",
        "- Unified memory architecture with **up to 192GB of RAM**, crucial for loading large models entirely into memory.\n",
        "\n",
        "##### 2. High Memory Bandwidth\n",
        "- Apple Silicon chips have **extremely fast memory bandwidth**, aiding rapid data movement during inference and training.\n",
        "\n",
        "##### 3. Neural Engine\n",
        "- The **Apple Neural Engine (ANE)** can accelerate certain ML tasks.\n",
        "- While not fully utilized by all ML frameworks yet, it's promising for future optimization.\n",
        "\n",
        "##### 4. Energy Efficiency\n",
        "- Much more **power-efficient** than traditional workstations with discrete GPUs.\n",
        "- Ideal for long-running tasks without excessive heat or power draw.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 Software Ecosystem for LLMs on macOS\n",
        "\n",
        "##### 1. Support for ML Frameworks\n",
        "- macOS supports **PyTorch**, **TensorFlow**, and **Hugging Face Transformers**.\n",
        "- Tools like **Llama.cpp**, **GGUF**, and **MLX (Apple’s ML framework)** are optimized for Apple Silicon.\n",
        "\n",
        "#####2. Running Quantized Models\n",
        "- Models like **LLaMA 2**, **Mistral**, or **Phi-3** can run in 4-bit or 8-bit quantized formats.\n",
        "- With 192GB RAM, even **larger models** like LLaMA 3 70B can be experimented with in quantized form.\n",
        "\n",
        "##### 3. MLX Framework\n",
        "- Apple’s MLX framework is designed to take full advantage of Apple Silicon.\n",
        "- Makes it easier to run and experiment with models locally.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧪 Use Cases for Local LLMs\n",
        "\n",
        "- **Privacy-sensitive applications** (e.g., medical or educational data).\n",
        "- **Offline access** for fieldwork or remote teaching.\n",
        "- **Rapid prototyping** without relying on cloud APIs.\n",
        "- **Fine-tuning small models** for domain-specific tasks.\n",
        "\n",
        "---\n",
        "\n",
        "Would you like help setting up a local LLM on a Mac Studio Ultra, or exploring which models would run best on it?\n",
        "\n",
        "\n",
        "## Overview\n",
        "### Rear ports\n",
        "\n",
        "The Mac Studio is a desktop personal computer, designed to sit between the consumer-level Mac Mini and the professional-targeted Mac Pro. The Mac Studio has an identical width and depth to the contemporary Mac mini, 7.7 inches (200 mm), but it stands taller at 3.7 inches (94 mm).\n",
        "\n",
        "The Mac Studio was initially offered in two ARM-based SoC: the M1 Max or the M1 Ultra, which combines two M1 Max chips in one package. It has:\n",
        "\n",
        "- Four Thunderbolt 4 (USB 4) ports\n",
        "- Two USB 3.0 Type-A ports\n",
        "- HDMI (up to 4K @ 60 Hz)\n",
        "- 10Gb Ethernet with Lights Out Management\n",
        "- Headphone jack\n",
        "\n",
        "The front panel has:\n",
        "\n",
        "- Two USB-C ports (Thunderbolt 4 in M1 Ultra models)\n",
        "- SD card slot (supports SDXC cards and UHS-II bus)\n",
        "\n",
        "It is cooled by a pair of double-sided blowers and a mesh of holes on the bottom and back of the case, which helps reduce fan noise. Nevertheless, there have been reports of excessive fan noise.\n",
        "\n",
        "Mac Studio models with the Ultra SoC are heavier than the Max-equipped models, as they exchange the aluminum heat sink for one composed of copper. Apple says the Mac Studio performs 50% faster than a Mac Pro with a 16-core Intel Xeon processor.\n",
        "\n",
        "The Mac Studio was introduced alongside the Apple Studio Display, a 27-inch 5K monitor with:\n",
        "\n",
        "- Integrated 12 MP camera\n",
        "- Six-speaker sound system with spatial audio and Dolby Atmos support\n",
        "- Height adjustable stand\n",
        "\n",
        "Customers reported months-long shipping delays for the Mac Studio, attributed to a global chip shortage.\n",
        "\n",
        "## Updates\n",
        "- **June 5, 2023 (WWDC)**: Updated Mac Studio models with M2 Max and M2 Ultra chips.\n",
        "  - Bluetooth 5.3\n",
        "  - Wi-Fi 6E\n",
        "  - Support for up to six 6K monitors\n",
        "  - 8K display support over Thunderbolt and HDMI\n",
        "\n",
        "- **March 5, 2025**: Updated Mac Studio models with M4 Max and M3 Ultra chips (shipping began March 12).\n",
        "  - Thunderbolt 5\n",
        "  - Memory configurable up to 512 GB\n",
        "  - Storage configurable up to 16 TB (M3 Ultra)\n",
        "  - M3 Ultra included due to no existing Ultra chips in the M4 line\n",
        "\n",
        "## Repairability\n",
        "\n",
        "![Mac Studio with Studio Display, Magic Keyboard, and Magic Trackpad in an Apple Store](image-placeholder removable flash storage ports, with one or two in use depending on storage configuration. While swapping flash storage cards between same-size models is possible with Apple Configurator restore, upgrading is not officially supported.\n",
        "\n",
        "Criticism includes:\n",
        "\n",
        "- Limited upgradeability unfriendly to right to repair\n",
        "- SSD controller integrated into SoC for encryption\n",
        "- SSD placement beneath exposed power supply\n",
        "\n",
        "## Reception\n",
        "\n",
        "> This section needs expansion. You can help by adding to it. (March 2025)\n",
        "\n",
        "## Specifications\n",
        "| Model | 2022 | 2023 | 2025 |\n",
        "|-------|------|------|------|\n",
        "| **Announced** | Mar 8, 2022 | Jun 5, 2023 | Mar 5, 2025 |\n",
        "| **Released** | Mar 18, 2022 | Jun 13, 2023 | Mar 12, 2025 |\n",
        "| **Discontinued** | Jun 5, 2023 | Mar 5, 2025 | In production |\n",
        "\n",
        "### Chip Configurations\n",
        "\n",
        "- **2022**\n",
        "  - M1 Max: 10-core CPU, 24-core GPU, 16-core Neural Engine\n",
        "  - M1 Ultra: 20-core CPU, 48-core GPU, 32-core Neural Engine\n",
        "\n",
        "- **2023**\n",
        "  - M2 Max: 12-core CPU, 30-core GPU, 16-core Neural Engine\n",
        "  - M2 Ultra: 24-core CPU, 60-core GPU, 32-core Neural Engine\n",
        "\n",
        "- **2025**\n",
        "  - M4 Max: 14-core CPU, 32-core GPU, 16-core Neural Engine\n",
        "  - M3 Ultra: 28-core CPU, 60-core GPU, 32-core Neural Engine\n",
        "\n",
        "### Memory\n",
        "\n",
        "- 2022: 32 GB (up to 64 GB)\n",
        "- 2023: 64 GB (up to 128 GB)\n",
        "- 2025:\n",
        "  - M4 Max: 36 GB (up to 128 GB)\n",
        "  - M3 Ultra: 96 GB (up to 512 GB)\n",
        "\n",
        "### Storage\n",
        "\n",
        "- 2022 & 2023: 512 GB (Max) or 1 TB (Ultra), up to 8 TB\n",
        "- 2025: Up to 16 TB (Ultra)\n",
        "\n",
        "### Wireless\n",
        "\n",
        "- 2022: Wi-Fi 6, Bluetooth 5.0\n",
        "- 2023: Wi-Fi 6E, Bluetooth 5.3\n",
        "\n",
        "### Connectivity\n",
        "\n",
        "- Thunderbolt 4/5 USB-C ports\n",
        "- USB-A ports\n",
        "- HDMI 2.0/2.1\n",
        "- 10Gb Ethernet\n",
        "- 3.5 mm headphone jack\n",
        "- SDXC card slot\n",
        "### Power\n",
        "\n",
        "- 2022: 370 W\n",
        "- 2023: 480 W\n",
        "\n",
        "### Dimensions\n",
        "- 3.7 in × 7.7 in × 7.7 in\n",
        "\n",
        "### Weight\n",
        "\n",
        "- Max: ~5.9 lb\n",
        "- Ultra: ~7.9–8.0 lb\n",
        "\n",
        "### Emissions\n",
        "\n",
        "- Varies by model and configuration (e.g., 262–382 kg CO₂e)\n",
        "\n",
        "## Software and Operating Systems\n",
        "\n",
        "All Mac Studio models ship with macOS, starting with **macOS Monterey**.\n",
        "\n",
        "### Supported macOS Releases\n",
        "\n",
        "| OS Release | 2022 | 2023 | 2025 |\n",
        "|------------|------|------|------|\n",
        "| 12 Monterey | 12.2 | — | — |\n",
        "| 13 Ventura | Yes | 13.4 | — |\n",
        "| 14 Sonoma | Yes | Yes | — |\n",
        "| 15 Sequoia | Yes | Yes | 15.2 |\n",
        "| 26 Tahoe | Yes | Yes | Yes |\n",
        "\n",
        "---\n",
        "\n",
        "**See also**: [List of Mac models]\n"
      ],
      "metadata": {
        "id": "I7So4JT8SXy0"
      }
    }
  ]
}