{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEEW13uCtiJ"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/master/Class_03_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BIO 1173: Intro Computational Biology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Module 3: Introduction to TensorFlow**\n",
    "\n",
    "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
    "\n",
    "\n",
    "### Module 3 Material\n",
    "\n",
    "* Part 3.1: Deep Learning and Neural Network Introduction\n",
    "* Part 3.2: Using Keras to Build Regression Models\n",
    "* **Part 3.3: Using Keras to Build Classification Models**\n",
    "* Part 3.4: Saving and Loading a Keras Neural Network\n",
    "* Part 3.5: Early Stopping in Keras to Prevent Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpVJpj2DCtiM"
   },
   "source": [
    "## Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wU1AMzx8CtiM",
    "outputId": "24a17c67-4563-471f-9955-dfadd0f171d7"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Setup\n",
    "\n",
    "Run the next code cell to load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You MUST run this code cell first\n",
    "\n",
    "# Import TensorFlow modules\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import scikit-learn metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# Import other needed packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "os.environ['tf.compat.v1.logging.set_verbosity'] = '1'\n",
    "import shutil\n",
    "path = '/'\n",
    "memory = shutil.disk_usage(path)\n",
    "dirpath = os.getcwd()\n",
    "\n",
    "# Print out diagnostics\n",
    "print(\"Your current working directory is : \" + dirpath)\n",
    "print(\"Disk\", memory)\n",
    "print(\"TensorFlow version:\", tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network Classification and Regression**\n",
    "![Neural Network Classification and Regression](https://biologicslab.co/BIO1173/images/class_2_ann_class_reg.png \"Neural Network Classification and Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_dpgVtfCtiS"
   },
   "source": [
    "# Part 3.3: Using Keras to Build Classification Models\n",
    "\n",
    "In the previous lesson (Class_03_2) we looked at how to use Keras/Tensorflow to build simple neural network models that performed a regression analysis. In this lesson, we continue our introduction into Keras and Tensorflow by building neural network models that perform a **_classification_**.\n",
    "\n",
    "**_Classification_** is how a neural network attempts to classify the input into one or more **_classes_**.  The simplest way of evaluating a classification network is to track the percentage of training set items classified incorrectly.  \n",
    "\n",
    "We typically score human results in this manner.  For example, you might have taken multiple-choice exams in school in which you had to shade in a bubble for choices A, B, C, or D.  If you chose the wrong letter on a 10-question exam, you would earn a 90%.  In the same way, we can grade computers; however, most classification algorithms do not merely choose A, B, C, or D.  Computers typically report a classification as their percent confidence in each class.  The figure below shows how a computer and a human might respond to question number 1 on an exam.\n",
    "\n",
    "**Classification Neural Network Output**\n",
    "![Classification Neural Network Output](https://biologicslab.co/BIO1173/images/class-multi-choice.png)\n",
    "\n",
    "As you can see, the human test taker marked the first question as \"B.\" However, the computer test taker had an 80% (0.8) confidence in \"B\" and was also somewhat sure with 10% (0.1) on \"A.\" The computer then distributed the remaining points to the other two.  \n",
    "\n",
    "In the simplest sense, the machine would get 80% of the score for this question if the correct answer were \"B.\" The computer would get only 5% (0.05) of the points if the correct answer were \"D.\" \n",
    "\n",
    "We previously saw how to train a neural network to predict either the `Ripeness` or the `Acidity` of an apple. In this lesson, we will now see how to build a neural network to predict a **_class_**. In particular, we are going to build a neural network that can predict the **_species_** of a particular Iris flower based either on it's sepal dimensions or on its petal dimensions. \n",
    "\n",
    "The code to construct a neural network that can classify Iris flowers is similar to the code for building a neural network for regression. However, there are 3 important differences in classification models:\n",
    "\n",
    "* The output neuron count is **not 1**, but matches the number of classes.\n",
    "* The **_Softmax_** transfer function is utilized by the output layer.\n",
    "* The loss function is **_cross entropy_**.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example 1: Predict Iris Species\n",
    "\n",
    "In Example 1, our goal will be to predict the `class` (species) of an _Iris_ flower based _only_ on the length and width of its **_sepals_**. In **Example 1** you will repeat the analysis, but your model will only use the **_petal_** measurements for training. Although sepals and petals in Iris flowers look similar, they are distinctly different if you look closely.\n",
    "\n",
    "The next image shows an example of how sepal and petal measurements are made. \n",
    "\n",
    "**Iris Sepal and Petal Measurements**\n",
    "\n",
    "![____](https://biologicslab.co/BIO1173/images/iris_petal_sepal.png)\n",
    "\n",
    "As was done in Lesson_03_3, the code for Example 1 will be divided into the following 3 steps:\n",
    "\n",
    "1. Read datafile and create DataFrame \n",
    "2. Create feature vector\n",
    "3. Construct, compile and train the neural network model\n",
    "\n",
    "When constructing neural networks, AI researchers typically follow the same 3 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-Step 1: Read datafile and create DataFrame\n",
    "\n",
    "The first step is usually to either read the a dataset from a local file, or download one from the Internet. In this example, we will read the Iris Flower dataset stored in a CSV file called `iris.csv` on the course HTTPS server, `https://biologicslab.co`, using this code chunk:\n",
    "~~~text\n",
    "# Read dataset into a DataFrame\n",
    "sepalDF = pd.read_csv(\n",
    "    \"http://biologicslab.co/BIO1173/data/iris.csv\", \n",
    "            na_values=['NA', '?'])\n",
    "~~~\n",
    "As the dataset is being read, it is being stored in a Pandas DataFrame called `sepalDF`. This name was choosen to remind us that this DataFrame is being used for Example 1. In this example, we are going to **_shuffle_** and reindex the data after setting the random seed = 42. \n",
    "\n",
    "Finally, after creating our new DataFrame and shuffling the data, we display the first few rows and columns to make sure the data was read correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Read datafile and create DataFrame\n",
    "\n",
    "# Read dataset into a DataFrame\n",
    "sepalDF = pd.read_csv(\n",
    "    \"http://biologicslab.co/BIO1173/data/iris.csv\", \n",
    "            na_values=['NA', '?'])\n",
    "\n",
    "# Set the random seed to 42\n",
    "np.random.seed(42) \n",
    "\n",
    "# Shuffle & reindex\n",
    "sepalDF = sepalDF.reindex(np.random.permutation(sepalDF.index))\n",
    "\n",
    "# Set the max rows and max columns\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(sepalDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following table:\n",
    "\n",
    "![___](https://biologicslab.co/BIO1173/images/class_03_3_Shuffle.png)\n",
    "\n",
    "\n",
    "As you can see, all of the information in the DataFrame is numeric, with the exception of the column `species`. We need to keep this mind when we create our feature vector in the next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-Step 2: Create Feature Vector\n",
    "\n",
    "While we normally begin by converting all the string values to integers, we are **_not_** going to do this in this particular example. The only column with non-numeric values is the column `species`. Since the `species` column will be our Y-values, we take care of it **_after_** we first generate our X-values.\n",
    "\n",
    "Normally we would like to use **all** of the useful data that is available in a dataset for training our neural network. However, since this is a teaching example, we will limit our X-values to just the sepal measurements. We can limit what columns in our DataFrame are used for generating the X-values by simply identifying the specific columns that we want to use by name, as shown in the following code chunk:\n",
    "~~~text\n",
    "# Generate X-values\n",
    "sepalX = sepalDF[['sepal_length', 'sepal_width']].values\n",
    "sepalX = np.asarray(sepalX).astype('float32')\n",
    "~~~\n",
    "When generate either X or Y values, we always want to make sure that they are type `float32` by using the code line:\n",
    "~~~text\n",
    "sepalX = np.asarray(sepalX).astype('float32')\n",
    "~~~\n",
    "\n",
    "One **critical difference** between classification neural networks and regression neural networks is how the Y-values are generated. In regression, you can directly use the numerical values in the correct column in the DataFrame as was demonstrated in the previous lesson. However, when creating a feature vector for a classification neural network, **_the Y-values must be One-Hot Encoded!_**\n",
    "\n",
    "Here is the code chunk for generating the Y-values for classification using One-Hot Encoding:\n",
    "~~~text\n",
    "# Generate Y-values\n",
    "dummies = pd.get_dummies(sepalDF['species'], dtype=int) # Classification\n",
    "iris_species = dummies.columns\n",
    "sepalY = dummies.values\n",
    "sepalY = np.asarray(sepalY).astype('float32')\n",
    "~~~\n",
    "\n",
    "To verify that our coding was correct, the example prints the first 10 values in the variable `dummies` and our Numpy array containing the Y-values, `sepalY`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLp65T9JCtiS",
    "outputId": "63ff7475-c714-4b15-9469-a93db0f96b2c"
   },
   "outputs": [],
   "source": [
    "# Example 1-Step 2: Create Feature Vector \n",
    "\n",
    "# Generate X-values\n",
    "sepalX = sepalDF[['sepal_length', 'sepal_width']].values\n",
    "sepalX = np.asarray(sepalX).astype('float32')\n",
    "\n",
    "# Generate Y-values\n",
    "dummies = pd.get_dummies(sepalDF['species'], dtype=int) # Classification\n",
    "iris_species = dummies.columns\n",
    "sepalY = dummies.values\n",
    "sepalY = np.asarray(sepalY).astype('float32')\n",
    "\n",
    "# Print dummies\n",
    "print(dummies[0:10])\n",
    "\n",
    "# Print first 10 Y-values \n",
    "print(sepalY[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "~~~text\n",
    "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
    "73             0                1               0\n",
    "18             1                0               0\n",
    "118            0                0               1\n",
    "78             0                1               0\n",
    "..           ...              ...             ...\n",
    "64             0                1               0\n",
    "141            0                0               1\n",
    "68             0                1               0\n",
    "82             0                1               0\n",
    "\n",
    "[10 rows x 3 columns]\n",
    "[[0. 1. 0.]\n",
    " [1. 0. 0.]\n",
    " [0. 0. 1.]\n",
    " [0. 1. 0.]\n",
    " [0. 1. 0.]\n",
    " [1. 0. 0.]\n",
    " [0. 1. 0.]\n",
    " [0. 0. 1.]\n",
    " [0. 1. 0.]\n",
    " [0. 1. 0.]]\n",
    "~~~\n",
    "\n",
    "The variable called `dummies` is actually a DataFrame that was generated as part of the One-Hot Encoding. The first 10 records in the `dummies` DataFrame are shown at the top of this output. You should note that the `dummies` DataFrame has **_exactly_** the same numeric values as the Numpy array `sepalY` shown at the bottom of the output. This makes sense given that `sepalY` was generated by the following code chunk:\n",
    "~~~text\n",
    "sepalY = dummies.values\n",
    "~~~\n",
    "This line of code simply converts the numeric **_values_** in the `dummies` DataFrame into a Numpy array, `sepalY`.\n",
    "\n",
    "For example, the first flower in `dummies` (index number `73`) has a `1` in the second column `Iris-versicolor`. If you look at the first element in the `sepalY` array, there is also a `1` in the second column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-Step 3: Construct, Compile and Train Neural Network\n",
    "\n",
    "As mentioned above, the neural network that we will use to classify Iris flowers based on their sepal dimensions, is very similar to a regression neural network but with the following exceptions:\n",
    "\n",
    "* The output neuron count matches the number of classes (in this case 3, since there are 3 different species).\n",
    "* The `Softmax` transfer function is utilized by the output layer.\n",
    "* The loss function is `cross entropy`.\n",
    "\n",
    "The code in the cell below builds a simple neural network called `sepalModel`. Notice that the number of neurons in the input layer is specified by `input_dim=sepalX.shape[1]`:\n",
    "~~~text\n",
    "sepalModel.add(Dense(50, input_dim=sepalX.shape[1], \n",
    "                     activation='relu')) # Hidden 1\n",
    "~~~\n",
    "Also the output layer of this classification neural network is different:\n",
    "~~~text\n",
    "sepalModel.add(Dense(sepalY.shape[1],activation='softmax')) # Output\n",
    "~~~\n",
    "First, the are more than 1 neuron in the output layer. In a classification neural network, there must be 1 neuron for each class. Since there are 3 classes (species) in the Iris Flower dataset, there has to be 3 output neurons. The number of output neurons is specified by the argument `sepalY.shape[1]`. \n",
    "\n",
    "The other difference in the output layer is the presence of an activation function. In this example, the activation function is `softmax`. In a regression neural network, the single output neuron does **not** have an activation function. \n",
    "\n",
    "Finally, you should notice that when the model is compiled, it uses the `categorical_crossentropy` loss function instead of the `mean_squared_error` loss function used in regression neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLp65T9JCtiS",
    "outputId": "63ff7475-c714-4b15-9469-a93db0f96b2c"
   },
   "outputs": [],
   "source": [
    "# Example 1-Step 2: Construct, compile and train neural network\n",
    "\n",
    "# Import TensorFlow modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "# Construct model\n",
    "sepalModel = Sequential()\n",
    "sepalModel.add(Dense(50, input_dim=sepalX.shape[1], \n",
    "                     activation='relu')) # Hidden 1\n",
    "sepalModel.add(Dense(25, activation='relu')) # Hidden 2\n",
    "sepalModel.add(Dense(sepalY.shape[1],activation='softmax')) # Output\n",
    "\n",
    "# Compile the model\n",
    "sepalModel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Print model summary (optional)\n",
    "sepalModel.summary()\n",
    "\n",
    "# Train model\n",
    "sepalModel.fit(sepalX,sepalY,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "\n",
    "~~~text\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " dense_2 (Dense)             (None, 50)                150       \n",
    "                                                                 \n",
    " dense_3 (Dense)             (None, 25)                1275      \n",
    "                                                                 \n",
    " dense_4 (Dense)             (None, 3)                 78        \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,503\n",
    "Trainable params: 1,503\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/100\n",
    "5/5 - 0s - loss: 1.2106 - 381ms/epoch - 76ms/step\n",
    "Epoch 2/100\n",
    "5/5 - 0s - loss: 1.1682 - 31ms/epoch - 6ms/step\n",
    "Epoch 3/100\n",
    "5/5 - 0s - loss: 1.1215 - 32ms/epoch - 6ms/step\n",
    "Epoch 4/100\n",
    "5/5 - 0s - loss: 1.0868 - 30ms/epoch - 6ms/step\n",
    "Epoch 5/100\n",
    "5/5 - 0s - loss: 1.0732 - 37ms/epoch - 7ms/step\n",
    "..................\n",
    "\n",
    "Epoch 95/100\n",
    "5/5 - 0s - loss: 0.4945 - 18ms/epoch - 4ms/step\n",
    "Epoch 96/100\n",
    "5/5 - 0s - loss: 0.4947 - 18ms/epoch - 4ms/step\n",
    "Epoch 97/100\n",
    "5/5 - 0s - loss: 0.4929 - 19ms/epoch - 4ms/step\n",
    "Epoch 98/100\n",
    "5/5 - 0s - loss: 0.4927 - 18ms/epoch - 4ms/step\n",
    "Epoch 99/100\n",
    "5/5 - 0s - loss: 0.4922 - 19ms/epoch - 4ms/step\n",
    "Epoch 100/100\n",
    "5/5 - 0s - loss: 0.4905 - 19ms/epoch - 4ms/step\n",
    "\n",
    "<keras.callbacks.History at 0x27e3c8ee940>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Print Predictions\n",
    "\n",
    "Now that we have trained our neural network, `sepalModel`, we would like to be able to use it. As before, we will generate predictions. Instead of given us a single prediction, as the regression neural network model did in Class_03_2, our new model will make **_3 predictions_**, one prediction for each **_class_** in the dependent variable. These three predictions represents the 3 probabilities that a particular unknown flower is (1) _Iris setosa_, (2) _Iris versicolor_, and (3) _Iris virginica_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YzlVpw-CtiS",
    "outputId": "7b664d3d-7092-44f9-b124-c3404da038c4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 2: Print Predictions\n",
    "\n",
    "# Compute the model predictions\n",
    "sepalPred = sepalModel.predict(sepalX)\n",
    "\n",
    "# Change print from scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Print out the results\n",
    "print(f\"Shape of sepalPred: {sepalPred.shape}\")\n",
    "print(sepalPred[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct your should see something similar to the following:\n",
    "\n",
    "~~~text\n",
    "5/5 [==============================] - 0s 2ms/step\n",
    "Shape of sepalPred: (150, 3)\n",
    "[[0.00667937 0.49824646 0.49507418]\n",
    " [0.9701563  0.02258347 0.00726027]\n",
    " [0.00000133 0.2490988  0.75089985]\n",
    " [0.02025999 0.5275467  0.4521932 ]\n",
    " [0.00030747 0.40100244 0.59869015]\n",
    " [0.8894263  0.07975859 0.0308151 ]\n",
    " [0.10499485 0.5329848  0.3620204 ]\n",
    " [0.00158804 0.4518695  0.5465425 ]\n",
    " [0.0000668  0.3567878  0.6431454 ]\n",
    " [0.01239389 0.51633203 0.47127402]]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of numbers represents the model's prediction for one Iris flower in the dataset. The first column represents the **_probability_** that the flower's species is _I. setosa_, the second column is the probability for _I. versicolor_, and the third column is the probability for _I. virginica_. \n",
    "\n",
    "You should note two things about these predictions. First, generally, one column has a significantly higher probability than the other two columns, but this is not always the case. \n",
    "\n",
    "In the particular example shown above, there is a very low probability that the first flower is _I. setosa_ (prob=0.0067), but the `sepalModel` assigned essentially equal probabilites to the flowere being  _I. versicolor_ (prob=0.498 or 49.8%) and _I. virginica_ (prob=0.495 or 49.5%). In other words, our `sepalModel` thinks there is a 50=50 chance that this particular flower is either  _I. versicolor_ or _I. virginica_. \n",
    "\n",
    "For the next flower on the list, our `sepalModel` is very confident (prob=0.970 or 97%) that it is  _I. setosa_. Finally, `sepalModel` is moderately confident (prob=0.750 or 75%) that the third flower is _I. virginica_ but, the is some possibilty (prob=0.249 or 25%) that it is really _I. virginica_.  \n",
    "\n",
    "As you might expect, when you add up all three probabilities for any particular flower, the sum is essentially zero. To demonstrate this, the next code cell adds the three probabilites of the last flower in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add up the probabilites for list flower in the list\n",
    "0.01239389 + 0.51633203 + 0.47127402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOvMqI7QCtiS"
   },
   "source": [
    "As you can see, it's pretty close to 1. That makes sense since there is a 100% probability that any flower will be one of the three possible species in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDC7hxqECtiS"
   },
   "source": [
    "### Example 3: Print Predicted and Expected Values\n",
    "\n",
    "Usually, the program considers the column with the **_highest_** prediction to be the prediction of the neural network. The `np.argmax()` function can be used to find the index of the **_maximum prediction_** for each row. \n",
    "\n",
    "As shown in the cell below, we can use `np.argmax()` function generate the variables `sepalPredict_classes` and `sepalExpected_classes`. We will need these variables shortly when we want to compute the model's accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "367mbx_PCtiT",
    "outputId": "bf69a471-4080-4628-ebc5-9571d408881d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 3: Print Predicted and Expected Values\n",
    "\n",
    "# Find the maximum prediction for each row\n",
    "sepalPredict_classes = np.argmax(sepalPred,axis=1)\n",
    "\n",
    "# Find the expected value for each row\n",
    "sepalExpected_classes = np.argmax(sepalY,axis=1)\n",
    "\n",
    "# Print out the results\n",
    "print(f\"Predictions: {sepalPredict_classes}\")\n",
    "print(f\"Expected: {sepalExpected_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "Predictions: [2 0 2 1 2 0 1 2 2 1 2 0 0 0 0 1 2 2 1 2 0 1 0 2 2 2 2 2 0 0 0 0 2 0 0 2 1\n",
    " 0 0 0 1 1 2 0 0 2 2 2 2 2 1 2 1 0 2 1 0 0 0 2 2 0 0 0 1 0 1 2 0 2 2 0 1 1\n",
    " 2 1 1 2 0 1 2 0 0 2 2 0 1 0 0 1 1 2 2 2 2 1 0 0 2 2 0 0 0 2 1 0 2 1 0 2 2\n",
    " 2 2 1 0 2 1 2 2 1 1 1 2 1 0 1 2 2 0 1 2 2 0 2 0 2 2 2 1 2 2 2 1 1 0 2 1 0\n",
    " 2 2]\n",
    "Expected: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
    " 0 0 0 2 1 1 0 0 1 2 2 1 2 1 2 1 0 2 1 0 0 0 1 2 0 0 0 1 0 1 2 0 1 2 0 2 2\n",
    " 1 1 2 1 0 1 2 0 0 1 1 0 2 0 0 1 1 2 1 2 2 1 0 0 2 2 0 0 0 1 2 0 2 2 0 1 1\n",
    " 2 1 2 0 2 1 2 1 1 1 0 1 1 0 1 2 2 0 1 2 2 0 2 0 1 2 2 1 2 1 1 2 2 0 1 2 0\n",
    " 1 2]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrcy0Q4xCtiT"
   },
   "source": [
    "### Example 4 - Convert Index Values into Species Names\n",
    "\n",
    "With a little bit of python coding, it's not too hard to change the numbers `0`, `1` and `2` into their corresponding species names. The trick is the variable `iris_species` which is Python type called `index`. This variable was created as part of the One-Hot Encoding of the `species` column during the creation of the feature vector in Example 1-Step 2. \n",
    "\n",
    "If you print out `iris_species` you get the following:\n",
    "~~~text\n",
    "Index(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype='object')\n",
    "~~~~\n",
    "The code in the next cell shows how you can use this `index` type to convert index values in the variable `sepalPred` to their species names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTORTvygCtiT",
    "outputId": "a931a4d1-3204-42de-af37-a366ec2ba353"
   },
   "outputs": [],
   "source": [
    "# Example 4: Convert index values into species names\n",
    "\n",
    "# Print index values for first 5 flowers\n",
    "print(f\"sepalPredict_classes: {sepalPredict_classes[0:4]}\")\n",
    "\n",
    "# Convert index values to species names\n",
    "print(*iris_species[sepalPredict_classes[0:4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see:\n",
    "~~~text\n",
    "sepalPredict_classes: [1 0 2 1]\n",
    "Iris-versicolor Iris-setosa Iris-virginica Iris-versicolor\n",
    "~~~\n",
    "As you can see, the code in the cell above converted the 4 index values `[1 0 2 1]` into the 4 species names `Iris-versicolor`,`Iris-setosa`, `Iris-virginica`, and `Iris-versicolor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ljez1ZRACtiT"
   },
   "source": [
    "### Example 5: Compute the Accuracy Score\n",
    "\n",
    "When using a regression neural network, the convention is to use Root Mean Squared Error (RMSE) as a meaure of the model's ability to correctly predict the Y-values (see Class_03_2). As we dicussed previously, interpreting how good a model is by it's RSME is tricky. \n",
    "\n",
    "The situation is mucn better when working with classification neural networks. Instead of measuring performance with RSME, we use an **_Accuracy Score_** which is a more easily understood error metric. An accuracy score is essentially a test score. As an example, for all of the species predictions made by the `sepalModel`, what percent were correct? In other words, the accuracy score is like the number of correct answers on an exam.  \n",
    "\n",
    "Unfortunatley, the accuracy score isn't a perfect error metric because it doesn't consider how confident the neural network was in each prediction.\n",
    "\n",
    "The code in the cell below uses the `accuracy_score()` function imported from the **scikit-learn** package (nickname `sklearn`), to compute the accuracy of the predicitions made by `sepalModel` and stores this value in a variable called `sepalCorrect`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zth2S2OcCtiT",
    "outputId": "f68a373c-f84e-4d01-8e83-dc22199e76ff"
   },
   "outputs": [],
   "source": [
    "# Example 5: Compute the accuracy score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Compute accuracy\n",
    "sepalCorrect = accuracy_score(sepalExpected_classes,sepalPredict_classes)\n",
    "\n",
    "# Print out the results\n",
    "print(f\"Accuracy: {sepalCorrect}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see something similar to the following output:\n",
    "~~~text\n",
    "Accuracy: 0.7466666666666667\n",
    "~~~\n",
    "The accuracy of the `sepalModel` is roughly 75% accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jY07aiLICtiT"
   },
   "source": [
    "### Example 6: Use Model to Make an _ad hoc_ Prediction\n",
    "\n",
    "The code below performs an _ad hoc_ prediction. Suppose we measure the sepal length and width of flower from an unknown Iris species. We can \"feed\" this information into our trained neural network model `sepalModel` and ask it to predict which species did the flower came from. This is an example of an _ad hoc_ prediction. \n",
    "\n",
    "The first step is to define a variable `sample_flower` with the measurements (in cm) for the sepal length (6.6) and the sepal width (2.9):\n",
    "~~~text\n",
    "sample_flower = np.array( [[6.6,2.9]], dtype=float)\n",
    "~~~\n",
    "\n",
    "Since the model `sepalModel` was trained on data where the sepal length was \"first\" and sepal width was \"second\", it is essential to submit the sepal measurements in exactly the same order. \n",
    "\n",
    "The next line of code uses the `sepalModel` to make the actual prediction which is stored in the variable `sepalPred`:\n",
    "~~~text\n",
    "sepalPred = sepalModel.predict(sample_flower)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZUSWVGnCtiT",
    "outputId": "d98e7cc3-7e10-44f0-a5cb-b858f3c4c850"
   },
   "outputs": [],
   "source": [
    "# Example 6: Use model to make an ad hoc prediction\n",
    "\n",
    "# Specify the sepal length and width for an unknown Iris flower\n",
    "sample_flower = np.array( [[6.6,2.9]], dtype=float)\n",
    "\n",
    "# Use the neural network to predict the species\n",
    "sepalPred = sepalModel.predict(sample_flower)\n",
    "\n",
    "# Print out the results\n",
    "print(sepalPred)\n",
    "sepalPred = np.argmax(sepalPred)\n",
    "print(f\"Model predicts sepal dimensions {sample_flower} are from: {iris_species[sepalPred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "~~~text\n",
    "1/1 [==============================] - 0s 20ms/step\n",
    "[[0.0014901  0.45076337 0.5477465 ]]\n",
    "Model predicts sepal dimensions [[6.6 2.9]] are from: Iris-virginica\n",
    "~~~\n",
    "While our `sepalModel` predicted that the unknown flower was Iris-virginica, by looking at the output, we can see that it isn't very confident with this prediction. Look at the line:\n",
    "~~~text\n",
    "[[0.0014901  0.45076337 0.5477465 ]]\n",
    "~~~\n",
    "These three numbers are what the model thinks are the probabilites that the flower is Iris-setosa, Iris-versicolor _or_ Iris-virginica, respectively. \n",
    "\n",
    "Specifically, the model predicted there was a very small probabilty (0.0014901) that the sample flower species was Iris-setosa. However, it had considerable trouble deciding if the flower species was Iris-versicolor (0.45076337 or 45% chance) or Iris-virginica (0.5477465 or 55% chance). Going with the highest probability, the model \"guessed\" that it was Iris-virginica, but it still recorded that there was a 45% chance that real species was Iris-versicolor.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Use Model to Make Two _ad hoc_ Predictions\n",
    "\n",
    "You can also predict two sample flowers by stacking the sepal mesurements. \n",
    "~~~text\n",
    "# Specify the sepal length and width for the two Iris flower\n",
    "sample_flowers = np.array( [[5.9,2.8],[5.1,3.5]],\\\n",
    "        dtype=float)\n",
    "~~~\n",
    "The code for making the actual predictions is the same:\n",
    "~~~text\n",
    "sepalPred = sepalModel.predict(sample_flowers)\n",
    "~~~\n",
    "Notice that the **argmax** in the second prediction requires **axis=1**.  Since we have a 2D array now, we must specify which axis to take the **argmax** over.  The value **axis=1** specifies we want the max column index for each row.\n",
    "~~~text\n",
    "sepalPred = np.argmax(sepalPred, axis=1)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdSSkkmwCtiT",
    "outputId": "68d48b43-ea6b-4c5c-a226-9c19c0ae5060",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 7: Use the model to make two ad hoc predictions\n",
    "\n",
    "# Specify the sepal length and width for the two Iris flower\n",
    "sample_flowers = np.array( [[5.9,2.8],[5.1,3.5]],\\\n",
    "        dtype=float)\n",
    "\n",
    "# Use the neural network to predict the species\n",
    "sepalPred = sepalModel.predict(sample_flowers)\n",
    "\n",
    "# Print out the results\n",
    "print(sepalPred)\n",
    "sepalPred = np.argmax(sepalPred, axis=1)\n",
    "print(f\"Model predicts sepal dimensions {sample_flowers} are from: {iris_species[sepalPred]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similiar to the following output:\n",
    "~~~text\n",
    "1/1 [==============================] - 0s 21ms/step\n",
    "[[0.0158558  0.5222274  0.46191677]\n",
    " [0.9817724  0.0140365  0.00419102]]\n",
    "Model predicts sepal dimensions [[5.9 2.8]\n",
    " [5.1 3.5]] are from: Index(['Iris-versicolor', 'Iris-setosa'], dtype='object')\n",
    "~~~\n",
    "\n",
    "Looking at the output shown above, the `sepalModel` again had problems deciding between Iris-versicolor (prob=0.5222274 or 52%) and Iris-virginica (prob=0.46191677 or 46%) for the first flower, but was quite certain (prob=0.9817724 or 98%) that the second flower was from an Iris-setosa plant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 1: Predict Iris Species**\n",
    "\n",
    "For **Exercise 1** you are build the same neural network that was created in Example 1. Call your new neural network `petalModel`. The only real difference with your model will be the _features_ used to predict the species of an Iris flower. Rather than use sepal dimensions, you will train your model using **_petal_** dimensions (i.e. petal length and petal width). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1-Step 1: Read datafile and create DataFrame**\n",
    "\n",
    "In the cell below, write the code to read the CVS file, `iris.csv` from the course HTTPS server and store the information in a new DataFrame called `petalDF`. Shuffle and reindex the data, making sure to change the value of the random seed. Set your new `random seed = 30`. \n",
    "\n",
    "**WARNING: If you don't change the value of the random seed to `30` you won't earn full credit for this lesson!**\n",
    " \n",
    "After shuffling the data,  display the first 8 rows and columns to make sure the data was read correctly and your DataFrame was shuffled using the correct random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1-Step 1 here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following table:\n",
    "\n",
    "![___](https://biologicslab.co/BIO1173/images/class_03_3_Exe1.png)\n",
    "\n",
    "If you table looks similar but has different numbers, it means you forgot to set the random seed = 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1-Step 2: Create Feature Vector**\n",
    "\n",
    "In the cell below create a feature vector for your neural network model. \n",
    "\n",
    "You will need to modify the code used to generate your X-values. Call your X-values `petalX` and only use the data in the columns called `petal_length` and `petal_width`. \n",
    "\n",
    "Since your feature vector will be used for classification, you will need to One-Hot Encode the column `species`. The code for doing this is exactly the same as the code in Example 1-Step 2 **_except_** you must call the array holding your Y-values `petalY`. \n",
    "\n",
    "As always, make sure both your X-values and Y-values are in the correct, `float32` format.\n",
    "\n",
    "Finally, print out the first 10 values in both the DataFrame `dummies` and your `petalY` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1-Step 2 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "\n",
    "~~~text\n",
    "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
    "20             1                0               0\n",
    "5              1                0               0\n",
    "3              1                0               0\n",
    "101            0                0               1\n",
    "..           ...              ...             ...\n",
    "123            0                0               1\n",
    "145            0                0               1\n",
    "74             0                1               0\n",
    "107            0                0               1\n",
    "\n",
    "[10 rows x 3 columns]\n",
    "[[1. 0. 0.]\n",
    " [1. 0. 0.]\n",
    " [1. 0. 0.]\n",
    " [0. 0. 1.]\n",
    " [0. 1. 0.]\n",
    " [0. 1. 0.]\n",
    " [0. 0. 1.]\n",
    " [0. 0. 1.]\n",
    " [0. 1. 0.]\n",
    " [0. 0. 1.]]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1-Step 3: Construct, Compile and Train Neural Network**\n",
    "\n",
    "In the cell below, write the code to build a neural network called `petalModel`. Since your new model will trained on different data, training will cause your model to have significantly different weights and biases between neurons.  \n",
    "\n",
    "Make sure to set the input dimension to `petalX` as shown in this code chunk:\n",
    "~~~text\n",
    "petalModel.add(Dense(50, input_dim=petalX.shape[1], activation='relu')) # Hidden 1\n",
    "~~~\n",
    "Similarily, sure to set the output dimension to `petalY` as shown in this code chunk:\n",
    "~~~text\n",
    "petalModel.add(Dense(petalY.shape[1],activation='softmax')) # Output\n",
    "~~~\n",
    "As mentioned previously, when students in the course create neural network using \"copy-and-paste\", the often forget to change these values.\n",
    "\n",
    "Finally, don't forget that you need to train your `petalModel` using the X-values in `petalX` and the Y-values in `petalY`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1-Step 3 here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:\n",
    "\n",
    "~~~text\n",
    "Model: \"sequential_1\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " dense_5 (Dense)             (None, 50)                150       \n",
    "                                                                 \n",
    " dense_6 (Dense)             (None, 25)                1275      \n",
    "                                                                 \n",
    " dense_7 (Dense)             (None, 3)                 78        \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,503\n",
    "Trainable params: 1,503\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/100\n",
    "5/5 - 0s - loss: 1.0804 - 265ms/epoch - 53ms/step\n",
    "Epoch 2/100\n",
    "5/5 - 0s - loss: 1.0275 - 28ms/epoch - 6ms/step\n",
    "Epoch 3/100\n",
    "5/5 - 0s - loss: 1.0020 - 37ms/epoch - 7ms/step\n",
    "Epoch 4/100\n",
    "5/5 - 0s - loss: 0.9877 - 27ms/epoch - 5ms/step\n",
    "Epoch 5/100\n",
    "5/5 - 0s - loss: 0.9729 - 27ms/epoch - 5ms/step\n",
    "\n",
    ".......................\n",
    "\n",
    "Epoch 95/100\n",
    "5/5 - 0s - loss: 0.1660 - 18ms/epoch - 4ms/step\n",
    "Epoch 96/100\n",
    "5/5 - 0s - loss: 0.1647 - 19ms/epoch - 4ms/step\n",
    "Epoch 97/100\n",
    "5/5 - 0s - loss: 0.1629 - 20ms/epoch - 4ms/step\n",
    "Epoch 98/100\n",
    "5/5 - 0s - loss: 0.1606 - 19ms/epoch - 4ms/step\n",
    "Epoch 99/100\n",
    "5/5 - 0s - loss: 0.1629 - 20ms/epoch - 4ms/step\n",
    "Epoch 100/100\n",
    "5/5 - 0s - loss: 0.1607 - 19ms/epoch - 4ms/step\n",
    "\n",
    "<keras.callbacks.History at 0x27e47fa9610>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2: Print Predictions**\n",
    "\n",
    "In the cell below compute the predictions made by your `petalModel` and store these values in a new variable called `petalPred`. Print out the predictions for the first 10 Iris flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YzlVpw-CtiS",
    "outputId": "7b664d3d-7092-44f9-b124-c3404da038c4"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following:\n",
    "\n",
    "~~~text\n",
    "5/5 [==============================] - 0s 2ms/step\n",
    "Shape of petalPred: (150, 3)\n",
    "[[0.99420524 0.00576605 0.00002864]\n",
    " [0.98149616 0.01836091 0.000143  ]\n",
    " [0.9948488  0.00511919 0.00003205]\n",
    " [0.00001897 0.14643341 0.85354763]\n",
    " [0.00697531 0.9362573  0.05676734]\n",
    " [0.01162005 0.9580431  0.03033691]\n",
    " [0.0000592  0.24554215 0.75439864]\n",
    " [0.00000036 0.01080822 0.9891914 ]\n",
    " [0.00268251 0.90185    0.09546751]\n",
    " [0.0000111  0.36802647 0.6319624 ]]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3:  Print Predicted and Expected Values**\n",
    "\n",
    "In the cell below, print the predicted and the actual values (class) for your `petalModel`. \n",
    "\n",
    "To do this you need to find the maximum prediction for each row using this code chunk:\n",
    "~~~text\n",
    "# Find the maximum prediction for each row\n",
    "petalPredict_classes = np.argmax(petalPred,axis=1)\n",
    "~~~\n",
    "You will also have to find the expected value for each row using this code chunk:\n",
    "~~~text\n",
    "# Find the expected value for each row\n",
    "petalExpected_classes = np.argmax(petalY,axis=1)\n",
    "~~~\n",
    "\n",
    "Once you have determined these values, you can print the results with this code chunk:\n",
    "~~~text\n",
    "# Print out the results\n",
    "print(f\"Predictions: {petalPredict_classes}\")\n",
    "print(f\"Expected: {petalExpected_classes}\")\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9PSDexjCtiS",
    "outputId": "d06e6901-8168-4835-a998-ee1d43bb65d2"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "\n",
    "~~~text\n",
    "Predictions: [0 0 0 2 1 1 2 2 1 2 0 2 1 1 0 1 0 0 0 1 1 0 0 0 2 2 2 2 0 1 2 1 2 2 2 2 1\n",
    " 2 1 1 2 2 0 1 2 1 1 1 1 1 0 1 2 1 0 1 0 1 1 1 0 1 0 1 0 2 2 2 0 2 2 2 0 0\n",
    " 1 0 2 2 2 2 0 1 0 1 1 1 2 0 1 0 1 2 1 0 0 0 2 2 0 1 1 1 0 0 0 0 2 0 2 0 0\n",
    " 2 2 2 0 2 1 1 2 1 1 1 1 2 0 1 0 1 0 0 0 2 1 0 0 1 1 2 2 2 0 1 1 0 2 1 2 2\n",
    " 0 0]\n",
    "Expected: [0 0 0 2 1 1 2 2 1 2 0 2 1 1 0 1 0 0 0 1 2 0 0 0 2 2 1 2 0 1 2 1 2 2 2 2 1\n",
    " 2 1 2 2 2 0 1 2 1 1 1 1 1 0 1 2 1 0 1 0 1 1 1 0 1 0 1 0 2 2 2 0 2 1 2 0 0\n",
    " 1 0 2 2 2 2 0 1 0 1 1 1 2 0 1 0 1 2 1 0 0 0 2 2 0 1 1 1 0 0 0 0 2 0 2 0 0\n",
    " 2 2 2 0 2 1 1 2 1 1 1 1 2 0 1 0 1 0 0 0 2 1 0 0 1 2 2 2 2 0 1 2 0 2 1 2 2\n",
    " 0 0]\n",
    "~~~\n",
    "\n",
    "This output shows your model's prediction of each flower's species (top array) as well as their actual (expected) species name (bottom array). The number `0` means Iris-setosa, `1` means Iris-versicolor and `2` means Iris-virginica. Just by a simple, visual comparison, you can see that your model did a very good job predicting a flower's species based on its petal dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrcy0Q4xCtiT"
   },
   "source": [
    "### **Exercise 4: Convert Index Values into Species Names**\n",
    "\n",
    "In the cell below, print out the first 5 values in `petalPredict_classes` and then using the index variable `iris_species`, print the species names of these first 5 flowers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTORTvygCtiT",
    "outputId": "a931a4d1-3204-42de-af37-a366ec2ba353"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 4 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see:\n",
    "~~~text\n",
    "petalPredict_classes: [0 0 0 2]\n",
    "Iris-setosa Iris-setosa Iris-setosa Iris-virginica\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ljez1ZRACtiT"
   },
   "source": [
    "### **Exercise 5: Compute the Accuracy Score**\n",
    "\n",
    "In the cell below, compute the accuracy score for your `petalModel` neural network model. Use the f-sting print statement to print the accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zth2S2OcCtiT",
    "outputId": "f68a373c-f84e-4d01-8e83-dc22199e76ff"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exericse 5 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following output:\n",
    "~~~text\n",
    "Accuracy: 0.96\n",
    "~~~\n",
    "WOW! Your `petalModel` is roughly 95% accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy for your `petalModel` is substantially higher than the accuracy of `sepalModel` created in Example 1. \n",
    "\n",
    "Since the same neural network architecture was used for both models, this difference in accuracy must mean that **_petal_** dimensions are more different in these 3 Iris species than their **_sepal_** dimensions. \n",
    "\n",
    "You can verify this fact by comparing the mean dimensions for sepal and petals shown below in the Appendix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jY07aiLICtiT"
   },
   "source": [
    "### **Exercise 6: Use the Model to Make an _ad hoc_ Prediction**\n",
    "\n",
    "Use your `petalModel` to make an _ad hoc_ prediction of an unknown Iris species. You measured the petal length to be 1.5 cm and a petal width of 0.3 cm. Print out the model's prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZUSWVGnCtiT",
    "outputId": "d98e7cc3-7e10-44f0-a5cb-b858f3c4c850"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 6 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following:\n",
    "~~~text\n",
    "1/1 [==============================] - 0s 19ms/step\n",
    "[[0.9773777  0.02249157 0.00013073]]\n",
    "Model predicts flower with petal dimensions [[1.5 0.3]] is: Iris-setosa\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 7: Use Model to Make Two _ad hoc_ Predictions**\n",
    "\n",
    "Use your `petalModel` to make 2 _ad hoc_ predictions. The petal dimensions are 4.2 and 1.3 cm for the first flower and 5.1 and 3.5 cm for the second flower. As in Exercise 6, print out the model's predictions as probabilies and then the two highest probabilites as the model's final choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdSSkkmwCtiT",
    "outputId": "68d48b43-ea6b-4c5c-a226-9c19c0ae5060"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 7 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following:\n",
    "~~~text\n",
    "1/1 [==============================] - 0s 22ms/step\n",
    "[[0.00969335 0.7415197  0.24878693]\n",
    " [0.00000006 0.00312731 0.99687254]]\n",
    "Model predicts flowers with petal dimensions [[4.2 1.3]\n",
    " [5.1 3.5]] are: Index(['Iris-versicolor', 'Iris-virginica'], dtype='object')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lesson Turn-in**\n",
    "\n",
    "When you have completed all of the code cells, and run them in sequential order (the last code cell should be number 21, **not** counting the 4 code cells in the Appendix below). Use the **File --> Print.. --> Save to PDF** to generate a PDF of your JupyterLab notebook. Save your PDF as `Class_03_3.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "\n",
    "### **Appendix**\n",
    "\n",
    "One of the more interesting results of this lesson was the ability of a very simple neural network to more accurately predict a flower's species when it had been trained on petal dimensions compared to sepal dimensions. Specifically, the accuracy of your `petalModel` was close to 95% while the `sepalModel` was only about 75% accurate. \n",
    "\n",
    "Since these two neural networks had exactly the same architecture, and were both trained for 100 epochs, the difference in accuracy must be attributable to species specific differences in sepal and petal dimensions. In other words, the **_range_** in petal dimensions must be more pronounced in these 3 Iris species than their sepal dimensions.  \n",
    "\n",
    "In the cells below, the Pandas `df.groupby()` function was used to compute the mean values of sepal length, sepal width, petal width, and petal width in the three different Iris flower species, _I. setosa_, _I. versicolor_, and _I. virginica_. \n",
    "\n",
    "As expected, species differences for the mean petal dimensions are much greater than the mean sepal dimensions. These differences are sufficient to explain why the accuracy of your `petalModel` was so much higher (\\~95% accurate) than the `sepalModel` (\\~75% accurate).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Iris flower species by mean Sepal Length\n",
    "print(\"Mean SEPAL LENGTHS by species\")\n",
    "sepal_length = petalDF.groupby('species')['sepal_length'].mean()\n",
    "sepal_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Iris flower species by mean Sepal Width\n",
    "print(\"Mean SEPAL WIDTHS by species\")\n",
    "sepal_width = petalDF.groupby('species')['sepal_width'].mean()\n",
    "sepal_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Iris flower species by mean Petal Length\n",
    "print(\"Mean PETAL LENGTHS by species\")\n",
    "petal_length = petalDF.groupby('species')['petal_length'].mean()\n",
    "petal_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Iris flower species by mean Petal Width\n",
    "print(\"Mean PETAL WIDTHS by species\")\n",
    "petal_width = petalDF.groupby('species')['petal_width'].mean()\n",
    "petal_width"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
