{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1k3z0a1S7pkKlE5cxvPU+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/main/Assignment_01_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ],
      "metadata": {
        "id": "ZNirsAlIEuxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ],
      "metadata": {
        "id": "HhOPZPgmEus_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment 1: Neural Networks for Analysis of Tabular Data**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
        "\n"
      ],
      "metadata": {
        "id": "tS0hL9bkEum_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **READ CAREFULLY**\n",
        "\n",
        "The **_first_**  digit in your myUTSA ID (e.g. \"abc123\") will determine which dataset you are to analyze for this assignment and which type of neural network (i.e. classification or regression) you will need to construct. For example, if your myUTSA ID was **vue682**, then your first digit is the number `6`.\n",
        "\n",
        "**---WARNING------WARNING------WARNING------WARNING------WARNING------WARNING---**\n",
        "\n",
        "You are **not** free to choose any dataset for this assignment. If analyze the wrong dataset, your assignment will **NOT BE GRADED** and you will automatically receive a **`0`**. If you are uncertain which dataset you should be working on, contact your Instructor for help. Remember, your score in this assignment will have a large impact on your course grade so please be careful.\n",
        "\n",
        "\n",
        "| First Digit myUTSA ID    | Dataset to Analyze      | Neural Network Type\n",
        "--------------------------|-------------------------|-----------------\n",
        "0                         | Hepatitis               | Binary Classification\n",
        "1                         | Coimbra Breast Cancer   | Binary Classification\n",
        "2                         | Parkinson Speech        | Binary Classification\n",
        "3                         | Indian Liver            | Binary Classification\n",
        "4                         | Thyroid Replacement     | Multiclass Classification\n",
        "5                         | Wine Quality            | Multiclass Classification\n",
        "6                         | Liver Disease           | Multiclass Classification\n",
        "7                         | Bone Marrow Transplant  | Regression\n",
        "8                         | German Breast Cancer    | Regression\n",
        "9                         | Diabetes Progression    | Regression\n",
        "\n",
        "#### **NOTE: You can only use this Colab notebook if the first digit of your _myUTSA_ ID  is between `0` and `3`.**"
      ],
      "metadata": {
        "id": "x0SZ0iP-EuYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Purpose of Assignments**\n",
        "\n",
        "In this course, **_Assignments_** are designed to help me (and you) assess your ability to transfer knowledge gained in completing class coding exercises to solving more realistic problems.\n",
        "\n",
        "Assignments play a pivotal role in reinforcing your learning, as they require you to apply theoretical concepts to practical scenarios. This helps solidify your understanding and enhances your problem-solving skills. By tackling these assignments independently, you develop critical thinking and the ability to synthesize information from various sources. Moreover, assignments encourage you to explore topics more deeply, fostering intellectual curiosity and promoting a deeper engagement with the subject matter. Ultimately, these assignments are not just a measure of your learning, but a means to equip you with the skills needed for real-world applications and future challenges."
      ],
      "metadata": {
        "id": "Ze8uywoTFYx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MAKE A COPY OF THIS NOTBOOK!**\n",
        "\n",
        "For your assignment to be graded, you **must** make a copy of this Colab notebook in your GDrive and use this copy as your worksheet."
      ],
      "metadata": {
        "id": "S5SeEYKrFcYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. By running this code cell, you will map your GDrive to /content/drive and print out your Google GMAIL address. Your Instructor will use your GMAIL address to verify the author of this class lesson."
      ],
      "metadata": {
        "id": "OZA5LczUFcvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C50uDh3DodE"
      },
      "outputs": [],
      "source": [
        "# YOU MUST RUN THIS CELL FIRST\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    Colab = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"**WARNING**: Your GMAIL address was **not** printed in the output below.\")\n",
        "    print(\"**WARNING**: You will NOT receive credit for this assignment.\")\n",
        "    Colab = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your GMAIL address **must** appear in the output in order for your work to be graded. If your GMAIL is not visible you will receive a `0` for your grade. You will not be given a second chance to fix this problem!"
      ],
      "metadata": {
        "id": "4vxXQyP-FpAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assigment 1: Regression**\n",
        "\n",
        "**Assignment_01** is specifically designed to assess your ability to write the Python/Tensorflow/Keras code necessary to build neural networks that can analyze tabular data stored in a Pandas DataFrame. These analyzes include: (1) binary classification, (2) multiclass classification and (3) regression.\n",
        "\n",
        "You will use this Colab notebook **only** if the first digit in your myUTSA ID is between `7` and `9`. If that is correct, you have been assigned to perform **regression**.\n",
        "\n",
        "Unlike your class lessons, you will **not** be given examples that you can use to simply copy-and-paste code. Rather, you will be given a problem to solve and it will be up to you to use code snippets that you have been given previously to solve different aspects of this assignment. And unlike your class lessons, your will **not** be given the correct output. In other words, this assignment is basically how you would solve an actual biomedical problem.\n"
      ],
      "metadata": {
        "id": "xM9Obi2W56lD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression by Neural Networks**\n",
        "**Regression** of tabular data is a type of supervised learning task where the goal is to predict a continuous target variable based on the attributes of the observations.\n",
        "\n",
        "#### **Regression:**\n",
        "Regression deals with problems where the outcome is a continuous variable. Examples include:\n",
        "1. **Medical Predictions:**\n",
        "   - Predicting blood pressure levels based on patient attributes.\n",
        "   - Estimating the progression of a disease over time.\n",
        "   - Forecasting patient recovery times after surgery.\n",
        "   - Estimating the cost of medical treatments.\n",
        "\n",
        "2. **Biological Predictions:**\n",
        "   - Predicting enzyme activity levels based on substrate concentration.\n",
        "   - Estimating growth rates of bacteria or cell cultures under different conditions.\n",
        "   - Forecasting gene expression levels based on environmental factors.\n",
        "   - Estimating the concentration of hormones in blood samples.\n",
        "\n",
        "3. **Disease Progression:**\n",
        "   - Predicting tumor growth rates based on imaging data.\n",
        "   - Estimating the severity of disease symptoms over time.\n",
        "   - Forecasting the spread of infectious diseases in a population.\n",
        "   - Estimating the decline in lung function in patients with respiratory diseases.\n",
        "\n",
        "4. **Treatment Outcomes:**\n",
        "   - Predicting patient response to different medication dosages.\n",
        "   - Estimating the duration of hospital stays based on initial symptoms.\n",
        "   - Forecasting the likelihood"
      ],
      "metadata": {
        "id": "YQWjLrJ26NW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Descriptions of Data Sets for Regression**\n",
        "\n",
        "This section describes the various datasets, information for downloading them, and what variable(s) your network should predict. Remember, you do **not** earn and credit if you analyze the wrong dataset. Pay particular attention to the **variable for Regression** for your assigned dataset. You will need to know the name of this feature when you are constructing yor `X-` and `Y-feature` vectors.\n"
      ],
      "metadata": {
        "id": "hZt1gey66RrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------\n",
        "\n",
        "\n",
        "## **Bone Marrow Transplant - 1st myUTSA Digit = 7**\n",
        "\n",
        "#### **Filename:** `bone_marrow_transplant.csv`\n",
        "#### **Response Variable for Regression (Y):** `survival_time`\n",
        "\n",
        "### **Bone Marrow Transplant dataset**\n",
        "\n",
        "The **Bone Marrow Transplant** dataset describes pediatric patients with several hematologic diseases: malignant disorders (e.g. patients with acute lymphoblastic leukemia, with acute myelogenous leukemia, with chronic myelogenous leukemia, with myelodysplastic syndrome) and nonmalignant cases (i.a. patients with severe aplastic anemia, with Fanconi anemia, with X-linked adrenoleukodystrophy).\n",
        "\n",
        "All patients were subject to the unmanipulated allogeneic unrelated donor hematopoietic stem cell transplantation.\n",
        "\n",
        "The motivation of this study was to identify the most important factors influencing the success or failure of the transplantation procedure. In particular, verification of the research hypothesis that increased dosage of CD34+ cells / kg extends overall **survival time** without simultaneous occurrence of undesirable events affecting patients' quality of life.\n",
        "\n",
        "#### Features:\n",
        "\n",
        "1. **Recipientgender:** Male, Female\n",
        "- **Stemcellsource:** Source of hematopoietic stem cells (Peripheral blood - 1\t Bone marrow - 0)\n",
        "2. **Donorage:** Age of the donor at the time of hematopoietic stem cells apheresis\n",
        "3. **Donorage35:** - Donor age <35 - 0\t Donor age >=35 - 1\n",
        "- **IIIV:** - Development of acute graft versus host disease stage II or III or IV (Yes - 1\t No - 0)\n",
        "4. **Gendermatch:** Compatibility of the donor and recipient according to their gender (Female to Male - 1\t Other - 0)\n",
        "- **DonorABO:** ABO blood group of the donor of hematopoietic stem cells (0 - 0\t1\t A\t B=-1\t AB=2)\n",
        "5. **RecipientABO:** ABO blood group of the recipient of hematopoietic stem cells (0 - 0\t1\t A\t B=-1\t AB=2)\n",
        "6. **RecipientRh:** Presence of the Rh factor on recipientï¿½s red blood cells ('+' - 1\t '-' - 0)\n",
        "7. **ABOMatch:** Compatibility of the donor and the recipient of hematopoietic stem cells according to ABO blood group (matched - 1\t mismatched - 1)\n",
        "8. **CMVstatus:** Serological compatibility of the donor and the recipient of hematopoietic stem cells according to cytomegalovirus\n",
        "infection prior to transplantation (the higher the value the lower the compatibility)\n",
        "9. **RecipientCMV:** Presence of cytomegalovirus infection in the donor of hematopoietic stem cells prior to transplantation (presence - 1\t absence - 0)\n",
        "10. **Disease:** Type of disease (ALL\tAML\tchronic\tnonmalignant lymphoma)\n",
        "11. **Riskgroup:** High risk - 1\t Low risk - 0\n",
        "12. **Txpostrelapse:** The second bone marrow transplantation after relapse (No - 0; Yes - 1)\n",
        "13. **Diseasegroup:** Type of disease (malignant - 1\t nonmalignant - 0)\n",
        "14. **HLAmatch:** Compatibility of antigens of the main histocompatibility complex of the donor and the recipient of hematopoietic stem cells\t\t\t\t\taccording to ALL international BFM SCT 2008 criteria\n",
        "15. **HLAmismatch:** - HLA matched - 0\t HL mismatched - 1\n",
        "16.**Antigen:** In how many anigens there is difference beetwen the donor nad the recipient (-1 - no differences\t 0 - one difference\t1 (2) - two (three) diffences)\n",
        "17. **Allel:** In how many allele there is difference beetwen the donor nad the recipient {-1 no differences\t0 - one difference\t 1 (2) (3) - two\t (tree\t four) differences)\n",
        "18. **HLAgrI:** The differecne type beetwien the donor and the recipient (HLA mateched - 0\tthe difference is in only one antigen - 1, the difference is only in one allel - 2, the difference is only in DRB1 cell - 3, two differences (two allele or two antignes) - 4, two differences (two allele or two antignes) - 5)\n",
        "19. **Recipientage:** Age of the recipient of hematopoietic stem cells at the time of transplantation\n",
        "20. **Recipientage10:**  Recipient age <10 - 0\t Recipient age>=10 - 1\n",
        "21. **Recipientageint:** Recipient age in (0\t5] - 0\t (5\t 10] - 1\t (10\t 20] - 2\n",
        "22. **Relapse:** Reoccurrence of the disease (No - 0\t Yes - 1)\n",
        "23. **aGvHDIIIIV:** Development of acute graft versus host disease stage III or IV (Yes - 0\t No - 1)\n",
        "24. **extcGvHD:** Development of extensive chronic graft versus host disease (Yes - 0\t No - 1)\n",
        "25. **CD34kgx10d6:** CD34+ cell dose per kg of recipient body weight (10^6/kg)\n",
        "26. **CD3dCD34:** CD3+ cell to CD34+ cell ratio\n",
        "27. **CD3dkgx10d8:** CD3+ cell dose per kg of recipient body weight (10^8/kg)\n",
        "28. **Rbodymass:** Body mass of the recipient of hematopoietic stem cells at the time of transplantation\n",
        "29. **ANCrecovery:** Time to neutrophils recovery defined as neutrophils count >0.5 x 10^9/L\n",
        "30. **PLTrecovery:**  Time to platelet recovery defined as platelet count >50000/mm3\n",
        "31. **time_to_aGvHD_III_IV:** Time to development of acute graft versus host disease stage III or IV\n",
        "32. **survival_time:** Survival time in days -- Response Variable (Y values)\n",
        "33. **survival_status:** Survived (Yes - 0 No - 1)"
      ],
      "metadata": {
        "id": "CHZ3oEXB6dcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------\n",
        "\n",
        "## **German Breast Cancer Dataset - 1st myUTSA Digit = 8**\n",
        "\n",
        "#### **Filename:** `GermanBreastCancer.csv`\n",
        "#### **Response Variable for Regression (Y):** `time`\n",
        "\n",
        "### **German Breast Cancer Study Group (GBSG2) dataset**\n",
        "\n",
        "The **German Breast Cancer Study Group (GBSG2)** dataset studies the effects of hormone treatment on recurrence-free survival time. The event of interest is the recurrence of cancer time. This data frame contains the observations of 686 women.\n",
        "\n",
        "#### Features:\n",
        "\n",
        "1.**horTh:** hormonal therapy, a factor at two levels (yes 1 and no 2).\n",
        "2. **age:** age of the patients in years.\n",
        "3. **menostat:** menopausal status, a factor at two levels pre (premenopausal = 1) and post (postmenopausal = 2).\n",
        "4. **tsize:** tumor size (in mm).\n",
        "5. **tgrade:** tumor grade, a ordered factor at levels 1 < 2 < 3.\n",
        "6. **pnodes:** number of positive nodes.\n",
        "7. **progrec:** progesterone receptor (in fmol).\n",
        "8. **estrec:** estrogen receptor (in fmol).\n",
        "9. **time:** recurrence free survival time (in days). Response variable (Y values)\n",
        "10. **cens:** censoring indicator (0- censored, 1- event).\n"
      ],
      "metadata": {
        "id": "jR-suFQC6dTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------\n",
        "\n",
        "## **Diabetes Progression Dataset - 1st myUTSA Digit = 9**\n",
        "\n",
        "#### **Filename:** `diabetes_progrssion.csv`\n",
        "\n",
        "#### **Response Variable for Regression (Y):** `disease_progression`\n",
        "\n",
        "**Diabetes** is more than just a high blood sugar condition; it’s a complex, chronic illness that, if not managed properly, can lead to severe health complications like heart disease, nerve damage, and kidney failure. Recognizing the urgency of effective management, I embarked on a project to predict diabetes progression using advanced data science techniques. This project involved regression analysis, data visualization, and model evaluation. The complete code is available on my GitHub page, aiding better medical decision-making and patient care.\n",
        "\n",
        "**Dataset Overview**\n",
        "\n",
        "The Diabetes dataset, a mainstay in regression analysis, includes ten baseline variables such as age, sex, BMI, average blood pressure, and six blood serum measurements for 442 diabetes patients. The target variable is a quantitative measure of disease progression one year after the baseline.\n",
        "\n",
        "**Data Characteristics:**\n",
        "**Number of Instances:** 442\n",
        "**Number of Attributes:** 10 numeric predictive values\n",
        "**Target:** Quantitative measure of disease progression\n",
        "\n",
        "**Attribute Information:**\n",
        "- **age:** Age in years\n",
        "- **sex:** Gender of the patient\n",
        "- **bmi:** Body mass index\n",
        "- **bp:** Average blood pressure\n",
        "- **serum_chol:** Total serum cholesterol (mg/dL)\n",
        "- **ldl:** Low-density lipoproteins (mg/dL)\n",
        "- **hdl:** High-density lipoproteins (mg/dL)\n",
        "- **chol_hdl_ratio:** Total cholesterol / HDL\n",
        "- **log_trigly:** Log of serum triglycerides level\n",
        "- **blood_glu:** Blood sugar level (mg/dL)\n",
        "- **disease_progression:** Disease progression one year after baseline. Response variable (Y values)"
      ],
      "metadata": {
        "id": "dhfA8FOX6ol3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Instructions**\n",
        "\n",
        "To make the assignment more manageable, you will given a number of specific steps to perform. To help guide you in writing your code, you will be given a specific example in a particular class lesson that you can use for a reference. For example, in **Step 1: Download and Extract Data** you are given **REF: Class_01_6: Examples 1 & 2**. That means Examples 1 and 2 in `Class_01_6` provide code that you can use to complete that step of this assignment.\n",
        "\n",
        "### **Variable Names**\n",
        "\n",
        "In writing your code for this assignment, you are free to give your variables any name that makes sense to you. This includes the name of the DataFrame that holds your data. When you `copy-and-paste` code from earlier Class assignments, you always have to edit the name of the DataFrame to match the name you select for this assignment in **Step 1**.\n",
        "\n",
        "When it has been necessary to give an example that includes a DataFrame name, the DataFrame has been called `df` or `my_df`. You will need to edit these names to match the actual name you give to your DataFrame in **Step 1**.\n",
        "\n",
        "### **Can I Use AI?**\n",
        "\n",
        "You are free to use AI (e.g. Microsoft Co-Pilot) to help you complete your assignment---but you need to be very careful.\n",
        "\n",
        "While AI can be very helpful in correcting coding errors, but it can also give you code that is totally incorrect for this assignment. A small number of students in previous classes have flunked their assignment by using AI code that did not generate the correct output. Useless you give the AI a well-constructed prompt, the answer you get back might lead you in the wrong direction.\n",
        "\n",
        "If your aren't sure what you are doing, it's **much, much safer to get help with any of your coding problems from your course instructor and/or course TA's.**"
      ],
      "metadata": {
        "id": "zglo_zTrG4d9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create functions\n",
        "\n",
        "The cell below creates a custom function needed for this assignment. If you don't run this cell, you will receive errors later when you try to run some cells."
      ],
      "metadata": {
        "id": "M2aQbHe5G4P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create functions for this lesson\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 0️⃣  Create hms_string()\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "# Simple function to print out elasped time\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "metadata": {
        "id": "6vuDFK-5HKg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Download and Extract Data**\n",
        "\n",
        "**REF: Class_01_6: Examples 1 & 2**\n",
        "\n",
        "In the cell below, write the code to download your datafile from the course server and create a `Pandas` DataFrame to store your data. Are are free to use any name for DataFrame, just make sure to keep it consistent throughout the assignment.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. When using the command `pd.read_csv()` the file separator argument `sep` will be always be a comma **`,`**\n",
        "\n",
        "2. You can **only** use the assigned dataset that you download from the course file server https://biologicslab.co even if you find a dataset with the same name at a different web location.\n",
        "\n",
        "3. Use this code to set your display settings:\n",
        "```text\n",
        "# Set max columns and max rows\n",
        "pd.set_option('display.max_columns', my_df.shape[1])\n",
        "pd.set_option('display.max_rows', 8)\n",
        "```\n",
        "4. At the end of the cell use the function `display(df)` to show your DataFrame.\n"
      ],
      "metadata": {
        "id": "I8o6hPfSG301"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download and Extract Data\n",
        "\n"
      ],
      "metadata": {
        "id": "6wueN8hyIYDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct you should see a table with a relatively large number of columns that may very well extend beyond the right edge of your notebook display."
      ],
      "metadata": {
        "id": "hClhWLb8IdNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Print Summary Statistics**\n",
        "\n",
        "**REF: Class_01_6: Example 3**\n",
        "\n",
        "In the cell below use `df.describe()` to print put the summary statistics of your DataFrame.  \n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "Use this code to set your print output:\n",
        "```text\n",
        "# Set max columns and max rows\n",
        "pd.set_option('display.max_columns', 12)\n",
        "pd.set_option('display.max_rows', 8)\n",
        "```\n"
      ],
      "metadata": {
        "id": "9JXxQm3QNTPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Print summary statistics\n",
        "\n"
      ],
      "metadata": {
        "id": "zmIr8IptNsMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your output should be table showing summary statistics for each column in your DataFrame."
      ],
      "metadata": {
        "id": "kAgUPj80N8bV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Find Missing Values**\n",
        "\n",
        "**REF: Class_01_6: Example 4**\n",
        "\n",
        "Use `df.isnull()` to find any missing values in your DataFrame. Print out the missing locations in two vertical columns titled `column_name` and `has_missing`.  \n"
      ],
      "metadata": {
        "id": "Fs6Id0FRImr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Find missing values\n",
        "\n"
      ],
      "metadata": {
        "id": "HpF_DeydIwkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct you should see a list of all the columns in your DataFrame and whether or not any column has one (or more) missing data. Make careful note of name of any column that is missing data."
      ],
      "metadata": {
        "id": "8DEOVMzkIzAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4: Replace Missing Values**\n",
        "\n",
        "**REF: Class_01_6: Example 5**\n",
        "\n",
        "Use `df.fillna()` to replace any missing values in your DataFrame with the median value of that column. Use the same print commands as in `Class_01_6: Example 5` to show what was done."
      ],
      "metadata": {
        "id": "jG2dMQGBiG7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Replace missing values\n"
      ],
      "metadata": {
        "id": "2UEmD6aglnf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see the same list that was generated by Step 2 except now all of the values in the `has_missing` column should now be `False`.  "
      ],
      "metadata": {
        "id": "vTneGIKoVvT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5: Display Data Types**\n",
        "\n",
        "**REF: Class_02_2: Example 1 - Step2**\n",
        "\n",
        "Display the different data types in your DataFrame using `df.info()` method.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "Set your print option using this code chunk:\n",
        "```text\n",
        "# Set max rows to the number of columns\n",
        "pd.set_option('display.max_rows', len(df.columns))\n",
        "```\n",
        "where `df` is the name of your DataFrame."
      ],
      "metadata": {
        "id": "9lhujPUbXL7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Display data types\n"
      ],
      "metadata": {
        "id": "n_9WMRbEZsQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the very bottom of the output will be the strings that you will need to map to an integer in the next step."
      ],
      "metadata": {
        "id": "1zjIf9Z8apIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the column `Dtype` for the word `object`. This means the column contains string values that need to be mapped to an integer value."
      ],
      "metadata": {
        "id": "MU9-WUfdYwU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6: Map Strings to Integers**\n",
        "\n",
        "**REF: Class_01_6: Example 9**\n",
        "\n",
        "In the cell below write the code to map the strings shown in the output of the previous cell (Step 5) to an integer. Depending upon the dataset, 2-4 strings will need to be mapped. Always start your mapping with the integer `0`.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. Set the variable `col_name_map` to the string following the word `Column:` at the bottom of the output from `Step 5` above.\n",
        "\n",
        "2. The names immediately below the word `Column:` are the strings that you need to map to an integer.\n",
        "\n",
        "Use the `display()` function to print out **only** the contents of the column that you are mapping, before and then after the mapping has been performed."
      ],
      "metadata": {
        "id": "DxIEjoG7W4Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Map strings to integers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o2bF0DqwdVyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After mapping the mapped column in your `DataFrame` should now contain only integers (**`dtype`**:int64)."
      ],
      "metadata": {
        "id": "y2di5K_Tei4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 7: Create Feature Vectors for Regression Neural Network**\n",
        "\n",
        "**REF: Class_02_2: Example 6**\n",
        "\n",
        "In the cell below, write the code to preprocess the data in your DataFrame to create `X-` and `Y-` feature vectors.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. The name of the target column (`TARGET_COL`), the `Y-values`, was given as part of the description of your assigned dataset at the beginning of this assignment.\n",
        "\n",
        "2. Pre-process your data using the code in `Block 2` of `Example 7`:\n",
        "```text\n",
        "# ------------------------------------------------------------------\n",
        "# 2️⃣  Pre‑processing pipeline\n",
        "# ------------------------------------------------------------------\n",
        "```\n",
        "3. Split your data as shown in `Block 3` of `Example 7`\n",
        "```text\n",
        "# ------------------------------------------------------------------\n",
        "# 3️⃣  Split into train / test sets\n",
        "# ------------------------------------------------------------------\n",
        "```\n",
        "4. Fit the transformer as shown in `Block 4` of `Example 7`\n",
        "```text\n",
        "# ------------------------------------------------------------------\n",
        "# 4️⃣  Fit the transformer on the training data\n",
        "# ------------------------------------------------------------------\n",
        "```\n",
        "\n",
        "5. Scale your target using the code in `Block 5` of `Example 7`\n",
        "```text\n",
        "# ------------------------------------------------------------------\n",
        "# 5️⃣  Scale the target\n",
        "# ------------------------------------------------------------------\n",
        "```\n",
        "\n",
        "6. Inspect your data using the code in `Block 6` of `Example 7`\n",
        "```text\n",
        "# ------------------------------------------------------------------\n",
        "# 6️⃣  Inspect the first few rows\n",
        "# ------------------------------------------------------------------\n",
        "```"
      ],
      "metadata": {
        "id": "PC9W0pgzJ6uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Create feature vector for Regression Neural Network\n",
        "\n"
      ],
      "metadata": {
        "id": "iJVg__RH8Y4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you code is correct you should see the first 4 rows of the processed `X` data and below their corresponding y values."
      ],
      "metadata": {
        "id": "2wNV9kzCaUwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 8: Construct and Compile Regression Neural Network**\n",
        "\n",
        "**REF: Class_02_2 Example 7**\n",
        "\n",
        "In the cell below write the code to construct and compile a regression neural network.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. Start by importing the following packages:\n",
        "```text\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping,\n",
        "    ModelCheckpoint,\n",
        "    ReduceLROnPlateau,\n",
        ")\n",
        "```\n",
        "\n",
        "2. Build a regression model with an input layer --> dense layer with 25 neurons --> drop out layer --> dense layer with 50 neurons --> output layer with 1 neuron.\n",
        "\n",
        "4. Compile your neural network using `\"mean_squared_error\"` as the loss, the `Adam` optimizer with an initial learning rate set to `0.0010` and `mae` as the metrics.\n",
        "\n",
        "\n",
        "**IMPORTANT:** Do **not** start training your model yet. This will be done in a separate step."
      ],
      "metadata": {
        "id": "ZDz5O3hkKOAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Constructr and compile regression neural network\n"
      ],
      "metadata": {
        "id": "zOcjHFKt93Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct, you should **not** see any output after running the previous cell. If you see any output you didn't follow directions and your grade will be reduced accordingly."
      ],
      "metadata": {
        "id": "-CNJISn-KN0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 9: Print Model Summary**\n",
        "\n",
        "**REF: Class_02_4: Example 4**\n",
        "\n",
        "In the cell below, use the `model.summary()` command to print out the information about your neural network.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "You only need to write a **single line of code** in the cell below."
      ],
      "metadata": {
        "id": "FS1Qew2DKWMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Print Summary of Your Model\n",
        "\n"
      ],
      "metadata": {
        "id": "8ySuP7U8KjcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct you should see a table showing the 5 layers in your neural network model, their `Output Shape` and their number of parameters."
      ],
      "metadata": {
        "id": "qVvVJch6ZeYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 10: Create `callbacks`**\n",
        "\n",
        "**REF: Class_02_2: Example 7**\n",
        "\n",
        "\n",
        "Write the code to add `callbacks` to monitor your model's training.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. You should add the following imports at the top of the code cell:\n",
        "```text\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping,\n",
        "    ModelCheckpoint,\n",
        "    ReduceLROnPlateau,\n",
        ")\n",
        "```\n",
        "2. You should add the follow code to define your parameters:\n",
        "```text\n",
        "EPOCHS = 100\n",
        "PATIENCE = 20\n",
        "VERBOSE=2\n",
        "lr = 0.0010\n",
        "OPTIMIZER = Adam(learning_rate=lr)\n",
        "```\n",
        "3. `Example 7` in `Class_02_2` shows the code to needed to create `EarlyStopping`, `ModelCheckpoint` and `ReduceLROnPlateu` callbacks. Do **not** copy all of the code in `Example 7`, just the code snippet within the section called:\n",
        "\n",
        "```text\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4️⃣ Add Callbacks\n",
        "# ---------------------------------------------------------------------------\n",
        "```"
      ],
      "metadata": {
        "id": "QBaoq4eAKmIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Create callbacks\n",
        "\n"
      ],
      "metadata": {
        "id": "CRc1vNJVKsIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct, you should not see any output."
      ],
      "metadata": {
        "id": "OyjRWGggKl8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 11: Train the Model**\n",
        "\n",
        "**REF: Class_02_2: Example 7**\n",
        "\n",
        "In the cell below, write the Python code to train the regression neural network that you constructed in **Step 10**. Set the number of epochs to `100`. Make sure the parameter `verbose` is set to `2` so that the output of each epoch is written out.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. Use the code in `Block 1` of `Example 7` to define parameters:\n",
        "```text\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1️⃣ Define parameters\n",
        "# ---------------------------------------------------------------------------\n",
        "EPOCHS = 100\n",
        "PATIENCE = 20\n",
        "VERBOSE = 2\n",
        "lr = 0.0010\n",
        "OPTIMIZER = Adam(learning_rate=lr)\n",
        "\n",
        "```\n",
        "2. Use the code in `Block 4` of `Example 7` to train your model.\n",
        "\n",
        "```text\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4️⃣ Train model\n",
        "# ---------------------------------------------------------------------------\n",
        "```\n",
        "\n",
        "3. Use the code in `Block 5` of `Example 7` to inspect your training:\n",
        "\n",
        "```text\n",
        "# ---------------------------------------------------------------------------\n",
        "# 5️⃣ Inspect training\n",
        "# ---------------------------------------------------------------------------\n",
        "```\n",
        "\n",
        "**NOTE:** Make sure that your code prints out the `Elapsed time:` formatted as `hr:min:sec` at the end of training."
      ],
      "metadata": {
        "id": "856IrePpKWB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Train the Model\n",
        "\n"
      ],
      "metadata": {
        "id": "IcR2UkBLK1Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you code is correct you should see the output generated by each epoch during training with the `Best validation accuracy` and the `Elapsed time` print at the end of the output."
      ],
      "metadata": {
        "id": "eeyAqS_dWIXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 12: Plot Predicted vs Actual**\n",
        "\n",
        "**REF: Class_02_2 Example 9**\n",
        "\n",
        "\n",
        "In the cell below, write the code to generate a plot of **Predicted** vs **Actual** to visualized what happened during training of your model. The plot should show a dashed red line showing `Perfect Prediction`."
      ],
      "metadata": {
        "id": "3k0Bzdp9K6Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Plot predicted vs actual\n",
        "\n"
      ],
      "metadata": {
        "id": "490G7DjDAop2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct you should see a single plot showing `Predicted vs Actual Values` with a dashed red line showing `Perfect Predictions`."
      ],
      "metadata": {
        "id": "GDX9-4otW9H8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Assignment Turn-in**\n",
        "\n",
        "When you have completed and run all of the code cells, use the **File --> Print.. --> Save to PDF** to generate a PDF of your Colab notebook. Save your PDF as `Copy of Assignment_01.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas.\n",
        "\n",
        "## **---WARNING---WARNING--WARNING---**\n",
        "\n",
        "Unlike class lessons, you are **only given 1 submission** for assignments. If you failed to carefully follow directions and make a bad mistake you won't have a 2nd chance to correct your errors.\n",
        "\n",
        "Therefore, you are **STRONGLY ENCOURAGED** to have your completed assignment checked by an Instructor **_before_** you submit your PDF to Canvas. Every semester one (or more) students fail to follow directions and receive an automatic `0` on an assignment--which virtually assures that the student just had their final course grade lower by a letter. Don't be that student!"
      ],
      "metadata": {
        "id": "x_Ls8jsIK6Nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Poly-A Tail**\n",
        "\n",
        "## **DeepSeek**\n",
        "\n",
        "![__](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/DeepSeek_logo.svg/1920px-DeepSeek_logo.svg.png)\n",
        "\n",
        "**DeepSeek** (Chinese: 深度求索; pinyin: Shēndù Qiúsuǒ) is a Chinese artificial intelligence company that develops open-source large language models (LLMs). Based in Hangzhou, Zhejiang, it is owned and funded by Chinese hedge fund High-Flyer, whose co-founder, Liang Wenfeng, established the company in 2023 and serves as its CEO.\n",
        "\n",
        "The DeepSeek-R1 model provides responses comparable to other contemporary large language models, such as OpenAI's GPT-4o and o1. It is trained at a significantly lower cost—stated at US$6 million compared to $100 million for OpenAI's GPT-4 in 2023—and approximately a tenth of the computing power used for Meta's comparable model, LLaMA 3.1. DeepSeek's AI models were developed amid United States sanctions on China and other countries for chips used to develop artificial intelligence, which were intended to restrict the ability of these countries to develop advanced AI systems. Lesser restrictions were later announced that would affect all but a few countries.\n",
        "\n",
        "On 10 January 2025, DeepSeek released its first free chatbot app, based on the DeepSeek-R1 model, for iOS and Android; by 27 January, DeepSeek had surpassed ChatGPT as the most-downloaded free app on the iOS App Store in the United States,[10] causing Nvidia's share price to drop by 18%. DeepSeek's success against larger and more established rivals has been described as \"upending AI\"[10] and ushering in \"a new era of AI brinkmanship\". DeepSeek's compliance with Chinese government censorship policies and its data collection practices have also raised concerns over privacy and information control in the model, prompting regulatory scrutiny in multiple countries.\n",
        "\n",
        "DeepSeek makes its generative artificial intelligence algorithms, models, and training details open-source, allowing its code to be freely available for use, modification, viewing, and designing documents for building purposes.However, reports indicate that the API version hosted in China applies content restrictions in accordance with local regulations, limiting responses on topics such as the Tiananmen Square massacre and Taiwan’s status. The company reportedly vigorously recruits young AI researchers from top Chinese universities, and hires from outside the computer science field to diversify its models' knowledge and abilities.\n",
        "\n",
        "**Background**\n",
        "\n",
        "In February 2016, High-Flyer was co-founded by AI enthusiast Liang Wenfeng, who had been trading since the 2007–2008 financial crisis while attending Zhejiang University. They began stock-trading with a deep learning model running on GPU on October 21, 2016. Prior to this, they used CPU-based models, mainly linear models. Most trading was done by AI by the end of 2017.\n",
        "\n",
        "By 2019, he established High-Flyer as a hedge fund focused on developing and using AI trading algorithms. By 2021, High-Flyer exclusively used AI in trading, often using Nvidia chips. DeepSeek has made its generative artificial intelligence chatbot open source, meaning its code is freely available for use, modification, and viewing. This includes permission to access and use the source code, as well as design documents, for building purposes.\n",
        "\n",
        "In 2021, while running High-Flyer, Liang began stockpiling Nvidia GPUs for an AI project.[20] According to 36Kr, Liang had built up a store of 10,000 Nvidia A100 GPUs, which are used to train AI, before the United States federal government imposed AI chip restrictions on China.\n",
        "\n",
        "On 14 April 2023,[22] High-Flyer announced the start of an artificial general intelligence lab dedicated to research developing AI tools separate from High-Flyer's financial business. Incorporated on 17 July 2023, with High-Flyer as the investor and backer, the lab became its own company, DeepSeek. Venture capital firms were reluctant to provide funding, as they considered it unlikely that the venture would be able to generate an \"exit\" in a short period of time.\n",
        "\n",
        "On May 16, 2023, the company Beijing DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd. incorporated under the control of Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd. As of May 2024, Liang Wenfeng held 84% of DeepSeek through two shell corporations.\n",
        "\n",
        "After releasing DeepSeek-V2 in May 2024, which offered strong performance for a low price, DeepSeek became known as the catalyst for China's AI model price war. It was quickly dubbed the \"Pinduoduo of AI\", and other major tech giants such as ByteDance, Tencent, Baidu, and Alibaba began to cut the price of their AI models to compete with the company. Despite the low price charged by DeepSeek, it was profitable compared to its rivals that were losing money.\n",
        "\n",
        "DeepSeek is focused on research and has no detailed plans for commercialization, which also allows its technology to avoid the most stringent provisions of China's AI regulations, such as requiring consumer-facing technology to comply with the government's controls on information.\n",
        "\n",
        "DeepSeek's hiring preferences target technical abilities rather than work experience, resulting in most new hires being either recent university graduates or developers whose AI careers are less established. Likewise, the company recruits individuals without any computer science background to help its technology understand other topics and knowledge areas, including being able to generate poetry and perform well on the notoriously difficult Chinese college admissions exams (Gaokao).\n",
        "\n",
        "**Training framework**\n",
        "\n",
        "High-Flyer/DeepSeek has built at least two computing clusters, Fire-Flyer (萤火一号) and Fire-Flyer 2 (萤火二号). Fire-Flyer began construction in 2019 and finished in 2020, at a cost of 200 million yuan. It contained 1,100 GPUs interconnected at a rate of 200 Gbps. It was 'retired' after 1.5 years in operation. Fire-Flyer 2 began construction in 2021 with a budget of 1 billion yuan.[18] It was reported that in 2022, Fire-Flyer 2's capacity had been utilized at over 96%, totaling 56.74 million GPU hours. Of those GPU hours, 27% was used to support scientific computing outside the company.\n",
        "\n",
        "Fire-Flyer 2 consisted of co-designed software and hardware architecture. On the hardware side, there are more GPUs with 200 Gbps interconnects. The cluster is divided into two \"zones\", and the platform supports cross-zone tasks. The network topology was two fat trees, chosen for its high bisection bandwidth. On the software side, there are\n",
        "\n",
        "* **3FS (Fire-Flyer File System):** A distributed parallel file system. It was specifically designed for asynchronous random reads from a dataset, and uses Direct I/O and RDMA Read. In contrast to standard Buffered I/O, Direct I/O does not cache data. Caching is useless for this case, since each data read is random, and would not be reused.\n",
        "* **hfreduce:** Library for asynchronous communication, originally designed to replace Nvidia Collective Communication Library (NCCL).[30] It was mainly used for allreduce, especially of gradients during backpropagation. It is asynchronously run on the CPU to avoid blocking kernels on the GPU.[28] It uses two-tree broadcast like NCCL.\n",
        "* **hfai.nn:** Software library of commonly used operators in neural network training, similar to torch.nn in PyTorch.\n",
        "* **HaiScale Distributed Data Parallel (DDP):** Parallel training library that implements various forms of parallelism in deep learning such as Data Parallelism (DP), Pipeline Parallelism (PP), Tensor Parallelism (TP), Experts Parallelism (EP), Fully Sharded Data Parallel (FSDP) and Zero Redundancy Optimizer (ZeRO). It is similar to PyTorch DDP, which uses NCCL on the backend.\n",
        "* **HAI Platform:** Various applications such as task scheduling, fault handling, and disaster recovery.\n",
        "During 2022, Fire-Flyer 2 had 5000 PCIe A100 GPUs in 625 nodes, each containing 8 GPUs. At the time, they chose to exclusively use PCIe instead of DGX version of A100, since at the time the models they trained could fit within a single 40 GB GPU VRAM, so there was no need for the higher bandwidth of DGX (i.e. they required only data parallelism but not model parallelism).[30] Later, they also incorporated NVLinks and NCCL, to train larger models that required model parallelism."
      ],
      "metadata": {
        "id": "jyj_ZFKtLUiS"
      }
    }
  ]
}