{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEEW13uCtiJ"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/master/Class_04_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BIO 1173: Intro Computational Biology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Module 4: Training for Tabular Data**\n",
    "\n",
    "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
    "\n",
    "### Module 4 Material\n",
    "\n",
    "* Part 4.1: Encoding a Feature Vector for Keras Deep Learning\n",
    "* **Part 4.2: Keras Multiclass Classification for Deep Neural Networks with ROC and AUC**\n",
    "* Part 4.3: Keras Regression for Deep Neural Networks with RMSE\n",
    "* Part 4.4: Backpropagation, Nesterov Momentum, and ADAM Neural Network Training\n",
    "* Part 4.5: Neural Network RMSE and Log Loss Error Calculation from Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKQylnEiLDUM"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n",
    "  Running the following code will map your GDrive to ```/content/drive```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seXFCYH4LDUM",
    "outputId": "c05015aa-871e-4779-9265-5ad07e8bf617"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Setup\n",
    "\n",
    "Run the next code cell to load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You MUST run this code cell first\n",
    "\n",
    "# Classification neural network\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "path = '/'\n",
    "memory = shutil.disk_usage(path)\n",
    "dirpath = os.getcwd()\n",
    "print(\"Your current working directory is : \" + dirpath)\n",
    "print(\"Disk\", memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF1dep09K1AL"
   },
   "source": [
    "# Part 4.2: Multiclass Classification with ROC and AUC\n",
    "\n",
    "The output of modern neural networks can be of many different forms. However, classically, neural network output has typically been one of the following:\n",
    "\n",
    "* **Binary Classification** - Classification between two possibilities (positive and negative). Common in medical testing, does the person has the disease (positive) or not (negative).\n",
    "* **Classification** - Classification between more than 2.  The iris dataset (3-way classification).\n",
    "* **Regression** - Numeric prediction.  How many MPG does a car get? (covered in next video)\n",
    "\n",
    "We will look at some visualizations for all three in this section.\n",
    "\n",
    "It is important to evaluate the false positives and negatives in the results produced by a neural network. We will now look at assessing error for both classification and regression neural networks.\n",
    "\n",
    "## Binary Classification and ROC Charts\n",
    "\n",
    "Binary classification occurs when a neural network must choose between two options: true/false, yes/no, correct/incorrect, or healthy/diseased. To see how to use binary classification, we will consider a classification system for quantitative cytological measurements of cells extracted from female breast tumors. This system will to classify if a breast tumor is cancerous (malignant) or not (benign). This classification system must decide how to respond to a new patient presenting with a breast tumor.  \n",
    "\n",
    "When you have only two classes that you can consider, the objective function's score is the number of false-positive predictions versus the number of false negatives. False negatives and false positives are both types of errors, and it is essential to understand the difference. For breast cancer data example, diagnosing a breast tumor as cancerous (malignant) would be positive. A false positive occurs when the model decides the tumor is cancerous when in fact it is benign. A false negative happens when the model decides the tumor is benign when in fact it is cancerous. \n",
    "\n",
    "Because only two options exist, we can choose the mistake that is the more serious type of error, a false positive or a false negative. This depends entirely on the situation. \n",
    "\n",
    "#### Breast Cancer Diagnosis\n",
    "\n",
    "In the context of diagnosing breast cancer tumors, a false positive result is generally considered worse than a false negative result in the short-term, but not in the long-term.\n",
    "\n",
    "* **False positive result:** means that a patient is incorrectly told they have cancer when they do not. This can lead to unnecessary anxiety, invasive follow-up tests, and potentially harmful treatments such as surgery, chemotherapy, and radiation therapy.\n",
    "\n",
    "* **False negative result:** means that a patient is incorrectly told they do not have cancer when they actually do. This may delay necessary treatment and allow the cancer to progress without intervention, potentially leading to poorer outcomes in the long run.\n",
    "\n",
    "\n",
    "#### COVID-19 Diagnosis\n",
    "\n",
    "On the other hand, consider the situation where a model predicts whether a subject has COVID-19. In the context of diagnosing COVID-19, a false negative result is generally considered worse than a false positive result.\n",
    "\n",
    "* **False negative result:** means that a person is incorrectly told they do not have COVID-19 when they actually do. This can lead to the person unknowingly spreading the virus to others, potentially causing further infections and contributing to community transmission.\n",
    "\n",
    "* **False positive result:** means that a person is incorrectly told they have COVID-19 when they do not. While this can lead to unnecessary isolation and anxiety for the individual, it typically does not have as severe consequences for public health as a false negative.\n",
    "\n",
    "While it is not always clear which type of error is more important, it is obvious that having a solid understanding of how neural network models work, and how to assess their predictive accuracy is of paramount importance for their appropriate deployment in a clinical setting and how to explain a model's predictions to patients and their family members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Read datafile and create DataFrame\n",
    "\n",
    "For the intial examples in this lesson, we will be using the \"Pima\" dataset that contains clinical information for 768 women of the Pima Indian nation. The data file, `pima.csv` is located on the course HTTPS server, located in the following filepath: `/BIO1173/data/`. The code below shows how to read this data file and store the information in a new DataFrame called `piDF`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "VmjrLkDwK1AM",
    "outputId": "650cc2a4-d295-459d-aa40-d9e2d2950c88",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 1: Read datafile and create DataFrame\n",
    "\n",
    "# Read file and create DataFrame\n",
    "piDF = pd.read_csv(\n",
    "    \"https://biologicslab.co/BIO1173/data/pima.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 0)\n",
    "pd.set_option('display.max_rows', 6)\n",
    "\n",
    "# Display DataFrame\n",
    "display(piDF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_04_2_Exm1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1: Read datafile and create DataFrame**\n",
    "\n",
    "In the cell below, read the datafile `wcbreast.csv` containing the _UCI Wisconsin Diagnostic Breast Cancer Data_ that is located on the course HTTPS server. Create a new DataFrame called `wcDF` to hold the data.  \n",
    "\n",
    "The Wisconsin Breast Cancer dataset provides data for 569 patients on 30 features of the cell nuclei obtained from a digitized image of a fine needle aspirate (FNA) of a breast mass. For each patient the cancer was diagnosed as malignant (`M`) or benign (`B`) in the column labeled `diagnosis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "VmjrLkDwK1AM",
    "outputId": "650cc2a4-d295-459d-aa40-d9e2d2950c88"
   },
   "outputs": [],
   "source": [
    "### Insert your code for Exercise 1 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following table:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_04_2_ex1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic_JG5KpK1AN"
   },
   "source": [
    "## ROC Curves\n",
    "\n",
    "\n",
    "ROC curves can be a bit confusing. However, they are prevalent in analytics. It is essential to know how to read them. Even their name is confusing. Do not worry about their name; the receiver operating characteristic curve (ROC) comes from electrical engineering (EE).\n",
    "\n",
    "Binary classification is common in medical testing. Often you want to diagnose if someone has a disease. This diagnosis can lead to two types of errors, known as false positives and false negatives:\n",
    "\n",
    "* **False Positive** - Your test (neural network) indicated that the patient had the disease; however, the patient did not.\n",
    "* **False Negative** - Your test (neural network) indicated that the patient did not have the disease; however, the patient did have the disease.\n",
    "* **True Positive** - Your test (neural network) correctly identified that the patient had the disease.\n",
    "* **True Negative** - Your test (neural network) correctly identified that the patient did not have the disease.\n",
    "\n",
    "Figure 4.ETYP shows you these types of errors.\n",
    "\n",
    "**Figure 4.ETYP: Type of Error**\n",
    "![__](https://biologicslab.co/BIO1173/images/class_4_errors.png)\n",
    "\n",
    "Neural networks classify in terms of the probability of it being positive. However, at what possibility do you give a positive result? Is the cutoff 50%? 90%? Where you set, this cutoff is called the **_threshold_**. Anything above the cutoff is positive; anything below is negative. Setting this cutoff allows the model to be more sensitive or specific.\n",
    "\n",
    "* **Sensitivity** of a test refers to its ability to correctly identify individuals who have the condition or disease (true positive rate). A highly sensitive test will correctly identify all or most of the individuals with the condition, resulting in few false negative results.\n",
    "\n",
    "* **Specificity** of a test, on the other hand, refers to its ability to correctly identify individuals who do not have the condition or disease (true negative rate). A highly specific test will correctly identify all or most of the individuals without the condition, resulting in few false positive results.\n",
    "\n",
    "The key point is that sensitivity focuses on the ability of a test to correctly identify individuals with the condition, while specificity focuses on the ability to correctly identify individuals without the condition. \n",
    "\n",
    "More info on Sensitivity vs. Specificity: [Khan Academy](https://www.youtube.com/watch?v=Z5TtopYX1Gc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XY plot illustrating Sensitivity vs. Specificity\n",
    "\n",
    "The code in the cell below generates an XY plot illustrating the inherent trade-off between test sensitivity and test specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "QfjMVDf2K1AO",
    "outputId": "9fefbe74-69f2-4c55-bad1-459a3c581c28"
   },
   "outputs": [],
   "source": [
    "# Generate XY Plot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mu1 = -2\n",
    "mu2 = 2\n",
    "variance = 1\n",
    "sigma = math.sqrt(variance)\n",
    "x1 = np.linspace(mu1 - 5*sigma, mu1 + 4*sigma, 100)\n",
    "x2 = np.linspace(mu2 - 5*sigma, mu2 + 4*sigma, 100)\n",
    "plt.plot(x1, stats.norm.pdf(x1, mu1, sigma)/1,color=\"green\", \n",
    "         linestyle='dashed')\n",
    "plt.plot(x2, stats.norm.pdf(x2, mu2, sigma)/1,color=\"red\")\n",
    "plt.axvline(x=-2,color=\"black\")\n",
    "plt.axvline(x=0,color=\"black\")\n",
    "plt.axvline(x=+2,color=\"black\")\n",
    "plt.text(-2.7,0.55,\"Sensitive\")\n",
    "plt.text(-0.7,0.55,\"Balanced\")\n",
    "plt.text(1.7,0.55,\"Specific\")\n",
    "plt.ylim([0,0.53])\n",
    "plt.xlim([-5,5])\n",
    "plt.legend(['Negative','Positive'])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test _cannot_ be both highly sensitive and highly specific simultaneously due to inherent trade-offs in test characteristics. In general, increasing sensitivity tends to decrease specificity, and vice versa. This is because the parameters that contribute to sensitivity (true positive rate) and specificity (true negative rate) are often inversely related.\n",
    "\n",
    "* **Sensitivity** focuses on minimizing false negatives, which means it aims to correctly identify all individuals with the condition. To achieve high sensitivity, the test may be designed to detect even low levels of the condition, making it more likely to generate false positives (lower specificity).\n",
    "\n",
    "* **Specificity** aims to minimize false positives by correctly identifying individuals without the condition. To achieve high specificity, the test may be designed to only detect the presence of the condition with a high degree of certainty, potentially leading to missed detections of milder cases (lower sensitivity).\n",
    "\n",
    "Therefore, to maximize sensitivity, a test may detect even slight signals of the condition, increasing the likelihood of false positives and reducing specificity. Conversely, a test designed for high specificity may require stronger, more specific indicators of the condition, potentially missing milder cases and reducing sensitivity. Achieving a balance between sensitivity and specificity is crucial in developing effective diagnostic tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ew7B8lNK1AO"
   },
   "source": [
    "We will now train a neural network for the Wisconsin breast cancer dataset. We begin by preprocessing the data. Because we have all numeric data, we compute a z-score for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Preprocess data for neural network training\n",
    "\n",
    "As usual, we will have to pre-process the Pima data in the DataFrame `piDF` before it can be used to train a neural network. All of the data in `piDF` is numeric, so it won't be necessary to One-Hot encode any categorical variables (strings). However, since there are large differences in magnitude below values. For example, while the glucose mean = 120.894531, the mean for the pedigree function is only 0.471876. To make the data values more similar, the code below converts them into Z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m55_Ygs9K1AP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 2: Preprocess data\n",
    "\n",
    "# Generate list of columns for X\n",
    "piX_columns = piDF.columns.drop('Outcome')\n",
    "\n",
    "# Replace values with their Z-scores\n",
    "for col in piX_columns:\n",
    "    piDF[col] = zscore(piDF[col])\n",
    "\n",
    "# Generate X as a Numpy array\n",
    "piX = piDF[piX_columns].values\n",
    "piX = np.asarray(piX).astype(np.float32)\n",
    "\n",
    "# Generate Y as Numpy array\n",
    "piY = piDF['Outcome']   \n",
    "piY = np.asarray(piY).astype(np.float32)    \n",
    "\n",
    "# Print X and Y\n",
    "print(piX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[ 0.63994724  0.8483238   0.14964075 ...  0.20401277  0.46849197\n",
    "   1.4259953 ]\n",
    " [-0.84488505 -1.1233964  -0.16054575 ... -0.68442196 -0.36506078\n",
    "  -0.1906719 ]\n",
    " [ 1.2338802   1.9437239  -0.26394126 ... -1.1032555   0.6043973\n",
    "  -0.10558415]\n",
    " ...\n",
    " [ 0.3429808   0.00330087  0.14964075 ... -0.7351896  -0.68519336\n",
    "  -0.27575967]\n",
    " [-0.84488505  0.1597866  -0.47073224 ... -0.24020459 -0.37110102\n",
    "   1.1707321 ]\n",
    " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378504\n",
    "  -0.87137395]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows the numpy array of Z-scores for the Pima independent variable, `piX`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2: Preprocess data for neural network training**\n",
    "\n",
    "In the cell below you are write the code to preprocess the Wisconsin Breast Cancer data in the DataFrame `wcDF`. Start by generating a list of columns to be used as X, `wcX_columns`. To do this, begin by dropping the two columns using this line of code:\n",
    "\n",
    "> `wcX_columns = wcDF.columns.drop('diagnosis').drop('id')`\n",
    "\n",
    "The column `id` should be dropped since it doesn't provide any useful information for making predictions about breast cancer. The column `diagnosis` needs to be dropped when generating `wcX_columns` since it is the target column (Y). \n",
    "\n",
    "As shown in Example 2, replace the X values in `wcX_columns` with their Z-scores and then generate a Numpy array called `wcX`. \n",
    "\n",
    "Unlike the Pima data preprocessed in Example 2, the target column `diagnosis` contains the categorical values 'M' for malignant and 'B' for benign. You will need to map the letter 'M' to the integer `1` and the letter `B` to the integer `0` using the following line of code:\n",
    "\n",
    "> `wcY = wcDF['diagnosis'].map({'M':1,\"B\":0}).values`\n",
    "\n",
    "Once the values in the target column `diagnosis` have been mapped, use the next line of code to convert it into a Numpy array:\n",
    "\n",
    "> `wcY = np.asarray(wcY).astype(np.float32)`\n",
    "\n",
    "Print out the X values in `wcX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m55_Ygs9K1AP"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[ 0.63994724  0.8483238   0.14964075 ...  0.20401277  0.46849197\n",
    "   1.4259953 ]\n",
    " [-0.84488505 -1.1233964  -0.16054575 ... -0.68442196 -0.36506078\n",
    "  -0.1906719 ]\n",
    " [ 1.2338802   1.9437239  -0.26394126 ... -1.1032555   0.6043973\n",
    "  -0.10558415]\n",
    " ...\n",
    " [ 0.3429808   0.00330087  0.14964075 ... -0.7351896  -0.68519336\n",
    "  -0.27575967]\n",
    " [-0.84488505  0.1597866  -0.47073224 ... -0.24020459 -0.37110102\n",
    "   1.1707321 ]\n",
    " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378504\n",
    "  -0.87137395]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as4rUCd1K1AP"
   },
   "source": [
    "### Define functions for plotting\n",
    "\n",
    "The code cell below defines two functions that will be used later in this lesson. The first function, `plot_confusion_matrix()` plots a confusion matrix. The second function, `plot_roc()` plots a ROC chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25ys9moDK1AP"
   },
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', \n",
    "                            cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be **_no output_** when you run the code cell above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zotNGspK1AQ"
   },
   "source": [
    "### ROC Chart Examples\n",
    "\n",
    "The following code demonstrates how to implement a ROC chart in Python. The first step will be to construct, compile and fit a classification neural network to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Construct, compile and fit a binary classification neural network\n",
    "\n",
    "The code in the cell below, uses the Keras/Tensorflow libraries to construct, compile and fit a binary classificantion neural network called `piModel`. The model has 3 hidden layers. It is designed to predict whether a women has Type II diabetes based on a several clinical measures. The model is trained (fitted) to the clinical data stored in `piX` and `piY`. A monitor function, `piMonitor`, is also created to allow for EarlyStopping when validation loss fails to improve after waiting for 10 epochs. Training (fitting) is set for 1000 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tchQMWrIK1AQ",
    "outputId": "e4be0d2b-d974-4917-bc0f-908917773c99"
   },
   "outputs": [],
   "source": [
    "# Example 3: Construct, compile and fit neural network\n",
    "\n",
    "# Split into train/test\n",
    "piX_train, piX_test, piY_train, piY_test = train_test_split(    \n",
    "    piX, piY, test_size=0.25, random_state=42)\n",
    "\n",
    "# Construct model\n",
    "piModel = Sequential()\n",
    "piModel.add(Dense(100, input_dim=piX.shape[1], activation='relu',\n",
    "                kernel_initializer='random_normal')) # Hidden 1\n",
    "piModel.add(Dense(50,activation='relu',kernel_initializer='random_normal')) # Hidden 2\n",
    "piModel.add(Dense(25,activation='relu',kernel_initializer='random_normal')) # Hidden 3\n",
    "piModel.add(Dense(1,activation='sigmoid',kernel_initializer='random_normal')) # Output\n",
    "\n",
    "# Compile model\n",
    "piModel.compile(loss='binary_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics =['accuracy'])\n",
    "\n",
    "# Create monitor with patience = 10\n",
    "piMonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "    patience=10, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "# Fit model to X and Y\n",
    "piModel.fit(piX_train,piY_train,validation_data=(piX_test,piY_test),\n",
    "          callbacks=[piMonitor],verbose=2,epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similiar to the output below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/1000\n",
    "18/18 - 1s - loss: 0.6896 - accuracy: 0.6458 - val_loss: 0.6841 - val_accuracy: 0.6406 - 648ms/epoch - 36ms/step\n",
    "Epoch 2/1000\n",
    "18/18 - 0s - loss: 0.6661 - accuracy: 0.6545 - val_loss: 0.6429 - val_accuracy: 0.6354 - 112ms/epoch - 6ms/step\n",
    "Epoch 3/1000\n",
    "18/18 - 0s - loss: 0.5802 - accuracy: 0.7222 - val_loss: 0.5561 - val_accuracy: 0.7500 - 109ms/epoch - 6ms/step\n",
    "Epoch 4/1000\n",
    "18/18 - 0s - loss: 0.4900 - accuracy: 0.7622 - val_loss: 0.5342 - val_accuracy: 0.7448 - 108ms/epoch - 6ms/step\n",
    "Epoch 5/1000\n",
    "18/18 - 0s - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.5361 - val_accuracy: 0.7031 - 105ms/epoch - 6ms/step\n",
    "....................\n",
    "Epoch 15/1000\n",
    "18/18 - 0s - loss: 0.4126 - accuracy: 0.8003 - val_loss: 0.5521 - val_accuracy: 0.7500 - 105ms/epoch - 6ms/step\n",
    "Epoch 16/1000\n",
    "18/18 - 0s - loss: 0.4088 - accuracy: 0.8003 - val_loss: 0.5560 - val_accuracy: 0.7552 - 114ms/epoch - 6ms/step\n",
    "Epoch 17/1000\n",
    "Restoring model weights from the end of the best epoch: 7.\n",
    "18/18 - 0s - loss: 0.4065 - accuracy: 0.7969 - val_loss: 0.5550 - val_accuracy: 0.7500 - 123ms/epoch - 7ms/step\n",
    "Epoch 17: early stopping\n",
    "\n",
    "<keras.callbacks.History at 0x2801c980970>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance, the model `piModel` reached a minimum validation loss of `val_loss: 0.5320` after only 7 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3: Construct, compile and fit a binary classification neural network**\n",
    "\n",
    "In the cell below, use the Keras/Tensorflow libraries to construct, compile and fit a binary classificantion neural network called `wcModel` with 3 hidden layers using Example 3 as a template.\n",
    "\n",
    "Your model should be designed to predict whether a breast tumor is cancerous (malignant) or benign after fitting it to the clinical data stored in `wcX` and `wcY`. Create a monitor function called `wcMonitor` to allow for EarlyStopping when validation loss fails to improve after waiting for 10 epochs. Set the training (fitting) for 1000 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tchQMWrIK1AQ",
    "outputId": "e4be0d2b-d974-4917-bc0f-908917773c99"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3 here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similiar to the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/1000\n",
    "14/14 - 1s - loss: 0.6823 - accuracy: 0.8357 - val_loss: 0.6615 - val_accuracy: 0.9441 - 769ms/epoch - 55ms/step\n",
    "Epoch 2/1000\n",
    "14/14 - 0s - loss: 0.6178 - accuracy: 0.9178 - val_loss: 0.5350 - val_accuracy: 0.9580 - 150ms/epoch - 11ms/step\n",
    "Epoch 3/1000\n",
    "14/14 - 0s - loss: 0.4274 - accuracy: 0.9437 - val_loss: 0.2670 - val_accuracy: 0.9720 - 138ms/epoch - 10ms/step\n",
    "Epoch 4/1000\n",
    "14/14 - 0s - loss: 0.2149 - accuracy: 0.9531 - val_loss: 0.1051 - val_accuracy: 0.9720 - 110ms/epoch - 8ms/step\n",
    "Epoch 5/1000\n",
    "14/14 - 0s - loss: 0.1131 - accuracy: 0.9648 - val_loss: 0.0680 - val_accuracy: 0.9720 - 105ms/epoch - 8ms/step\n",
    "........................\n",
    "Epoch 14/1000\n",
    "14/14 - 0s - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.0441 - val_accuracy: 0.9790 - 103ms/epoch - 7ms/step\n",
    "Epoch 15/1000\n",
    "14/14 - 0s - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.0470 - val_accuracy: 0.9790 - 111ms/epoch - 8ms/step\n",
    "Epoch 16/1000\n",
    "14/14 - 0s - loss: 0.0247 - accuracy: 0.9930 - val_loss: 0.0462 - val_accuracy: 0.9790 - 105ms/epoch - 8ms/step\n",
    "Epoch 17/1000\n",
    "Restoring model weights from the end of the best epoch: 12.\n",
    "14/14 - 0s - loss: 0.0216 - accuracy: 0.9953 - val_loss: 0.0486 - val_accuracy: 0.9790 - 109ms/epoch - 8ms/step\n",
    "Epoch 17: early stopping\n",
    "\n",
    "<keras.callbacks.History at 0x2801fc74f70>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance, the model `wcModel` reached a minimum validation loss of `val_loss: 0.0444` after only 12 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "\n",
    "## ROC Curves\n",
    "\n",
    "**_Receiver Operating Characteristic (ROC) Curve_** is a graphical representation that illustrates the diagnostic ability of a binary classification system as its discrimination threshold is varied. The ROC curve plots the true positive rate (Sensitivity) against the false positive rate (1-Specificity) for various threshold values, showing the trade-off between sensitivity and specificity.\n",
    "\n",
    "The ROC curve is important in evaluating the performance of diagnostic tests or classification models as it provides a comprehensive assessment of their ability to discriminate between positive and negative cases. Some key reasons why ROC curves are important include:\n",
    "\n",
    "* **Quantitative Measure:** ROC curves provide a quantitative measure of the diagnostic accuracy of a test by summarizing its performance across all possible thresholds.\n",
    "\n",
    "* **Comparison:** ROC curves allow for a direct comparison of different tests or models based on their area under the curve (AUC), where a higher AUC indicates better overall performance.\n",
    "\n",
    "* **Threshold Selection:** ROC curves help in selecting the optimal threshold for classification that balances sensitivity and specificity based on the specific requirements of the application.\n",
    "\n",
    "* **Visual Representation:** The visual nature of ROC curves facilitates a clear understanding of the trade-offs between sensitivity and specificity, aiding in decision-making and interpretation of test results.\n",
    "\n",
    "--------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Plot ROC curve for the Model\n",
    "\n",
    "The code in the cell below uses the model, `piModel`, to **_predict_** whether each of the 192 women who were randomly placed in the `piX_test` dataset, had Type II diabetes based on their clinical values. It then sends these predictions all with the women's actual diagnosis, stored in `wcY_test` to the plotting function, `plot_roc()` defined above. Using the predicted and the actual values, the plotting function generates an ROC curve.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "_95P1kTBK1AQ",
    "outputId": "35b353e5-0eaf-412f-83a3-1970e8e07bb1"
   },
   "outputs": [],
   "source": [
    "# Example 4: Plot ROC curve\n",
    "\n",
    "# Use model to generate predictions\n",
    "piPred = piModel.predict(piX_test)\n",
    "\n",
    "# Plot model predictions against actual values\n",
    "plot_roc(piPred,piY_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an annotated version of the ROC plot shown above.\n",
    "\n",
    "![ROC Curve ](https://biologicslab.co/BIO1173/images/class_04_2_ROC1A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve: Receiver Operating Characteristic Curve\n",
    "\n",
    "ROC curve stands for \"Receiver Operating Characteristic Curve\". The ROC Curve above shows the performance of the classification model `piModel` at all classification thresholds for predicting whether a Pima women has Type II diabetes. \n",
    "\n",
    "This curve plots two parameters:\n",
    "\n",
    "* True Positive Rate (Sensitivity)\n",
    "* False Positive Rate\n",
    "\n",
    "**True Positive Rate (TPR)** is a synonym for _sensitivity_ and is defined as follows:\n",
    "\n",
    "$TPR=\\frac{TP}{TP+FN}$\n",
    "\n",
    "In other words, the sensitivity of the model (True Positive Rate) increases to a perfect score (1.0) as the False Negative rate decreases to zero.\n",
    "\n",
    "**False Positive Rate (FPR)** is defined as follows:\n",
    "\n",
    "$FPR=\\frac{FP}{FP+TN}$\n",
    "\n",
    "In other words, the False Positive Rate increases to a perfect score (1.0) as the True Negative rate decreases to zero.\n",
    "\n",
    "An ROC curve plots TPR vs. FPR at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. \n",
    "\n",
    "### AUC: Area Under the ROC Curve\n",
    "\n",
    "AUC stands for \"Area under the ROC Curve.\" In the plot above, the area colored light blue is the AUC. AUC measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus) from (0,0) to (1,1).\n",
    "\n",
    "AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example.\n",
    "\n",
    "AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0. In this example, the AUC of the model `piModel` was 0.80.\n",
    "\n",
    "AUC is desirable for the following two reasons:\n",
    "\n",
    "* AUC is **scale-invariant**. It measures how well predictions are ranked, rather than their absolute values.\n",
    " \n",
    "* AUC is **classification-threshold-invariant**. It measures the quality of the model's predictions irrespective of what classification threshold is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 4: Plot ROC curve for the Model**\n",
    "\n",
    "In the cell below write the code to generate a ROC plot of your Breast Cancer classsification model, `wcModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "_95P1kTBK1AQ",
    "outputId": "35b353e5-0eaf-412f-83a3-1970e8e07bb1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 4 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If code is correct you should see the following ROC curve:\n",
    "\n",
    "![ROC Curve](https://biologicslab.co/BIO1173/images/class_04_2_ROC2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the Pima classification model, `piModel`, the ROC curve shows that your Breast Cancer model, `wcModel` is much more accurate since its AUC (area under the curve) = 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yElFCdNQK1AR"
   },
   "source": [
    "## Multiclass Classification Error Metrics\n",
    "\n",
    "If you want to predict more than one outcome, you will need more than one output neuron. Because a single neuron can predict two results, (e.g. `0` for \"no\", `1` for \"yes\") a neural network with two output neurons is somewhat rare. \n",
    "\n",
    "If there are three or more outcomes, there will be three or more output neurons. The following sections will examine several metrics for evaluating classification error in multiclass situtations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "\n",
    "## ST Segment \n",
    "\n",
    "(This vignette is from the [article](https://litfl.com/st-segment-ecg-library/) by Ed Burns and Robert Buttner, Mar 16, 2022)\n",
    "\n",
    "The **_ST segment_** is the flat, isoelectric section of the ECG between the end of the S wave (the J point) and the beginning of the T wave.\n",
    "\n",
    "* The ST Segment represents the interval between ventricular depolarization and repolarization.\n",
    "* The most important cause of ST segment abnormality (elevation or depression) is **myocardial ischaemia** or **infarction**.\n",
    "\n",
    "![ST Segment](https://biologicslab.co/BIO1173/images/ECG_ST.jpg)\n",
    "\n",
    "**Causes of ST Segment Elevation**\n",
    "\n",
    "* [Acute myocardial infarction](https://litfl.com/anterior-myocardial-infarction-ecg-library/)\n",
    "* [Coronary vasospasm (Printzmetal’s angina)](https://www.ncbi.nlm.nih.gov/pubmed/15293589)\n",
    "* [Pericarditis](https://litfl.com/pericarditis-ecg-library/)\n",
    "* [Benign early repolarization](https://litfl.com/benign-early-repolarisation-ecg-library/)\n",
    "* [Left bundle branch block](https://litfl.com/left-bundle-branch-block-lbbb-ecg-library/)\n",
    "* [Left ventricular hypertrophy](https://litfl.com/left-bundle-branch-block-lbbb-ecg-library/)\n",
    "* [Ventricular aneurysm](https://litfl.com/left-ventricular-aneursym-ecg-library/)\n",
    "* [Brugada syndrome](https://litfl.com/brugada-syndrome-ecg-library/)\n",
    "* [Ventricular paced rhythm](https://litfl.com/pacemaker-rhythms-normal-patterns/)\n",
    "* [Raised intracranial pressure](https://litfl.com/raised-intracranial-pressure-ecg-library/)\n",
    "* [Takotsubo Cardiomyopathy](https://litfl.com/tako-tsubo-cardiomyopathy-ecg-library/)\n",
    "\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Read datafile and create DataFrame\n",
    "\n",
    "For the next section in this lesson, we will again be using the Heart Disease dataset for the Examples. The data file, `heart_disease.csv` is located on the course HTTPS server, located in the following filepath: `/BIO1173/data/`. The code below shows how to read this data file and store the information in a new DataFrame called `ecgDF`. We will generate a new DataFrame to prevent problems with the previous manipulations of this dataset. \n",
    "\n",
    "In the examples above, we used the rightmost column `HeartDisease` as our target column (Y). Like many medical datasets, the `HeartDisease` values were binary, either `1` if the patient had heart disease and `0` if no heart disease. Since this section is on ***Multi*class Classification Error Metrics**, we will use instead `RestingECG` as our target column (Y). The `HeartDisease` column will now be included as part of the independent variables (X).\n",
    "\n",
    "The column `RestingECG` has the 3 following categorical values `Normal`, `ST` (ST segment elevation), `LVH` (left ventricular hypertropy). Consequently, our classification neural network model will have **_3_** output neurons--one for each category. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 5: Read the data set\n",
    "\n",
    "# Read the data file and create DataFrame\n",
    "ecgDF = pd.read_csv(\n",
    "    \"https://biologicslab.co/BIO1173/data/heart_disease.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 0)\n",
    "pd.set_option('display.max_rows', 6)\n",
    "\n",
    "# Display DataFrame\n",
    "display(ecgDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If code is correct you should see the following table:\n",
    "\n",
    "![ROC Curve](https://biologicslab.co/BIO1173/images/class_04_2_Ex5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 5: ReadRead datafile and create DataFrame**\n",
    "\n",
    "For the next section in this lesson, you will be using the Iris Flower dataset for your Exercises. The data file, `iris.csv` is located on the course HTTPS server located in the usual filepath: `/BIO1173/data/`. \n",
    "\n",
    "In the cell below, write the code to read this data file and store the information in a new DataFrame called `ifDF`. Set the display options to show all columns and 6 rows of the `ifDF` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 5 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If code is correct you should see the following table:\n",
    "\n",
    "![ROC Curve](https://corgi.genomelab.utsa.edu/BIO1173/images/class_04_2_Exe5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Compute number of samples in each output class\n",
    "\n",
    "It is generally useful to have some idea how many samples are in each output class. Ideally, for training a multiclass classification neural network, the number of samples in each class should be approximately equal.\n",
    "\n",
    "The code below uses the grouby.count to print out next section in this lesson, we will again be using the Heart Disease dataset for the Examples. The data file, heart_disease.csv is located on the course HTTPS s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 6: Groupby\n",
    "\n",
    "# Create groupby\n",
    "ecgGroups = ecgDF.groupby(['RestingECG'])['RestingECG'].count()\n",
    "\n",
    "# Print results\n",
    "print(ecgGroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RestingECG\n",
    "LVH       188\n",
    "Normal    552\n",
    "ST        178\n",
    "Name: RestingECG, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output above, the number of samples in each of the 3 output classes, `LVH`, `Normal` and `ST` are _not_ ideal. The number of samples in the class `Normal` is almost twice the size of the other two classes, `LVH` and `ST`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 6: Compute number of samples in each output class**\n",
    "\n",
    "In the cell below write the code to print out the number of samples in each class of the DataFrame `ifDF`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 6 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "species\n",
    "Iris-setosa        50\n",
    "Iris-versicolor    50\n",
    "Iris-virginica     50\n",
    "Name: species, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output above, the number of samples in each of the 3 output classes, `Iris-setosa`, `Iris-versicolor` and `Iris-virginica` are exactly equal (i.e. `50`), which is ideal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Check for missing data\n",
    "\n",
    "The code in the cell below checks the DataFrame `ecgDF` for missing values. The number of rows is set to `15` to make sure that the results from all of the columns are displayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7: Check for missing data\n",
    "\n",
    "# Find the locations of missing data\n",
    "missing_locations = ecgDF.isnull().any()\n",
    "\n",
    "# Set max rows to 15\n",
    "pd.set_option('display.max_rows', 15)\n",
    "\n",
    "# Display the locations of missing data\n",
    "print(missing_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Age               False\n",
    "Sex               False\n",
    "ChestPainType     False\n",
    "RestingBP         False\n",
    "Cholesterol       False\n",
    "FastingBS         False\n",
    "RestingECG        False\n",
    "MaxHR             False\n",
    "ExerciseAngina    False\n",
    "Oldpeak           False\n",
    "ST_Slope          False\n",
    "HeartDisease      False\n",
    "dtype: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that there are no missing data values in the DataFrame `ecgDF`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 7: Check for missing data**\n",
    "\n",
    "In the cell below write the code to check for missing values in the DataFrame `ifDF`. Set the number of rows to display to `5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 7 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sepal_length    False\n",
    "sepal_width     False\n",
    "petal_length    False\n",
    "petal_width     False\n",
    "species         False\n",
    "dtype: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that there are no missing data values in the DataFrame `ifDF`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 8: Preprocess data for neural network training\n",
    "\n",
    "The code in the cell below preprocesses the Heart Disease data to make it ready for machine learning. Two columns, `Sex`, and `ExerciseAngina` have _binary_ categorical variables--the column `Sex` has the letters `M` and `F`, and the column `ExerciseAngina` has the letters `Y` and `N`. In the cell below, these categorical values will be **_mapped_** to the integers `1` and `0`.  \n",
    "\n",
    "Two other columns have categorical values than need to be converted into numerical values. The column `ST_Slope`, has the categorical values `Down`, `Up` and `Flat` while the column `ChestPainTypes` has four categorical values, `ATA`, `NAP`, `ASY`, `TA`. One-Hot encoding will be applied to these two columns before they are used to generate the X-values.\n",
    "\n",
    "The `ecgDF` DataFrame has 4 columns with numeric data: `RestingBP`, `Cholesterol`, `FastingBS` and `MaxHR`. Since the values in these columns vary substantially in magnitude, there will be **_standardized_** by replacing their values by their Z-scores. \n",
    "\n",
    "Finally, the target column for this example, `RestingECG` has three categorical values: `LVH`, `Normal`, and `ST`. Such this is is going to be our target column, it will be One-Hot encoded separately when generating the Y-values. \n",
    "\n",
    "Remember, the with classification neural networks, it is **always** necessary to One-Hot encode the target column when generating the Y values, whether or not the target column contains string or numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wD57aaWKK1AR"
   },
   "outputs": [],
   "source": [
    "# Example 8: Preprocess data\n",
    "\n",
    "# Map `Sex` to int\n",
    "mapping = {'M': 1, 'F': 0}\n",
    "ecgDF['Sex'] = ecgDF['Sex'].map(mapping)\n",
    "\n",
    "# Map 'ExerciseAngina' to int\n",
    "mapping = {'Y': 1, 'N': 0}\n",
    "ecgDF['ExerciseAngina'] = ecgDF['ExerciseAngina'].map(mapping)\n",
    "\n",
    "# One Hot encode ChestPainType\n",
    "ecgDF = pd.concat([ecgDF,pd.get_dummies(ecgDF['ChestPainType'],prefix=\"PainType\", dtype=float)],axis=1)\n",
    "ecgDF.drop('ChestPainType', axis=1, inplace=True)\n",
    "\n",
    "# One Hot encode ST_Slope\n",
    "ecgDF = pd.concat([ecgDF,pd.get_dummies(ecgDF['ST_Slope'],prefix=\"ST_Slope\", dtype=float)],axis=1)\n",
    "ecgDF.drop('ST_Slope', axis=1, inplace=True)\n",
    "\n",
    "# Standardize ranges in numeric columns\n",
    "ecgDF['RestingBP'] = zscore(ecgDF['RestingBP'])\n",
    "ecgDF['Cholesterol'] = zscore(ecgDF['Cholesterol'])\n",
    "ecgDF['FastingBS'] = zscore(ecgDF['RestingBP'])\n",
    "ecgDF['MaxHR'] = zscore(ecgDF['MaxHR'])\n",
    "\n",
    "\n",
    "# Generate X from all columns EXCEPT the target colunm\n",
    "ecgX_columns = ecgDF.columns.drop('RestingECG')\n",
    "ecgX = ecgDF[ecgX_columns].values \n",
    "ecgX = np.asarray(ecgX).astype(np.float32)\n",
    "\n",
    "# One-Hot encode the target column and generate Y\n",
    "dummies = pd.get_dummies(ecgDF['RestingECG'], dtype=float) # Classification\n",
    "ECGclasses = dummies.columns\n",
    "ecgY = dummies.values\n",
    "ecgY = np.asarray(ecgY).astype(np.float32)\n",
    "\n",
    "# Print the ECGtypes\n",
    "print(*ECGclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "LVH Normal ST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output represents the 3 output classes (Y) that our neural network will be designed to predict after being trained on the X data stored in the variable `ecgX`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "## Should binary numerical categories be converted to Z-scores?\n",
    "\n",
    "Since we converted the numerical data into Z-scores, should we also convert the data in the columns that were mapped to `0` and `1` into Z-scores?\n",
    "\n",
    "No, binary numerical categories should **not** be converted into Z-scores when fitting a neural network. Z-scores are used for standardizing continuous numerical data by calculating the number of standard deviations a data point is from the mean. Binary numerical categories are already in a format that is suitable for inputting into a neural network, as they typically represent two distinct classes or states. Converting them into Z-scores would not add any meaningful information and could potentially introduce unnecessary noise into the data.\n",
    "\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 8: Preprocess data for neural network training**\n",
    "\n",
    "In the cell below, preprocess the data in your DataFrame `ifDF` to make it ready for processing by a neural network. Compared to Example 8 above, your code will require fewer steps.\n",
    "\n",
    "Things you **don't** have to do for preprocessing:\n",
    "\n",
    "1. Since there are no missing data in `ifDF` you don't need to correct for missing data.\n",
    "2. Since the all of the columns (except the target column) are numeric, you don't have to map any categorical values to integers.\n",
    "\n",
    "Things you **will** need to do for preprocessing:\n",
    "\n",
    "1. Create a variable called `if_columns` by dropping the target column `species`.\n",
    "2. Generate a variable called `ifX` from the values in `ifX_columns`.\n",
    "3. Convert `ifX` to float32 using the command: `ifX = np.asarray(ifX).astype(np.float32)`\n",
    "4. One-Hot encode the target column, `species`.\n",
    "5. Create variable `IRISpecies` from the `dummies.columns`.\n",
    "6. Create Y variable `ifY` from the `dummies.values`\n",
    "7. Convert `ifY` to float32 using the command: `ifY = np.asarray(ifY).astype(np.float32)`\n",
    "8. Print out the variable `IRISspecies` using the starred method: `print(*IRISspecies`.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wD57aaWKK1AR"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 8 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Iris-setosa Iris-versicolor Iris-virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the three classes that your neural network will be designed to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9: Construct, Compile and Fit a Multiclass Classification Neural Network\n",
    "\n",
    "The code in the cell below starts by splitting the X-values stored in `ecgX` into `ecgX_train` and `ecgX_test` sets with 75% being used for training. Similarily, the Y-values stores in `ecgY` are split into `ecgY_train` and `ecgY_test` sets. Keep in mind that the Y values in the training and testing sets match the X values in the training and testing sets.\n",
    "\n",
    "The cell below then builds a linear (\"sequential\") muticlass classsification neural network called `ecgModel` with 3 hidden layers. The number of inputs to the 1st hidden layer is specified by the argument `input_dim=ecgX.shape[1]`. The number of neurons in the output layer is specified by the argument `ecgY.shape[1]` in the last line in the construction code section. Since there are 3 classes in `ecgY` (`LVH`, `Normal`, `ST`) the output layer will have 3 neurons--one neuron for each class.\n",
    "\n",
    "Once the model is constructed, it is compiled using the loss function, `categorical_crossentropy` and the `Adam` optimizer. \n",
    "\n",
    "An EarlyStopping monitor, `ecgMoniter` is then created.  The monitor is specified to wait `50` epochs for the validation loss to start improving after reaching a local minimum, before termining the training. \n",
    "\n",
    "Finally, the model `ecgModel` is fitted to the training and test (validation) data sets for 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aggbZoEUK1AR",
    "outputId": "6893844e-1126-4e7d-b6cb-34b2ab04ab4f"
   },
   "outputs": [],
   "source": [
    "# Example 9: Classification neural network\n",
    "\n",
    "\n",
    "# Split into train/test\n",
    "ecgX_train, ecgX_test, ecgY_train, ecgY_test = train_test_split(    \n",
    "    ecgX, ecgY, test_size=0.25, random_state=10)\n",
    "\n",
    "\n",
    "# Construct neural network\n",
    "ecgModel = Sequential()\n",
    "ecgModel.add(Dense(100, input_dim=ecgX.shape[1], activation='relu',\n",
    "                kernel_initializer='random_normal'))  # Hidden 1\n",
    "ecgModel.add(Dense(50,activation='relu',kernel_initializer='random_normal')) # Hidden 2\n",
    "ecgModel.add(Dense(25,activation='relu',kernel_initializer='random_normal')) # Hidden 3\n",
    "ecgModel.add(Dense(ecgY.shape[1],activation='softmax',\n",
    "                kernel_initializer='random_normal')) # Output\n",
    "\n",
    "# Compile neural network\n",
    "ecgModel.compile(loss='categorical_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics =['accuracy'])\n",
    "\n",
    "# Create EarlyStopping monitor\n",
    "ecgMonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, \n",
    "                        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "# Fit the model to the data along with EarlyStopping montior\n",
    "ecgModel.fit(ecgX_train,ecgY_train,validation_data=(ecgX_test,ecgY_test),\n",
    "          callbacks=[ecgMonitor],verbose=2,epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you code is correct you should see something similiar to the output below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/1000\n",
    "22/22 - 1s - loss: 1.0377 - accuracy: 0.5596 - val_loss: 0.9685 - val_accuracy: 0.6043 - 630ms/epoch - 29ms/step\n",
    "Epoch 2/1000\n",
    "22/22 - 0s - loss: 0.9782 - accuracy: 0.6003 - val_loss: 0.9665 - val_accuracy: 0.6043 - 171ms/epoch - 8ms/step\n",
    "Epoch 3/1000\n",
    "22/22 - 0s - loss: 0.9786 - accuracy: 0.6003 - val_loss: 0.9652 - val_accuracy: 0.6043 - 147ms/epoch - 7ms/step\n",
    "Epoch 4/1000\n",
    "22/22 - 0s - loss: 0.9754 - accuracy: 0.6003 - val_loss: 0.9674 - val_accuracy: 0.6043 - 142ms/epoch - 6ms/step\n",
    "Epoch 5/1000\n",
    "22/22 - 0s - loss: 0.9733 - accuracy: 0.6003 - val_loss: 0.9626 - val_accuracy: 0.6043 - 145ms/epoch - 7ms/step\n",
    ".................\n",
    "Epoch 107/1000\n",
    "22/22 - 0s - loss: 0.7827 - accuracy: 0.6395 - val_loss: 0.9290 - val_accuracy: 0.6000 - 132ms/epoch - 6ms/step\n",
    "Epoch 108/1000\n",
    "22/22 - 0s - loss: 0.7833 - accuracy: 0.6337 - val_loss: 0.9500 - val_accuracy: 0.5913 - 141ms/epoch - 6ms/step\n",
    "Epoch 109/1000\n",
    "22/22 - 0s - loss: 0.7795 - accuracy: 0.6294 - val_loss: 0.9360 - val_accuracy: 0.6130 - 151ms/epoch - 7ms/step\n",
    "Epoch 110/1000\n",
    "Restoring model weights from the end of the best epoch: 60.\n",
    "22/22 - 0s - loss: 0.7744 - accuracy: 0.6294 - val_loss: 0.9543 - val_accuracy: 0.5870 - 143ms/epoch - 6ms/step\n",
    "Epoch 110: early stopping\n",
    "\n",
    "<keras.callbacks.History at 0x19d69ee9ee0>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular run, the model `egcModel` reached the lowest validation loss of `val_loss: 0.9099` after 60 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 9: Construct, Compile and Fit a Multiclass Classification Neural Network**\n",
    "\n",
    "In the cell below construct, compile and fit a multiclass classification neural network model called `ifModel` using the code in Example 8 as a template.\n",
    "\n",
    "Start by splitting the X-values stored in `ifX` into `ifX_train` and `ifX_test` sets with 75% being used for training. Similarily, split the Y-values stores in `ifY` are split into `ifY_train` and `ifY_test` sets. \n",
    "\n",
    "Build a linear (\"sequential\") muticlass classsification neural network called `ecgModel` with 3 hidden layers. Specify the number of inputs to the 1st hidden layer by the argument `input_dim=ifX.shape[1]` and specify the number of neurons in the output layer by the argument `ifY.shape[1]`. Since there are 3 classes in `ifY` (`Iris-setosa`, `Iris-versicolor`, `Iris-virginica`) the output layer will have 3 neurons--one neuron for each class.\n",
    "\n",
    "Once the model is constructed, it is compiled using the loss function, `categorical_crossentropy` and the `Adam` optimizer. \n",
    "\n",
    "Create an EarlyStopping monitor called, `ifMoniter` and specify the monitor to wait `20` epochs for the validation loss to start improving after reaching a local minimum, before termining the training. \n",
    "\n",
    "Finally, fit your model `ifModel` to the training and test (validation) data sets for 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aggbZoEUK1AR",
    "outputId": "6893844e-1126-4e7d-b6cb-34b2ab04ab4f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 9 here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you code is correct you should see something similiar to the output below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/1000\n",
    "4/4 - 0s - loss: 1.0967 - accuracy: 0.3214 - val_loss: 1.0958 - val_accuracy: 0.2895 - 477ms/epoch - 119ms/step\n",
    "Epoch 2/1000\n",
    "4/4 - 0s - loss: 1.0940 - accuracy: 0.3482 - val_loss: 1.0937 - val_accuracy: 0.2895 - 59ms/epoch - 15ms/step\n",
    "Epoch 3/1000\n",
    "4/4 - 0s - loss: 1.0909 - accuracy: 0.3482 - val_loss: 1.0904 - val_accuracy: 0.2895 - 57ms/epoch - 14ms/step\n",
    "Epoch 4/1000\n",
    "4/4 - 0s - loss: 1.0860 - accuracy: 0.3750 - val_loss: 1.0849 - val_accuracy: 0.3158 - 63ms/epoch - 16ms/step\n",
    "Epoch 5/1000\n",
    "4/4 - 0s - loss: 1.0798 - accuracy: 0.3393 - val_loss: 1.0775 - val_accuracy: 0.3158 - 65ms/epoch - 16ms/step\n",
    "...............\n",
    "Epoch 74/1000\n",
    "4/4 - 0s - loss: 0.0770 - accuracy: 0.9554 - val_loss: 0.0616 - val_accuracy: 0.9737 - 53ms/epoch - 13ms/step\n",
    "Epoch 75/1000\n",
    "4/4 - 0s - loss: 0.0786 - accuracy: 0.9732 - val_loss: 0.0594 - val_accuracy: 0.9737 - 56ms/epoch - 14ms/step\n",
    "Epoch 76/1000\n",
    "4/4 - 0s - loss: 0.0745 - accuracy: 0.9732 - val_loss: 0.0679 - val_accuracy: 1.0000 - 56ms/epoch - 14ms/step\n",
    "Epoch 77/1000\n",
    "Restoring model weights from the end of the best epoch: 72.\n",
    "4/4 - 0s - loss: 0.0740 - accuracy: 0.9821 - val_loss: 0.0674 - val_accuracy: 1.0000 - 54ms/epoch - 13ms/step\n",
    "Epoch 77: early stopping\n",
    "\n",
    "<keras.callbacks.History at 0x19d6a0cb130>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular run, the model `ifModel` reached the lowest validation loss of `val_loss: 0.0596` after 72 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr9U9rgvK1AR"
   },
   "source": [
    "### Calculate Classification Accuracy\n",
    " \n",
    "Accuracy is the number of rows where the neural network correctly predicted the target class.  Accuracy is _only_ used for classification, not regression.\n",
    "\n",
    "$$ accuracy = \\frac{c}{N} $$\n",
    "\n",
    "Where $c$ is the number correct and $N$ is the size of the evaluated set (training or validation). Higher accuracy numbers are desired.\n",
    "\n",
    "As we just saw, by default, Keras will return the percent probability for each class. We can change these prediction probabilities into the actual prediction values with **argmax**. For each prediction, argmax \"looks\" at the numerical value in each of the output neurons and assigns a value of one to the neuron with the highest values. In other words, this is an example of a \"winner take all\" strategy. The output neuron that \"wins\" represents the model's prediction for that particular combination of X values for one subject assigned to the training (validation) set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.24944986+0.501199+0.24935108"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 10: Convert prediction probabilites into actual prediction values\n",
    "\n",
    "The code in the cell below, uses `argmax` method to convert prediction probabilites from the `ecgModel` into actual prediction values. The `ecgModel` has three output neurons, the first one representing `RestingECG` class `LVH` (left ventricular hypertropy), the second one representing the class `Normal` and the third one representing the class `ST` (ST interval elevation). For each of the 230 subjects randomly assigned to the `ecgX_test` validation dataset, the model `ecgModel` will process the X-values for each subject and predicts the **_probability_** that the subject belongs to each class of `RestingECG` stores these prediction probabilites in a variable called `ecgProb`. \n",
    "\n",
    "What is actually stored in `ecgProb` is a 3-element numpy array for each of the 230 subjects in `ecgX_test` with the prediction probability values of the 3 output neurons. For example, here are the prediction probabilites values in `ecgProb` for the first subject in the `ecgX_test` data set:\n",
    "\n",
    "> `[[0.24944986 0.501199   0.24935108]]`\n",
    "\n",
    "The first value, `0.24944986` is the model's probability prediction that the subject had the `LVH` class of `RestingECG`, `0.501199` is the model's prediction probability that this subject had the `Normal` class and `0.24935108` the prediction probability that the subject had the `ST` class. As might be expected, the sum of these three values is 1.0. \n",
    "\n",
    "These prediction probabilites are converted into actual predictions using this line of code:\n",
    "\n",
    "> `ecgPred = np.argmax(ecgP1,axis=1)`\n",
    "\n",
    "The function `np.argmax()` sequentially processes each 3-element array in `ecgProb` and generates a new array called `ecgPred`. The array `ecgPred` will have a single integer value: `0`, `1` or `2` , for each subject in `x_test`, depending on prediction probabilities. If first value is the highest, `np.argmax()` will place a `0` in `ecgPred`, if the second value is the highest, the number `1` will be placed in `ecgPred`, and so forth. Subject 1, in the example above, would be assigned the value `1` since the second output neuron had the highest probability (`0.501199`). In other words, `np.argmax` assigns the model's actual prediction, `0`, `1` or `2`, to the output neuron with the highest probability prediction.\n",
    " subject.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 10: Convert probabilities to predictions\n",
    "\n",
    "# Use model to predict probabilites for subjects in x_test\n",
    "ecgProb = ecgModel.predict(ecgX_test)\n",
    "\n",
    "# Print prediction probabilites\n",
    "print(ecgProb[0:6])  \n",
    "\n",
    "# Use argmax to convert probabilites to prediction values\n",
    "ecgPred = np.argmax(ecgProb,axis=1)\n",
    "\n",
    "# Print out prediction values \n",
    "print(ecgPred[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similiar to the output below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8/8 [==============================] - 0s 3ms/step\n",
    "[[0.24944986 0.501199   0.24935108]\n",
    " [0.12482199 0.57438475 0.30079323]\n",
    " [0.17668504 0.6379587  0.18535627]\n",
    " [0.3083075  0.55753493 0.13415763]\n",
    " [0.25011855 0.6450567  0.10482469]\n",
    " [0.2428562  0.52980953 0.22733422]]\n",
    "[1 1 1 1 1 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, our model `ecgModel` is **_not_** very certain when it comes to predicting the `RestingECG` class. Essentially the model is saying that there is a 50% chance most subjects will have a `RestingECG` that is `Normal`, and a 50% chance that the subject's `RestingECG` will not be normal. This is basically the same accuracy as \"coin-flipping\". \n",
    "\n",
    "There is no guarantee that a neural network model you build will be especially accurate when fitted to given dataset! In this case, the relatively low number of test subjects in the dataset (_n_=918) is probably a main reason for the low accuracy. It is also possible that the class of `RestingECG` is not strongly dependent on the clinical variables used in the training set, `ecgX_train`.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 10: Convert prediction probabilites into actual prediction values**\n",
    "\n",
    "In the cell below write the code to generate an Numpy array called `ifProb` that contains the prediction probabilities for all of the Iris flowers in the validation set, `ifX_train`. Print out the first 6 values in `ifProb`. The use the function `np.argmax()` to convert these prediction probabilites into actual predictions. Store the model's actual predictions in a new Numpy array called `ifPred`. Print out the first 6 values in `ifPred`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 10 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2/2 [==============================] - 0s 5ms/step\n",
    "[[1.8357505e-05 9.6463978e-01 3.5341803e-02]\n",
    " [9.9827397e-01 1.7260480e-03 2.6477404e-10]\n",
    " [3.2641384e-18 1.2062706e-05 9.9998796e-01]\n",
    " [8.3687219e-06 9.2610931e-01 7.3882379e-02]\n",
    " [6.9982616e-06 9.6391165e-01 3.6081333e-02]\n",
    " [9.9725479e-01 2.7451809e-03 1.2289548e-09]]\n",
    "[1 0 2 1 1 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared the model `ecgModel`, the Iris Flower model, `ifModel` is clearly more certain about which `species` class to assign to the flowers in the validation data set `ifX_test`. In the example above, the model `ifModel` predicted that the first flower in the validation data set had the following probabilites:\n",
    "\n",
    "> `[1.8357505e-05 9.6463978e-01 3.5341803e-02]`\n",
    "\n",
    "Because these values vary so much in magnitude, Numpy automatically printed them out in **_scientific_** notation. In non-scientific notation, these values are:\n",
    "\n",
    "> `0.000018357505 0.96463978 0.035341803`\n",
    "\n",
    "In other words, `ifModel` predicts that there is an essentially `0%` chance that the first flower in the validation test set is `Iris setosa`, a `97%` chance that the flower species is `Iris versicolor` and less than a `4%` chance that the flower species is `Iris virginica`. The Numpy function, `np.argmax()` places a `1` in `ifPred` representing `Iris versicolor` as the model's actual prediction for the first flower.\n",
    "\n",
    "Even though the Iris flower dataset is much smaller (_n_=150) than the Heart Disease dataset (_n_=918), why is the neural network constructed in **Exercise 9** so much more accurate? \n",
    "\n",
    "The answer lies in the different nature of the two datasets. It turns out that the sepal and petal dimensions of Iris flowers are **very** species specific. It simply not that hard for a neural network to figure out the correct relationships (i.e. connection weights) between the neurons in the hidden layers so that a particular set of sepal and petal dimensions (X values) end up going to correct output neuron. \n",
    "\n",
    "On the other hand, humans often exhibit a wide range of variations in their characteristics. This is especially true for the measurements found in medical/clinical datasets. **_If_** there is a correlation between clinical values, it may take a very large dataset for a neural network to correctly identify these correlations.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_a5WcpJK1AS"
   },
   "source": [
    "### Example 11: Compute the percent accuracy\n",
    "\n",
    "Now that we have the actual `RestingECG` type predicted for each subject in the validation test set (`ecgX_test), we can calculate the percent accuracy (how many were correctly classified). The code for doing this is shown in the next cell. \n",
    "\n",
    "In the first step, a Numpy array called `ecg_compare` is created. This array contains the actual `RestingEGC` value for each subject in the validation set, where `0` represents `LVH`, `1` represents `Normal` and `2` represents `ST`. \n",
    "\n",
    "In the next step, the function `metric.accuracy_score()` from the `sklean` library computes the accuracy score by comparing the **actual** RestingECG values in `ecg_compare` with the **_predicted_** RestingECG values stored in `ecgPred` and returns the accuracy in the variable called `score`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7ZN4mO5K1AS",
    "outputId": "8a2bf888-d1e2-4317-bc55-855b78b5db99"
   },
   "outputs": [],
   "source": [
    "# Example 11: Compute precent accuracy\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate array containing actual class type\n",
    "ecgY_compare = np.argmax(ecgY_test,axis=1) \n",
    "print(f'First 6 values in Y_compare: {ecgY_compare[0:6]}')\n",
    "\n",
    "# Compute the percentage score\n",
    "score = metrics.accuracy_score(ecgY_compare, ecgPred)\n",
    "\n",
    "# Print out the score\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something like the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First 6 values in Y_compare: [1 2 1 2 0 1]\n",
    "Accuracy score: 0.5652173913043478"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this run, the model `ecgModel` was only able to predict the correct class of `RestingECG` about 56% of the time. Not especially impressive, but it's about what we would have expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_a5WcpJK1AS"
   },
   "source": [
    "### **Exercise 11: Compute the percent accuracy**\n",
    "\n",
    "In the cell below, compute the accuracy score for your model `ifModel` using Example 11 as a template. Store the actual species name (class value) in an array called `ifY_compare` and print out the first 6 values. Use the function `metrics.accuracy_score()` to compute the accuracy of your model and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7ZN4mO5K1AS",
    "outputId": "8a2bf888-d1e2-4317-bc55-855b78b5db99"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 11 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something like the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First 6 values in Y_compare: [1 0 2 1 1 0]\n",
    "Accuracy score: 0.9736842105263158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As might be expected, your model `ifModel` is able predict the correct species of Iris flower with more than 95% accuracy! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zlG17MKK1AS"
   },
   "source": [
    "## Calculate Classification Log Loss\n",
    "\n",
    "**_Log loss_**, also known as logarithmic loss or cross-entropy loss, is a common evaluation metric used in machine learning, particularly for binary classification problems. It measures the performance of a classification model by penalizing false classifications.\n",
    "\n",
    "In binary classification, where the target variable has two classes (usually labeled as 0 and 1), log loss is calculated as the negative logarithm of the predicted probability assigned to the correct class. The formula for log loss for a single observation is:\n",
    "\n",
    "$\\text{Log Loss} = - \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]$\n",
    "\n",
    "where:\n",
    "\n",
    "    ( N ) is the number of observations,\n",
    "    ( y_i ) is the actual class label (0 or 1) for the ( i )th observation,\n",
    "    ( p_i ) is the predicted probability that the ( i )th observation belongs to class 1.\n",
    "\n",
    "A lower log loss indicates better performance, with 0 representing a perfect model and higher values indicating poorer performance. Log loss is a useful metric for evaluating the accuracy of probabilistic predictions generated by a classification model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 12: Calculate Log Loss\n",
    "\n",
    "The code in the cell below calculates the log loss for the model `ecgModel`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ucCNS9XAK1AS",
    "outputId": "76375262-9554-4105-9d2c-3b088732e2df"
   },
   "outputs": [],
   "source": [
    "# Example 12: Calculate Log Loss\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Don't display numpy in scientific notation\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Generate predictions\n",
    "ecgPred = ecgModel.predict(ecgX_test)\n",
    "\n",
    "print(\"Numpy array of predictions\")\n",
    "display(ecgPred[0:5])\n",
    "\n",
    "print(\"As percent probability\")\n",
    "print(ecgPred[0]*100)\n",
    "\n",
    "score = metrics.log_loss(ecgY_test, ecgPred)\n",
    "print(\"Log loss score: {}\".format(score))\n",
    "\n",
    "# raw probabilities to chosen class (highest probability)\n",
    "ecgPred = np.argmax(ecgPred,axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the output below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8/8 [==============================] - 0s 4ms/step\n",
    "Numpy array of predictions\n",
    "\n",
    "array([[0.2494, 0.5012, 0.2494],\n",
    "       [0.1248, 0.5744, 0.3008],\n",
    "       [0.1767, 0.638 , 0.1854],\n",
    "       [0.3083, 0.5575, 0.1342],\n",
    "       [0.2501, 0.6451, 0.1048]], dtype=float32)\n",
    "\n",
    "As percent probability\n",
    "[24.945  50.1199 24.9351]\n",
    "Log loss score: 0.9228499967441923\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log loss score `0.92` looks pretty high. Let's see how it compares to your model `ifModel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 12: Calculate Log Loss**\n",
    "\n",
    "In the cell below calculate the log loss for the model `ifModel`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ucCNS9XAK1AS",
    "outputId": "76375262-9554-4105-9d2c-3b088732e2df"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 12 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the output below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2/2 [==============================] - 0s 9ms/step\n",
    "Numpy array of predictions\n",
    "\n",
    "array([[0.    , 0.9646, 0.0353],\n",
    "       [0.9983, 0.0017, 0.    ],\n",
    "       [0.    , 0.    , 1.    ],\n",
    "       [0.    , 0.9261, 0.0739],\n",
    "       [0.    , 0.9639, 0.0361]], dtype=float32)\n",
    "\n",
    "As percent probability\n",
    "[ 0.0018 96.464   3.5342]\n",
    "Log loss score: 0.0597694178993309"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log loss score for your Iris flower model, 0.06 is much lower, and therefore significantly better than the 0.92 log loss score for the model `ecgModel`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU3NLdorK1AS"
   },
   "source": [
    "[Log loss](https://www.kaggle.com/wiki/LogarithmicLoss) is calculated as follows:\n",
    "\n",
    "$$ \\mbox{log loss} = -\\frac{1}{N}\\sum_{i=1}^N {( {y}_i\\log(\\hat{y}_i) + (1 - {y}_i)\\log(1 - \\hat{y}_i))} $$\n",
    "\n",
    "\n",
    "You should use this equation only as an objective function for classifications that have two outcomes. The variable y-hat is the neural network’s prediction, and the variable y is the known correct answer.  In this case, y will always be 0 or 1.  The training data have no probabilities. The neural network classifies it either into one class (1) or the other (0).  \n",
    "\n",
    "The variable N represents the number of elements in the training set the number of questions in the test.  We divide by N because this process is customary for an average.  We also begin the equation with a negative because the log function is always negative over the domain 0 to 1.  This negation allows a positive score for the training to minimize.\n",
    "\n",
    "You will notice two terms are separated by the addition (+).  Each contains a log function.  Because y will be either 0 or 1, then one of these two terms will cancel out to 0.  If y is 0, then the first term will reduce to 0.  If y is 1, then the second term will be 0.  \n",
    "\n",
    "If your prediction for the first class of a two-class prediction is y-hat, then your prediction for the second class is 1 minus y-hat.  Essentially, if your prediction for class A is 70% (0.7), then your prediction for class B is 30% (0.3).  Your score will increase by the log of your prediction for the correct class.  If the neural network had predicted 1.0 for class A, and the correct answer was A, your score would increase by log (1), which is 0. For log loss, we seek a low score, so a correct answer results in 0.  Some of these log values for a neural network's probability estimate for the correct class:\n",
    "\n",
    "* -log(1.0) = 0\n",
    "* -log(0.95) = 0.02\n",
    "* -log(0.9) = 0.05\n",
    "* -log(0.8) = 0.1\n",
    "* -log(0.5) = 0.3\n",
    "* -log(0.1) = 1\n",
    "* -log(0.01) = 2\n",
    "* -log(1.0e-12) = 12\n",
    "* -log(0.0) = negative infinity\n",
    "\n",
    "As you can see, giving a low confidence to the correct answer affects the score the most.  Because log (0) is negative infinity, we typically impose a minimum value.  Of course, the above log values are for a single training set element.  We will average the log values for the entire training set.\n",
    "\n",
    "The log function is useful to penalizing wrong answers.  The following code demonstrates the utility of the log function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "g5Zv2tgNK1AT",
    "outputId": "f0861083-7809-406f-9970-4c83505ca14a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from numpy import arange, sin, pi\n",
    "\n",
    "#t = arange(1e-5, 5.0, 0.00001)\n",
    "#t = arange(1.0, 5.0, 0.00001) # computer scientists\n",
    "t = arange(0.0, 1.0, 0.00001)  # data     scientists\n",
    "\n",
    "fig = figure(1,figsize=(12, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(t, np.log(t))\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim((-8, 1.5))\n",
    "ax1.set_xlim((-0.1, 2))\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('log(x)')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaRtddpcK1AT"
   },
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A confusion matrix is a performance measurement tool used in machine learning for evaluating the accuracy of a classification model. It is a table that allows visualization of the performance of a model by comparing the actual values of the target variable with the predicted values. The confusion matrix is particularly useful for evaluating the performance of a classification model on a dataset with known class labels.\n",
    "\n",
    "The confusion matrix is organized into a grid with four possible outcomes:\n",
    "\n",
    "* **True Positives (TP):** The number of correct predictions that the model has made for the positive class.\n",
    "* **True Negatives (TN):** The number of correct predictions that the model has made for the negative class.\n",
    "* **False Positives (FP):** The number of incorrect predictions that the model has made, predicting a positive class when the actual class is negative (Type I error).\n",
    "* **False Negatives (FN):** The number of incorrect predictions that the model has made, predicting a negative class when the actual class is positive (Type II error).\n",
    "\n",
    "The confusion matrix enables the calculation of various evaluation metrics such as accuracy, precision, recall, F1 score, and specificity. These metrics help in assessing the model's performance, identifying potential areas for improvement, and making informed decisions about the model's effectiveness for the given classification task.\n",
    "\n",
    "In other words, a confusion matrix shows which predicted classes are often confused for the other classes. The vertical axis (y) represents the true labels and the horizontal axis (x) represents the predicted labels. When the true label and predicted label are the same, the highest values occur down the diagonal extending from the upper left to the lower right. The other values, outside the diagonal, represent incorrect predictions. For example, in the confusion matrix below, the value in row 2, column 1 shows how often the predicted value A occurred when it should have been B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 13: Generate Confusion Matrix\n",
    "\n",
    "The code in the cell below generates a Confusion Matrix for the model `ecgModel`. It uses the function `plot_confusion_matrix()` that was defined earlier in this lesson. To generate the Confusion Matrix, only two arguments need to be passed to the plotting function, the actual values of the `RestingEGC` of the patients in the validation set (i.e. `ecgY_compare`), and the model's predicted values for these patients (i.e. `ecgPred`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "1pvqhwRcK1AT",
    "outputId": "89d39b8b-af2d-4861-81da-905acb8c5528",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 13: Generate confusion matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(ecgY_compare, ecgPred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, ECGclasses, \n",
    "        title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the figure below:\n",
    "\n",
    "![___](https://biologicslab.co/BIO1173/images/class_04_2_CM1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Confusion Matrix above, for the model `ecgModel`, indicates that it predicted the `RestingEGC` was normal for nearly **_every_** subject in the validation (test) set, irregardless of their actual type. The model was able to correctly identify patients with LVH only 8% of the time but missidentified the remaining 90%  as having a normal `RestingECG` the rest of the time. The model was never able to identify any of the patients in the validation data set who had a `RestingECG` of the type `ST`. \n",
    "\n",
    "Based on our results so far, we should expect your model `ifModel` to generate a much different looking Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 13: Generate Confusion Matrix**\n",
    "\n",
    "In the cell below write the code to generate a Confusion Matrix for your Iris flower model, `ifModel`, using Example 13 as a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "1pvqhwRcK1AT",
    "outputId": "89d39b8b-af2d-4861-81da-905acb8c5528"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exericse 13 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the figure below:\n",
    "\n",
    "![___](https://biologicslab.co/BIO1173/images/class_04_2_CM2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the Confusion Matrix\n",
    "\n",
    "Let's analyze the Confusion Matrix above to see what is says about your Iris Flower model, `ifModel`. \n",
    "\n",
    "Based on the Confusion Matrix your `ifModel` was able to predict, with 100% accuracy, the correct species of flowers obtained from both _`Iris setosa`_ (top left) and _`Iris virginica`_ (bottom right). The top left and bottom right squares in the Confusion Matrix are colored with the darkest possible shade of blue. According to the color key shown at the right of this image, this shade of dark blue represents a value of `1.0`, which means a perfect score.\n",
    "\n",
    "When it came to flowers from the species, _`Iris versicolor`_, however, your model was accurate only about 90% of the time. Furthermore, based on the Confusion Matrix, when your model made a mistake, it invariably classified an _`Iris versicolor`_ flower as being from the species _`Iris virginica`_, but it _never_ confused the flower as being from the species _`Iris setosa`_. (Note light blue color panel in the center of the right side). \n",
    "\n",
    "If we wanted to improve our model, we should focus on ways to improve the model's ability to discrimate between flowers from these two species.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lesson Turn-in**\n",
    "\n",
    "When you have completed all of the code cells, and run them in sequential order (the last code cell should be number 33), use the **File --> Print.. --> Save to PDF** to generate a PDF of your JupyterLab notebook. Save your PDF as `Class_04_2.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
