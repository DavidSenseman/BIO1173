{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/main/Class_05_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZVwSpdbE3Y"
      },
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExN-OzpYbE3Y"
      },
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4imk1kbE3Y"
      },
      "source": [
        "##### **Module 5: Natural Language Processing**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Biology, Health and the Environment](https://sciences.utsa.edu/bhe/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "### Module 5 Material\n",
        "\n",
        "* Part 5.1: Introduction to Hugging Face\n",
        "* Part 5.2: Hugging Face Tokenizers\n",
        "* Part 5.3: Hugging Face Datasets\n",
        "* **Part 5.4: Training Hugging Face models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_-lPkxLbE3Z"
      },
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. By running this code cell, you will map your GDrive to /content/drive and print out your Google GMAIL address. Your Instructor will use your GMAIL address to verify the author of this class lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seXFCYH4LDUM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# You must run this cell first\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    Colab = True\n",
        "    print(\"Note: Using Google CoLab\")\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"**WARNING**: Your GMAIL address was **not** printed in the output below.\")\n",
        "    print(\"**WARNING**: You will NOT receive credit for this lesson.\")\n",
        "    Colab = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG3_sXTDfyjA"
      },
      "source": [
        "You should see the following output except your GMAIL address should appear on the last line.\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image01B.png)\n",
        "\n",
        "If your GMAIL address does not appear your lesson will **not** be graded."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Log into Hugging Face**\n",
        "\n",
        "Run the next code cell to log into your Hugging Face account using your HF_Token stored in your Colab Secrets. You may have to grant access to your Colab Secrets."
      ],
      "metadata": {
        "id": "l_0F_RKeiUQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log into Hugging Face.\n",
        "\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Get the token from Colab Secrets and log in\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"Successfully logged into Hugging Face!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error logging into Hugging Face: {e}\")"
      ],
      "metadata": {
        "id": "IJMpW0XqiYXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your `HF_TOKEN` is correctly stored in your Colab Secrets, you should see the following output:\n",
        "\n",
        "```text\n",
        "Successfully logged into Hugging Face!\n",
        "```\n",
        "Information on how to obtain your `HF_Token` and store it in your Colab Secrets has already been provided to you. If you are having trouble getting it to work, please see the course Instructor or a TA."
      ],
      "metadata": {
        "id": "Gx8_nEOPidsj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y1civyK7D7P"
      },
      "source": [
        "## **Accelerated Run-time Check**\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. The code in this cell checks what hardware acceleration you are using. To run this lesson, you must be running a Graphics Processing Unit (GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeDpYygK7OcO"
      },
      "outputs": [],
      "source": [
        "# You must run this cell second\n",
        "\n",
        "import torch\n",
        "\n",
        "# Check for GPU\n",
        "def check_colab_gpu():\n",
        "    print(\"=== Colab GPU Check ===\")\n",
        "\n",
        "    # Check PyTorch\n",
        "    pt_gpu = torch.cuda.is_available()\n",
        "    print(f\"PyTorch GPU available: {pt_gpu}\")\n",
        "\n",
        "    if pt_gpu:\n",
        "        print(f\"PyTorch device count: {torch.cuda.device_count()}\")\n",
        "        print(f\"PyTorch current device: {torch.cuda.current_device()}\")\n",
        "        print(f\"PyTorch device name: {torch.cuda.get_device_name()}\")\n",
        "        print(\"You are good to go!\")\n",
        "\n",
        "    else:\n",
        "        print(\"No compatible device found\")\n",
        "        print(\"WARNING: You must run this assigment using either a GPU to earn credit\")\n",
        "        print(\"Change your RUNTIME now and start over!\")\n",
        "\n",
        "check_colab_gpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv5dGIY77WS2"
      },
      "source": [
        "If you current `Runtime` is correct you should see something _similar_ to the following output\n",
        "\n",
        "```text\n",
        "=== Colab GPU Check ===\n",
        "PyTorch GPU available: True\n",
        "PyTorch device count: 1\n",
        "PyTorch current device: 0\n",
        "PyTorch device name: NVIDIA A100-SXM4-80GB\n",
        "You are good to go!\n",
        "```\n",
        "\n",
        "However, if the output says:\n",
        "```text\n",
        "No compatible device found\n",
        "WARNING: You must run this assigment using either a GPU to earn credit\n",
        "Change your RUNTIME now and start over!\n",
        "```\n",
        "you need to follow these instructions!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **YouTube Introduction to Training Hugging Face Datasets**\n",
        "\n",
        "Run the next cell to see short introduction to Training Hugging Face Datasets."
      ],
      "metadata": {
        "id": "xdz1XXs_gCks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "video_id = \"7YZOik5S3vs\"\n",
        "\n",
        "HTML(f\"\"\"\n",
        "<iframe width=\"560\" height=\"315\"\n",
        "  src=\"https://www.youtube.com/embed/{video_id}\"\n",
        "  title=\"YouTube video player\"\n",
        "  frameborder=\"0\"\n",
        "  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
        "  allowfullscreen\n",
        "  referrerpolicy=\"strict-origin-when-cross-origin\"> </iframe>\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "-WCyYxC1kSQa",
        "outputId": "d96c3a4b-4b2c-417f-8437-8df497009f82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<iframe width=\"560\" height=\"315\"\n",
              "  src=\"https://www.youtube.com/embed/7YZOik5S3vs\"\n",
              "  title=\"YouTube video player\"\n",
              "  frameborder=\"0\"\n",
              "  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
              "  allowfullscreen\n",
              "  referrerpolicy=\"strict-origin-when-cross-origin\"> </iframe>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOOH7DgTY1Gx"
      },
      "source": [
        "## **Training Hugging Face Models**\n",
        "\n",
        "**Hugging Face Models** are pre-trained machine learning models available on the Hugging Face Model Hub. These models cover a wide range of tasks, including natural language processing, computer vision, audio processing, and more. They are designed to be easily accessible and usable, allowing developers and researchers to leverage state-of-the-art models without needing to train them from scratch.\n",
        "\n",
        "There are several reasons why you might want to train Hugging Face Models:\n",
        "\n",
        "1. **Customization:** Fine-tuning a pre-trained model on your specific dataset can improve its performance on your particular task.\n",
        "\n",
        "2. **Efficiency:** Training a model from scratch can be time-consuming and resource-intensive. Fine-tuning a pre-trained model can save time and computational resources.\n",
        "\n",
        "2. **Accessibility:** Hugging Face provides tools and libraries that make it easier to train and deploy models, lowering the barrier to entry for machine learning projects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Ny7DNFYhRP"
      },
      "source": [
        "### Install Custom Function\n",
        "\n",
        "Run the next cell to create a custom function for this lesson. You code will not run corrctly if you fail to run the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WllsY2jkrj-C"
      },
      "outputs": [],
      "source": [
        "# Simple function to print out elasped time\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaOJ4Sr36arE"
      },
      "source": [
        "If the code is correct you should not see any output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlPf_OSZZK9u"
      },
      "source": [
        "### Install Hugging Face Datasets\n",
        "\n",
        "Install the Hugging Face datasets by running the code in the next cell. This may take a little while so please be patient.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evqhMPU8ZSV-"
      },
      "outputs": [],
      "source": [
        "# Install Hugging Face Datasets\n",
        "\n",
        "!pip install -q transformers\n",
        "!pip install -q transformers[torch]\n",
        "!pip install -q transformers[sentencepiece]\n",
        "!pip install -q datasets\n",
        "!pip install -q huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPq7I3d76Rzd"
      },
      "source": [
        "If the code is correct you should _not_ see any output."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Emotion Analysis**\n",
        "\n",
        "**Emotion analysis** (also called **affective computing** or **sentiment/emotion classification**) is a subfield of NLP that focuses on identifying and categorizing emotions expressed in text.\n",
        "\n",
        "Unlike sentiment analysis (which typically classifies text as positive, negative, or neutral), emotion analysis aims to detect **specific emotions** such as:\n",
        "- Joy\n",
        "- Sadness\n",
        "- Anger\n",
        "- Fear\n",
        "- Surprise\n",
        "- Disgust\n",
        "- Trust\n",
        "- Anticipation\n",
        "\n",
        "### **Common Approaches**\n",
        "\n",
        "#### **1. Lexicon-Based Methods**\n",
        "Use predefined dictionaries like:\n",
        "- **NRC Emotion Lexicon**\n",
        "- **WordNet-Affect**\n",
        "- **LIWC**\n",
        "\n",
        "These map words to emotions and aggregate scores across a text.\n",
        "\n",
        "#### **2. Machine Learning Models**\n",
        "Train classifiers (e.g., SVM, Logistic Regression) on labeled datasets:\n",
        "- Features: Bag-of-Words, TF-IDF, word embeddings\n",
        "- Datasets: EmoReact, ISEAR, SemEval, TweetEval\n",
        "\n",
        "#### **3. Deep Learning Models**\n",
        "Use neural networks like:\n",
        "- CNNs or RNNs (LSTM/GRU)\n",
        "- Transformers (e.g., BERT, RoBERTa)\n",
        "- Fine-tuned models on emotion datasets\n",
        "\n",
        "In Example 1 we will be using a transformer deep learning model called **`DistBert`** for **sequence classification** with the **`Go-Emotions`** dataset."
      ],
      "metadata": {
        "id": "2BL2nLCf2YIZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtY6Vr677LAK"
      },
      "source": [
        "## **GO‑Emotions Dataset (Hugging Face)**\n",
        "\n",
        "**The GO‑Emotions dataset** is a large, high-quality collection of 58,000 short `Reddit` comments annotated with 27 fine-grained emotions, such as *admiration*, *anger*, *anxiety*, and *gratitude*. Each comment may carry multiple emotions, making it a multi‑label classification resource that captures the nuanced affective states people express online.\n",
        "\n",
        "#### **Relevance for Computational Biologists**\n",
        "\n",
        "1. **Concrete, Hands‑On Machine‑Learning Practice**  \n",
        "   - The dataset is *only* 58 k short text snippets, so it can be processed on a laptop or a free Google‑Colab GPU.  \n",
        "   - Students learn the full pipeline: data loading, tokenization, model selection, fine‑tuning, evaluation, and reproducible experimentation—all in a single, end‑to‑end notebook.\n",
        "\n",
        "2. **Multi-Label Classification – A Common Challenge in Bioinformatics**  \n",
        "   - In genomics or proteomics you often predict *multiple* functional annotations per gene or protein.  \n",
        "   - Training on GO‑Emotions teaches how to handle overlapping labels, compute appropriate metrics (AUROC, macro‑F1), and balance class weights—skills directly transferable to multi‑label problems like predicting disease phenotypes or pathway memberships.\n",
        "\n",
        "3. **Transfer Learning & Fine‑Tuning of Pre-Trained Models**  \n",
        "   - Students get to experiment with transformer architectures (BERT, RoBERTa, etc.) and see how a language model trained on general English can be adapted to a highly specialized task.  \n",
        "   - This mirrors how pre‑trained protein language models (e.g., ESM, ProtBERT) are fine‑tuned for structure or function prediction in computational biology.\n",
        "\n",
        "4. **Real-World, Open-Science Data**  \n",
        "   - GO-Emotions is released under a CC-BY-SA license, encouraging open-source collaboration.  \n",
        "   - Working with openly available data instills best practices in reproducibility, version control, and ethical data handling—critical in biomedical research.\n",
        "\n",
        "5. **Interdisciplinary Connection to Bio‑Text Mining**  \n",
        "   - Sentiment and emotion analysis are valuable in public health surveillance, patient‑reported outcomes, and pharmacovigilance.  \n",
        "   - By mastering affective NLP, students can later apply these skills to biomedical literature mining, extracting patient emotions from electronic health records or social media for disease-monitoring projects.\n",
        "\n",
        "6. **Scalable Learning Curve**  \n",
        "   - The dataset is rich enough to explore advanced topics (e.g., class‑imbalance techniques, ensembling, interpretability) but still small enough for quick iteration.  \n",
        "   - This balance helps students build confidence before tackling larger biomedical corpora (e.g., PubMed abstracts, clinical notes).\n",
        "\n",
        "**Bottom line:** Training a model on **`GO-Emotions`** gives computational biology students a focused, manageable, and highly transferable machine‑learning project that bridges NLP fundamentals, multi‑label modeling, and open‑science principles—all of which are essential skills for modern bioinformatics and computational biology research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRT_IgZL03WL"
      },
      "source": [
        "----------------------------------\n",
        "\n",
        "## **Example**\n",
        "\n",
        "For pedagogical reasons the Example has been broken up into a series of sequential steps to make the coding easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5Cdpn42XxXp"
      },
      "source": [
        "### Example-Step 1: Load Dataset\n",
        "\n",
        "The code in the next cell loads the **`GO-Emotions`** dataset into the variable `emotions_dataset`. The code also loads several libraries that we will be using later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9LS0Ro0XZjj"
      },
      "outputs": [],
      "source": [
        "# Example-Step 1: Load dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, default_data_collator\n",
        "import torch\n",
        "import time\n",
        "from transformers import (\n",
        "    DistilBertForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "emotions_dataset = load_dataset(\"google-research-datasets/go_emotions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07TKU87ks_KE"
      },
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image01F.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knk_vdRk0sK0"
      },
      "source": [
        "### Example-Step 2: Print Examples\n",
        "\n",
        "The code in the next cell first prints out the column names in the `go_emotions_dataset`. It is important to know exactly what the column names are for later steps in the analysis.\n",
        "\n",
        "After the column names are printed, the `text` and the `label` from one record is printed. Which record selected depends upon the value of the variable `RecordNumber`. In the example below `RecordNumber` is set to 3. Just set this variable to another value if you want to look at a different record."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example-Step 2: Print Examples\n",
        "\n",
        "# Set record number\n",
        "RecordNumber = 3\n",
        "\n",
        "# Print column names\n",
        "print(f\"Dataset column names:\", emotions_dataset.column_names)\n",
        "\n",
        "# Print text from one record\n",
        "print(f\"Record\", RecordNumber, \"text:\", emotions_dataset['train'][RecordNumber]['text'])\n",
        "\n",
        "# Print label assigned to the text - handle both 'label' and 'labels'\n",
        "label_col = 'labels' if 'labels' in emotions_dataset['train'].column_names else 'label'\n",
        "print(f\"Record\", RecordNumber, \"label:\", emotions_dataset['train'][RecordNumber][label_col])\n"
      ],
      "metadata": {
        "id": "XGHzBNN60vyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct, you should see the following output:\n",
        "```text\n",
        "Dataset column names: {'train': ['text', 'labels', 'id'], 'validation': ['text', 'labels', 'id'], 'test': ['text', 'labels', 'id']}\n",
        "Record 3 text: To make her feel threatened\n",
        "Record 3 labels: [14]\n",
        "```"
      ],
      "metadata": {
        "id": "GsrYaoexmDzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For `RecordNumber=3` the text was:\n",
        "```text\n",
        "To make her feel threatened\n",
        "```\n",
        "The `emotions_dataset` assigned the `label` = `14` to this text.\n",
        "\n",
        "The table below shows the numerical value assigned to each emotion category. By inspection you can see that the number `14` maps to **Fear**, which seems reasonable for a woman who \"feels threatned\".\n",
        "\n",
        "List of **go‑emotions** emotion categories\n",
        "\n",
        "| #  | Emotion        |\n",
        "|----|----------------|\n",
        "| 1  | Admiration     |\n",
        "| 2  | Amusement      |\n",
        "| 3  | Anger          |\n",
        "| 4  | Annoyance      |\n",
        "| 5  | Approval       |\n",
        "| 6  | Caring         |\n",
        "| 7  | Confusion      |\n",
        "| 8  | Curiosity      |\n",
        "| 9  | Desire         |\n",
        "|10  | Disappointment |\n",
        "|11  | Disgust        |\n",
        "|12  | Embarrassment  |\n",
        "|13  | Excitement     |\n",
        "|14  | Fear           |\n",
        "|15  | Gratitude      |\n",
        "|16  | Grief          |\n",
        "|17  | Joy            |\n",
        "|18  | Love           |\n",
        "|19  | Nervousness    |\n",
        "|20  | Optimism       |\n",
        "|21  | Pride          |\n",
        "|22  | Realization    |\n",
        "|23  | Remorse        |\n",
        "|24  | Sadness        |\n",
        "|25  | Surprise       |\n",
        "|26  | Thankfulness   |\n",
        "|27  | Trust          |\n"
      ],
      "metadata": {
        "id": "sR6aGEmoZm_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------\n",
        "\n",
        "## **Tokenization**\n",
        "\n",
        "An important step in any NLP analysis is **tokenization**.\n",
        "\n",
        "#### **Why we need tokenization**\n",
        "\n",
        "| Need | What tokenisation gives us | Example |\n",
        "|------|---------------------------|---------|\n",
        "| **Convert text to numbers** | NLP models are neural nets that accept *vectors* of integers. | `\"I love coffee\"` → `[101, 1024, 1045, 112, ...]` |\n",
        "| **Respect model vocabulary** | The tokenizer knows the exact wordpiece / subword vocabulary of the chosen pre‑trained model. | `\"unbelievable\"` → `[token1, token2]` that match `distilbert`’s embedding matrix. |\n",
        "| **Add special tokens** | Most transformer models expect special tokens (`[CLS]`, `[SEP]`, etc.) at specific positions. | `\"Hello world\"` → `\"[CLS] Hello world [SEP]\"` |\n",
        "| **Generate attention masks** | Indicates to the model which positions are real tokens and which are padding. | `[1, 1, 1, 0, 0, ...]` |\n",
        "| **Uniform length** | `padding=\"max_length\"` pads every sequence to the same length, making batching possible. | Short sentences become `[ID, ID, PAD, PAD, ...]` |\n",
        "| **Truncate long sequences** | `truncation=True` keeps only the first `max_length` tokens, preventing OOM errors. | `\"This is a very long sentence …\"` → first 512 tokens |\n",
        "\n",
        "Without tokenisation, the model would receive a string of characters that it cannot process, and the training loop would fail.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Quick Visualization**\n",
        "\n",
        "```text\n",
        "raw text:  \"I am happy today!\"\n",
        "tokeniser:  tokenizer(\"I am happy today!\")\n",
        "outputs:    {\n",
        "              'input_ids': [101, 1045, 2572, 2690, 2006, 102],\n",
        "              'attention_mask': [1, 1, 1, 1, 1, 1],\n",
        "              ...\n",
        "            }\n",
        "```\n",
        "---------------------------"
      ],
      "metadata": {
        "id": "duj-7gAEc8Oe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOtJkR0P2U3u"
      },
      "source": [
        "### Example-Step 3: Tokenize and Format the Dataset\n",
        "\n",
        "\n",
        "The code in the cell below tokenizes the raw text, normalises the labels, and creates two ready-to-train splits (`train` & `eval`) that you can feed into a `DistilBERT model` (e.g., via Hugging Face Trainer).\n",
        "\n",
        "This code is a classic data-preparation pipeline for any text-classification task."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example-Step 3: Tokenize and Format the Dataset\n",
        "\n",
        "# Initialize the tokenizer\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "# Define the tokenize function\n",
        "def tokenize(rows):\n",
        "    return tokenizer(rows['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Tokenize the dataset\n",
        "eg_tokenized_datasets = emotions_dataset.map(tokenize, batched=True)\n",
        "\n",
        "# Ensure labels are in the correct format (flattening nested lists)\n",
        "def format_labels(example):\n",
        "    example['labels'] = example['labels'][0] if isinstance(example['labels'], list) else example['labels']\n",
        "    return example\n",
        "\n",
        "eg_tokenized_datasets = eg_tokenized_datasets.map(format_labels)\n",
        "\n",
        "# Split the tokenized dataset into train and eval sets\n",
        "eg_train_test_split = eg_tokenized_datasets['train'].train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "small_train_dataset = eg_train_test_split[\"train\"].shuffle(seed=42)\n",
        "small_eval_dataset = eg_train_test_split[\"test\"].shuffle(seed=42)\n"
      ],
      "metadata": {
        "id": "Uwu98Het5Ah7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q7Jt3cafjAQ"
      },
      "source": [
        "If the code is correct, you should see something similar to the following output:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image02G.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdjfaGtYBpP_"
      },
      "source": [
        "### Example-Step 4: Create Custom Collator\n",
        "\n",
        "The code in the cell below creates a **custom collator**. The code defines a custom data collator that wraps the default HuggingFace collator. In particular the code ensures that the `labels` tensor has the right shape (i.e. a detached `torch.long` tensor). This shape is necessary to satisfy classification loss expectations.\n",
        "\n",
        "The code then loads a pre-trained **`DistilBERT`** encoder and attaches a classification head configured for 28 output classes. Together, they prepare batches with correct label types and a model ready for fine-tuning on a multi‑class sequence-classification task.\n",
        "\n",
        "The following code **_instantiates_** the `DistilBert` model.\n",
        "\n",
        "```text\n",
        "# Instantiate the model\n",
        "eg_model = DistilBertForSequenceClassification.from_pretrained(model_ckpt, num_labels=28)\n",
        "```\n",
        "This means that the model has been just been created but not trained.\n",
        "\n",
        "**NOTE:** The name of the `DistilBert` model is **`eg_model`**. The **eg_** prefix has been used to indicate that this is the model being used in the lesson examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example-Step 4: Create custom collator\n",
        "\n",
        "# Custom data collator to handle potential edge cases and address the warning\n",
        "def custom_data_collator(features):\n",
        "    batch = default_data_collator(features)\n",
        "    if \"labels\" in batch:\n",
        "        batch[\"labels\"] = batch[\"labels\"].clone().detach().long()\n",
        "    return batch\n",
        "\n",
        "# Instantiate the model with ignore_mismatched_sizes to suppress warnings\n",
        "eg_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    model_ckpt,\n",
        "    num_labels=28,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "Pz_8Eneen81q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouGvMdKGgAVV"
      },
      "source": [
        "If the code is correct, you should see something similar to the following output:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image03G.png)\n",
        "\n",
        "The warning you're seeing is actually expected and not an error. Here's what's happening:\n",
        "\n",
        "**UNEXPECTED keys:** These are from the pre-trained model's masked language modeling (MLM) head (vocab_transform, vocab_projector, vocab_layer_norm), which aren't needed for sequence classification.\n",
        "\n",
        "**MISSING keys:** These are the new classification layers (pre_classifier, classifier) that are randomly initialized because they don't exist in the base pre-trained model.\n",
        "\n",
        "This is normal behavior when loading a pre-trained model for a different task (fine-tuning)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------\n",
        "\n",
        "### **Hugging Face Trainer**\n",
        "\n",
        "The **Hugging‑Face `Trainer`** is a high‑level training engine that abstracts away the boilerplate of a typical deep‑learning training loop.\n",
        "\n",
        "It automatically handles data loading, batching, padding, and device placement, supports distributed or mixed‑precision training out of the box, and provides built-in strategies for checkpointing, evaluation, and early stopping.\n",
        "\n",
        "By passing a `TrainingArguments` object, you can control logging, learning‑rate scheduling, and which metrics to monitor for the best checkpoint. Because it integrates seamlessly with Hugging‑Face `datasets`, tokenizers, and the `accelerate` library, you can write a single, concise script that runs on a single GPU, multiple GPUs, or a TPU without any code changes.\n",
        "\n",
        "While you can always write a custom loop for maximum control, the `Trainer` saves time, reduces bugs, and makes experiments reproducible and easy to share, making it the go-to choice for most fine‑tuning and research workloads.\n",
        "\n",
        "----------------------------\n"
      ],
      "metadata": {
        "id": "x1majM94exTo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm6Xn6kiXhoD"
      },
      "source": [
        "### Example-Step 5: Define Model, Training Arguments, and Trainer\n",
        "\n",
        "The code in the cell below creates a trained called **`eg_trainer`**. This trainer is configured using the `TrainingArguments`. These training arguments tells **`eg_trainer`** to:\n",
        "1. run up to 5 epochs or 500 steps,\n",
        "2. use 8-sample batches\n",
        "3. use 500 warm-up steps\n",
        "4. use a weight decay = `0.01`\n",
        "5. log every `10` steps.\n",
        "6. perform checkpoints and evaluations every `50` steps\n",
        "7. save the best model is chosen based on the lowest evaluation loss.\n",
        "\n",
        "An `EarlyStoppingCallback` with a patience of `3` is added so training stops if the eval loss does not improve for three consecutive evaluations.\n",
        "\n",
        "Finally, out  `eg_trainer` is created with the pre-trained model, the train/eval datasets, the custom collator, and the early-stopping callback. In short, our `eg_trainer` is all set, just waiting to for the code signal to start training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "untm7OYWXhQa"
      },
      "outputs": [],
      "source": [
        "# Example-Step 5: Define model, training arguments and trainer\n",
        "\n",
        "# Define variables\n",
        "EPOCHS=5\n",
        "EVAL_STEPS=50\n",
        "MAX_STEPS=500\n",
        "SAVE_STEPS=50\n",
        "\n",
        "# Set up TrainingArguments with early stopping requirements\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=EPOCHS,\n",
        "    max_steps=MAX_STEPS,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    logging_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=SAVE_STEPS,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=EVAL_STEPS,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "# Create an early stopping callback\n",
        "PATIENCE = 3\n",
        "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=PATIENCE)\n",
        "\n",
        "eg_trainer = Trainer(\n",
        "    model=eg_model,     # Important to assign model name\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    data_collator=custom_data_collator,\n",
        "    callbacks=[early_stopping_callback]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNQwSgiLgG1E"
      },
      "source": [
        "If the code is correct, you should _not_ see any output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcjGkVDxXrPK"
      },
      "source": [
        "### Example-Step 6: Train the Model and Save the Best Model\n",
        "\n",
        "The code in the cell below runs the full training loop for our **`eg_ model`** that has been wrapped in a Hugging-Face Trainer, **`eg_trainer`**.\n",
        "\n",
        "After training, the code writes out the best-performing checkpoint (i.e. the model that achieved the lowest validation loss / highest metric to a folder called `./eg_best_model`.\n",
        "\n",
        "This saves the tokenizer used during training to the same folder so you can later load the entire inference pipeline from that single directory.\n",
        "\n",
        "Since the model, **`eg_trainer`** is fairly large the next cell will require some time to finish training.\n",
        "\n",
        "**NOTE:** Make sure you have run the `Install Custom Function` cell at the start of the lesson or you will receive an error message!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq6NAcRvXq5C"
      },
      "outputs": [],
      "source": [
        "# Example-Step 6: Train the model and save the best model\n",
        "\n",
        "# Record start time\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"-----Starting Training-----------------------\")\n",
        "# Train the model\n",
        "eg_trainer.train()\n",
        "print(\"-----Training Done---------------------------\")\n",
        "\n",
        "# Save the best model\n",
        "best_model_dir = './eg_best_model'\n",
        "eg_trainer.save_model(best_model_dir)\n",
        "\n",
        "# Save tokenizer to the same directory\n",
        "tokenizer.save_pretrained(best_model_dir)\n",
        "\n",
        "# Record end time\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Print elapsed time\n",
        "print(f\"Elapsed time: {hms_string(elapsed_time)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv7bG2fpgmpK"
      },
      "source": [
        "If the code is correct, you should see something similar to the following output:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image12G.png)\n",
        "\n",
        "Even with the `A100` GPU hardware accelerator is took more than 6 minutes to complete training of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAZNJgMj7omt"
      },
      "source": [
        "**NOTE:** If your code generated this error message\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image07A.png)\n",
        "\n",
        "it means that you failed to run the code cell called **Install Custom Function** at the beginning of this lesson."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOlqUCDiKLw_"
      },
      "source": [
        "### Example-Step 7: Compute Accuracy Score\n",
        "\n",
        "The code in the cell below evaluates our model **`eg_trainer`** on a `hold-out set`. The **hold-out** set (also called a **test set**) is a small portion of our dataset that that was set aside before training your neural network.\n",
        "\n",
        "It important that the `hold-out` set is _never_ shown to the model during learning (nor to any hyper‑parameter tuning step). After training is done, the `hold-out` set fed into the model and a record is made of the model's predictions. The difference between these predictions and the true labels, gives an _unbiased estimate_ of the model's generalization accuracy.\n",
        "\n",
        "The code in the cell below uses a the function called `trainer.evaluate()` to get metrics (e.g., loss, accuracy) from the trained model. The code prints out each metric, and then obtains raw predictions via `trainer.predict`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8dZPyb1hLnf"
      },
      "outputs": [],
      "source": [
        "# Example-Step 7: Compute Accuracy Score\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluate the model on the evaluation dataset\n",
        "eval_results = eg_trainer.evaluate()\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"Evaluation results:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "# Get the predictions and true labels\n",
        "predictions, labels, _ = eg_trainer.predict(small_eval_dataset)\n",
        "\n",
        "# Convert predictions to label IDs\n",
        "predictions = torch.tensor(predictions)\n",
        "predictions = torch.argmax(predictions, dim=-1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf7p94XSijNM"
      },
      "source": [
        "If the code is correct, you should see something similar to the following output:\n",
        "```text\n",
        "Evaluation results:\n",
        "eval_loss: 1.9214\n",
        "eval_runtime: 34.2448\n",
        "eval_samples_per_second: 253.5270\n",
        "eval_steps_per_second: 31.7130\n",
        "epoch: 0.1152\n",
        "Accuracy: 0.4733\n",
        "```\n",
        "\n",
        "An accuracy of **< 0.50** indicates that the model correctly classifies less than half of the examples in the evaluation set.\n",
        "\n",
        "However, if the `eg_model` had just guessed randomly among 28 possible classes, it would be correct about 1 out of every 28 times. That's 1/28 = 0.0357, or roughly 3.6% accuracy. Since the model achieved ~47% accuracy, this is significantly better than the 3.6% random baseline.\n",
        "\n",
        "The model has clearly learned something meaningful from the training data—it's performing about 13 times better than random guessing (47% vs 3.6%). However, 47% still means it's wrong more than half the time, so there's substantial room for improvement.\n",
        "\n",
        "In practice this means:\n",
        "\n",
        "* The model is **under‑performing** relative to what one would hope for a well-tuned classifier in a biomedical setting.  \n",
        "* Possible reasons include insufficient training data, sub‑optimal hyper-parameters, or a model architecture that isn’t expressive enough for the task.  \n",
        "* Improving data quality, adding domain‑specific pre-training, fine-tuning longer, or experimenting with more powerful variants (e.g., `BioBERT`) could raise the score.\n",
        "\n",
        "In short, the model shows *positive* signal but still has significant room for improvement.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------\n",
        "\n",
        "## **Importance of Inference Using Trained Models**\n",
        "\n",
        "**Inference** is a critical phase in the machine learning lifecycle. It refers to the process of using a **trained model** to make predictions on **new, unseen data**. While training involves learning patterns from historical data, inference is where the model demonstrates its practical utility.\n",
        "\n",
        "#### **Why Inference Matters**\n",
        "\n",
        "- **Real-World Application**: Inference allows models to be deployed in real-world scenarios, such as diagnosing diseases, recommending products, detecting fraud, or translating languages.\n",
        "- **Performance Validation**: It helps validate how well the model generalizes beyond the training data. This is essential for assessing the model's reliability and robustness.\n",
        "- **Decision Support**: Inference outputs are often used to support or automate decision-making processes in various domains like healthcare, finance, and engineering.\n",
        "- **Efficiency and Speed**: Optimizing inference is crucial for applications requiring real-time predictions, such as autonomous vehicles or voice assistants.\n",
        "\n",
        "##### **Summary**\n",
        "\n",
        "Inference is the bridge between model development and real-world impact. It transforms a trained model from a theoretical construct into a practical tool that can generate insights, automate tasks, and solve complex problems in diverse domains.\n",
        "\n",
        "--------------------------"
      ],
      "metadata": {
        "id": "pTXbP3X6J-_d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uaYByy1gqwJ"
      },
      "source": [
        "### Example-Step 8: Perform Inference Using Trained Model\n",
        "\n",
        "The code in the cell below performs **`Inference`** on our **best trained** version of our **`eg_model`** that was stored in the directory **'./eg_best_model'**. The code loads the previously-saved tokenizer from the same directory.\n",
        "\n",
        "To get some idea how well our **`eg_model`** learned to evaluate the emotions expressed short text sentences, the code feeds `6` test sentences into our trained model for evaluation. Finally it prints out each sentence along with the model's prediction of its emotional category.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2S98902i_gJ"
      },
      "outputs": [],
      "source": [
        "# Example-Step 8: Perform Inference Using Trained Model\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "# Load the tokenizer and the model from the saved directory\n",
        "best_model_dir = './eg_best_model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(best_model_dir)\n",
        "eg_model = DistilBertForSequenceClassification.from_pretrained(best_model_dir)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "eg_model.eval()\n",
        "\n",
        "# Define the sentences to test\n",
        "sentences = [\n",
        "    \"I am feeling very happy today!\",\n",
        "    \"This is the worst day of my life.\",\n",
        "    \"I am so excited about the new project.\",\n",
        "    \"I feel sad and lonely.\",\n",
        "    \"I'm feeling very anxious about the presentation.\",\n",
        "    \"This news makes me extremely joyful.\"\n",
        "]\n",
        "\n",
        "# Tokenize the sentences\n",
        "inputs = tokenizer(sentences, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Get the model's predictions\n",
        "with torch.no_grad():\n",
        "    outputs = eg_model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "# Define the mapping of label IDs to emotions (based on the dataset's label mapping)\n",
        "label_mapping = {\n",
        "    0: \"sadness\",\n",
        "    1: \"joy\",\n",
        "    2: \"love\",\n",
        "    3: \"anger\",\n",
        "    4: \"fear\",\n",
        "    5: \"surprise\",\n",
        "    6: \"neutral\",\n",
        "    7: \"admiration\",\n",
        "    8: \"amusement\",\n",
        "    9: \"approval\",\n",
        "    10: \"caring\",\n",
        "    11: \"confusion\",\n",
        "    12: \"curiosity\",\n",
        "    13: \"desire\",\n",
        "    14: \"disappointment\",\n",
        "    15: \"disapproval\",\n",
        "    16: \"embarrassment\",\n",
        "    17: \"excitement\",\n",
        "    18: \"gratitude\",\n",
        "    19: \"grief\",\n",
        "    20: \"love\",\n",
        "    21: \"nervousness\",\n",
        "    22: \"pride\",\n",
        "    23: \"realization\",\n",
        "    24: \"relief\",\n",
        "    25: \"remorse\",\n",
        "    26: \"sadness\",\n",
        "    27: \"surprise\"\n",
        "}\n",
        "\n",
        "# Print the predicted emotions for each sentence\n",
        "for sentence, pred in zip(sentences, predictions):\n",
        "    emotion = label_mapping[pred.item()]\n",
        "    print(f\"Sentence: '{sentence}'\\nPredicted Emotion: {emotion}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY8-W3wVNRMW"
      },
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image13G.png)\n",
        "\n",
        "Because the model achieved only 45% accuracy on the validation set, these results are not surprising: the classifier appears to have learned a very weak signal that is heavily biased toward the “remorse” class (and in a few cases confuses gratitude with sadness or joy).  \n",
        "\n",
        "In practice this indicates a mismatch between the training labels and the mapping used for inference (the label-index table contains duplicate entries such as 0/26 for *sadness* and 2/20 for *love*), a possible class-imbalance issue, or simply insufficient training data/hyper-parameter tuning.  \n",
        "\n",
        "The output therefore suggests that the model is unreliable for production use and should be retrained (or a different architecture or domain-specific pre‑training applied) before it can be trusted to interpret emotion from text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gkrwpOpOsTR"
      },
      "source": [
        "## **Exercise**\n",
        "\n",
        "For the **Exercise**, you are to repeat the 8 steps demonstrated in the Example _but_ using a different Hugging Face dataset, the `cardiffnlp/tweet_eval-Irony Subset`\n",
        "\n",
        "The **CardiffNLP TweetEval-Irony Subset** is a **TweetEval** benchmark, developed by `CardiffNLP`, provides a unified framework for evaluating models on various `Twitter-based` classification tasks.\n",
        "\n",
        "Among its seven tasks, the **Irony Detection** subset is particularly notable for its focus on identifying ironic content in tweets. Irony is notoriously difficult for machines—and even humans—to detect accurately.\n",
        "\n",
        "Irony is a complex linguistic phenomenon where the intended meaning of a statement is often the **opposite** of its literal meaning. This makes it particularly challenging for machine learning models and natural language processing systems to interpret correctly.\n",
        "\n",
        "#### **Key Challenges in Irony Detection**\n",
        "\n",
        "###### **1. Context Dependence**\n",
        "Irony often relies heavily on **context**, including cultural references, prior knowledge, or the situation in which the statement is made. Without this context, the literal words may be misleading.\n",
        "\n",
        "> Example: \"Oh great, another Monday!\"  \n",
        "> Without context, this could be interpreted as positive, but it's likely ironic.\n",
        "\n",
        "###### **2. Subtlety and Ambiguity**\n",
        "Irony is frequently subtle and can be easily confused with sarcasm, humor, or even genuine sentiment. The lack of clear linguistic markers makes it hard to distinguish.\n",
        "\n",
        "###### **3. Lack of Prosody and Tone**\n",
        "In spoken language, irony is often conveyed through **tone of voice**, facial expressions, or gestures. In text (especially tweets), these cues are missing, making detection much harder.\n",
        "\n",
        "###### **4. Short and Informal Texts**\n",
        "Social media platforms like `Twitter` encourage brevity and informal language. This limits the amount of information available for models to interpret irony accurately.\n",
        "\n",
        "###### **5. Creative Language Use**\n",
        "Users often employ slang, emojis, hashtags, and unconventional grammar to express irony. These creative elements can confuse models trained on more formal or structured data.\n",
        "\n",
        "###### **Implications for NLP**\n",
        "\n",
        "Detecting irony is essential for improving the accuracy of:\n",
        "- **Sentiment analysis**\n",
        "- **Emotion detection**\n",
        "- **Content moderation**\n",
        "- **Social media monitoring**\n",
        "\n",
        "Models that fail to detect irony may misclassify negative sentiment as positive (or vice versa), leading to flawed insights and decisions.\n",
        "\n",
        "##### **Summary**\n",
        "\n",
        "Irony detection remains a challenging task in NLP due to its reliance on context, subtlety, and the absence of non-verbal cues. Advances in deep learning and contextual embeddings (like BERT and RoBERTa) have improved performance, but there's still significant room for growth in this area.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1-KoyVXQWiN"
      },
      "source": [
        "### **Exercise-Step 1: Load Dataset**\n",
        "\n",
        "In the cell below write the code to load the dataset. Use the following code for loading:\n",
        "\n",
        "```text\n",
        "# Load dataset\n",
        "irony_dataset = load_dataset(\"cardiffnlp/tweet_eval\", \"irony\")\n",
        "```\n",
        "This will create a variable called `irony_dataset` that you will use for **Exercise 1**.\n",
        "\n",
        "You should also load the several libraries that you will be using later."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise-Step 1 here\n",
        "\n"
      ],
      "metadata": {
        "id": "GDPVsnSgMq5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHqhynrAQWiO"
      },
      "source": [
        "If the code is correct, you should see something similar to the following output:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image07G.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxtoLei7r6og"
      },
      "source": [
        "### **Exercise-Step 2: Print Examples**\n",
        "\n",
        "In the next cell, write the code to prints out the column names in your `irony_dataset` since you will need to know exactly what the column names are for later steps in the analysis.\n",
        "\n",
        "After you print the column names print the text and the label from record number `2`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise-Step 2\n"
      ],
      "metadata": {
        "id": "A0jyQq2Z0lp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "```text\n",
        "Dataset column names: {'train': ['text', 'label'], 'test': ['text', 'label'], 'validation': ['text', 'label']}\n",
        "Record 2 text: Now I remember why I buy books online @user #servicewithasmile\n",
        "Record 2 label: 1\n",
        "```\n",
        "\n",
        "Since the Label = **1** for record = 2, this `tweet` is considered **ironic**."
      ],
      "metadata": {
        "id": "aSEgDNpqsi-d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL7zgR6GQWiO"
      },
      "source": [
        "### **Exercise-Step 3: Tokenize and Format the Dataset**\n",
        "\n",
        "In the cell below write the code to tokenize and format your `irony_dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise-Step 3\n",
        "\n"
      ],
      "metadata": {
        "id": "tmJcUZ-nDdB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMItfPe8QWiP"
      },
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image09G.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWgStO8NQWiP"
      },
      "source": [
        "### **Exercise-Step 4: Create Custom Collator**\n",
        "\n",
        "In the cell below create a **custom collator**. You can re-use the code in Example 1 - Step 4 with the following exception. When you _instantiate_ your model, make sure to call your model **`ex_model`**. The prefix **`ex_`** signifies that this is the model that you will be using in the lesson's **Exercise**.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMuyAqiJQWiP"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise-Step 4 here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmkFxB6bQWiP"
      },
      "source": [
        "If the code is correct, you should see something similar to the following output:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image08G.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdiy0wgSQWiP"
      },
      "source": [
        "### **Exercise-Step 5: Define Model, Training Arguments, and Trainer**\n",
        "\n",
        "In the cell below write the code to define your model, **`ex_model`** with `TrainingArguments`.\n",
        "\n",
        "You can simply re-use all of the code in Example 1 - Step 5 with the following modifications:\n",
        "\n",
        "1. Change the name of your trainer from  `eg_trainer` to  **`ex_trainer`**.\n",
        "2. Change the name of your model from  `eg_model` to  **`ex_model`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FK7mqNoQWiP"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise-Step 5 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvUAMnlhQWiP"
      },
      "source": [
        "If the code is correct, you should not see any output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPBiHBPlQWiP"
      },
      "source": [
        "### **Exercise-Step 6: Train the Model and Save the Best Model**\n",
        "\n",
        "In the cell below write the code to train your `ex_trainer`.\n",
        "\n",
        "You can re-use all of the in Example 1 - Step 6 with the following modifications:\n",
        "\n",
        "1. Make sure you are training your `ex_trainer` model.\n",
        "2. Change the name of the `best_model_dir` to './ex_best_model'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6BBHL5nQWiQ"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise-Step 6 here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPUaAjePQWiQ"
      },
      "source": [
        "If the code is correct, you should see something _similar_ to the following output:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image10G.png)\n",
        "\n",
        "Using the `A100` GPU hardware accelerator training required less than 2 minutes to complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-0-RzgxQWiQ"
      },
      "source": [
        "### **Exercise-Step 7: Compute Accuracy Score**\n",
        "\n",
        "In the cell below write the code to compute the accuracy score of your `ex_trainer`. (Remember, `ex_trainer` is basically your `ex_model` \"wrapped\" in some extra code.)\n",
        "\n",
        "Make sure to change\n",
        "\n",
        "1. `eg_trainer.evaluate()` to read **`ex_trainer.evaluate()`**.\n",
        "2. `eg_trainer.predict()` to read **`ex_trainer.predict()`**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziUb2MByQWiQ"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise-Step 6 here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUn5oUFyQWiQ"
      },
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "```text\n",
        "Evaluation results:\n",
        "eval_loss: 0.5910\n",
        "eval_runtime: 2.2883\n",
        "eval_samples_per_second: 250.4070\n",
        "eval_steps_per_second: 31.4650\n",
        "epoch: 1.7422\n",
        "Accuracy: 0.6684\n",
        "```\n",
        "An accuracy of **~0.67** indicates that the model correctly classifies roughly 70% of the examples in the evaluation set.  This is much better accuracy compared to `emotions_dataset` in the Example.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtZ3D4m5QWiQ"
      },
      "source": [
        "### **Exercise-Step 8: Perform Inference Using Trained Model**\n",
        "\n",
        "In the cell below write the code to perform Inference on your best model,**`ex_model`**, that was store in the directory './ex_best_model'.\n",
        "\n",
        "Make sure to set your model to evaluation mode using the following code:\n",
        "```text\n",
        "# Set the model to evaluation mode\n",
        "ex_model.eval()\n",
        "```\n",
        "You can copy-and-paste this code into your cell to create the tweets to analyze:\n",
        "\n",
        "```text\n",
        "# Define the sentences to test\n",
        "sentences = [\n",
        "    \"Mens Football clearly know how to have a good time.....  #archiesday #anychanceofasocial\", # Ironic\n",
        "    \"What an amazing start to the weekend!  #ohgoditsfridayagain\",                              # Ironic\n",
        "    \"my favorite thing to do on Tuesday is write psychology papers😐  #killme\",                 # Ironic\n",
        "    \"Last day in #Riga! #self #finnishgirl #businesswoman  @ PK Riga Hotel\",                     # Not ironic\n",
        "    \"Can't wait until this weekend is over...then no more Xmas parties!!!!!! #HateSchmoozing\",   # Not ironic\n",
        "    \"How to know when he really loves you. #tmi #imsorry #chickfila\",                            # Not ironic\n",
        "]\n",
        "```\n",
        "\n",
        "These tweets were taken from the `hold-out` (validation) set.\n",
        "\n",
        "Finally, use this code for mapping your responses:\n",
        "```text\n",
        "# Define the mapping of label IDs to emotions (based on the dataset's label mapping)\n",
        "label_mapping = {\n",
        "    0: \"Not ironic\",\n",
        "    1: \"Ironic\",\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsEcdsC-QWiQ"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 1-Step 8 here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skCUSIx_QWiQ"
      },
      "source": [
        "If the code is correct you should see something similar to the following output:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image11G.png)\n",
        "\n",
        "Predicting what is, or is not ironic isn't easy!\n",
        "\n",
        "The first 3 tweets were labeled as being **ironic** while the last 3 tweets were labeled **not ironic**. Based on this small sample, your trained `ex_model` didn't do all that well.   \n",
        "\n",
        "```type\n",
        "Sentence: 'Mens Football clearly know how to have a good time.....  #archiesday #anychanceofasocial'\n",
        "Predicted Irony: Ironic\n",
        "\n",
        "Sentence: 'What an amazing start to the weekend!  #ohgoditsfridayagain'\n",
        "Predicted Irony: Ironic\n",
        "\n",
        "Sentence: 'my favorite thing to do on Tuesday is write psychology papers😐  #killme'\n",
        "Predicted Irony: Not ironic\n",
        "\n",
        "Sentence: 'Last day in #Riga! #self #finnishgirl #businesswoman  @ PK Riga Hotel'\n",
        "Predicted Irony: Not ironic\n",
        "\n",
        "Sentence: 'Can't wait until this weekend is over...then no more Xmas parties!!!!!! #HateSchmoozing'\n",
        "Predicted Irony: Ironic\n",
        "\n",
        "Sentence: 'How to know when he really loves you. #tmi #imsorry #chickfila'\n",
        "Predicted Irony: Ironic\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx2GceWzUO7t"
      },
      "source": [
        "## **Lesson Turn-in**\n",
        "\n",
        "When you have completed and run all of the code cells,use the **File --> Print.. --> Microsoft Print to PDF** to generate a PDF of your Colab notebook if you are using Windows; use the **File --> Print.. --> Save to PDF** to generate a PDF of your Colab notebook if you are using a Mac. Name your PDF as `Class_05_4.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdwccJ0TUQ81"
      },
      "source": [
        "## **Lizard Tail**\n",
        "\n",
        "## **Lotus 1-2-3**\n",
        "\n",
        "![__](https://upload.wikimedia.org/wikipedia/commons/0/02/Lotus-123-3.0-MSDOS.png)\n",
        "\n",
        "**Lotus 1-2-3** is a discontinued spreadsheet program from Lotus Software (later part of IBM). It was the first killer application of the IBM PC, was hugely popular in the 1980s, and significantly contributed to the success of IBM PC-compatibles in the business market.\n",
        "\n",
        "The first spreadsheet, VisiCalc, had helped launch the Apple II as one of the earliest personal computers in business use. With IBM's entry into the market, VisiCalc was slow to respond, and when they did, they launched what was essentially a straight port of their existing system despite the greatly expanded hardware capabilities. Lotus's solution was marketed as a three-in-one integrated solution: it handled spreadsheet calculations, database functionality, and graphical charts, hence the name \"1-2-3\", though how much database capability the product actually had was debatable, given the sparse memory left over after launching 1-2-3. It quickly overtook VisiCalc, as well as Multiplan and SuperCalc, the two VisiCalc competitors.\n",
        "\n",
        "Lotus 1-2-3 was the state-of-the-art spreadsheet and the standard throughout the 1980s and into the early 1990s, part of an unofficial set of three stand-alone office automation products that included dBase and WordPerfect, to build a complete business platform. Lotus Software had their own word processor named Lotus Manuscript, which was to some extent acclaimed in academia, but did not catch the interest of the business, nor the consumer market. With the acceptance of Windows 3.0 in 1990, the market for desktop software grew even more. None of the major spreadsheet developers had seriously considered the graphical user interface (GUI) to supplement their DOS offerings, and so they responded slowly to Microsoft's own GUI-based products Excel and Word. Lotus was surpassed by Microsoft in the early 1990s, and never recovered. IBM purchased Lotus in 1995, and continued to sell Lotus offerings, only officially ending sales in 2013.\n",
        "\n",
        "### **History**\n",
        "\n",
        "**VisiCalc**\n",
        "\n",
        "VisiCalc was launched in 1979 on the Apple II and immediately became a best-seller. Compared to earlier programs, VisiCalc allowed one to easily construct free-form calculation systems for practically any purpose, the limitations being primarily related to the memory and speed of the computer. The application was so compelling that there were numerous stories of people buying Apple II machines to run the program (see article Killer application). VisiCalc's runaway success on the Apple led to direct bug compatible ports to other platforms, including the Atari 8-bit computers, Commodore PET and many others. This included the IBM PC when it launched in 1981, where it quickly became another best-seller, with an estimated 300,000 sales in the first six months on the market.\n",
        "\n",
        "There were well-known problems with VisiCalc, and several competitors appeared to address some of these issues. One early example was 1980's SuperCalc, which solved the problem of circular references, while a slightly later example was Microsoft Multiplan from 1981, which offered larger sheets and other improvements. In spite of these, and others, VisiCalc continued to outsell them all.\n",
        "\n",
        "**Beginnings**\n",
        "\n",
        "The Lotus Development Corporation was founded by Mitchell Kapor, a friend of the developers of VisiCalc. 1-2-3 was originally written by Jonathan Sachs, who had written two spreadsheet programs previously while working at Concentric Data Systems, Inc. To aid its growth both in the UK and possibly elsewhere, Lotus 1-2-3 became the very first computer software to use television consumer advertising.\n",
        "\n",
        "Kapor was primarily a marketing guru. His ability to develop his product to appeal to non-technical users was one secret to its rapid success. Unlike many technologists, Kapor relied on focus group feedback to make his user instructions more user-friendly. One example: the instructions that came with the floppy disc read: \"Remove the protective cover and insert disc into computer.\" A few focus group participants tried to rip-off the stiff plastic envelope of disc carrier. Kapor's recognition that techno-speak instructions needed to be translated to normative English was a strong contributor to the product's popularity.\n",
        "\n",
        "Lotus 1-2-3 was released on 26 January 1983, and immediately overtook Visicalc in sales. Unlike Microsoft Multiplan, it stayed very close to the model of VisiCalc, including the \"A1\" letter and number cell notation, and slash-menu structure. It was cleanly programmed, relatively bug-free, gained speed from being written completely in x86 assembly language (this remained the case for all DOS versions until 3.0, when Lotus switched to C[9]) and wrote directly to video memory rather than use the slow DOS and/or BIOS text output functions.\n",
        "\n",
        "Among other novelties that Lotus introduced was a graph maker that could display several forms of graphs (including pie charts, bar graphics, or line charts) but required the user to have a graphics card. At this early stage, the only video boards available for the PC were IBM's Color Graphics Adapter and Monochrome Display and Printer Adapter, the latter not supporting any graphics. However, because the two video boards used different RAM and port addresses, both could be installed in the same machine and so Lotus took advantage of this by supporting a \"split\" screen mode whereby the user could display the worksheet portion of 1-2-3 on the sharper monochrome video and the graphics on the CGA display.\n",
        "\n",
        "The initial release of 1-2-3 supported only three video setups: CGA, MDA (in which case the graph maker was not available) or dual-monitor mode. However, a few months later support was added for Hercules Computer Technology's Hercules Graphics Adapter which was a clone of the MDA that allowed bitmap mode. The ability to have high-resolution text and graphics capabilities (at the expense of color) proved extremely popular and Lotus 1-2-3 is credited with popularizing the Hercules graphics card.\n",
        "\n",
        "Subsequent releases of Lotus 1-2-3 supported more video standards as time went on, including EGA, AT&T/Olivetti, and VGA. Significantly, support for the PCjr/Tandy modes was never added and users of those machines were limited to CGA graphics.\n",
        "\n",
        "The early versions of 1-2-3 also had a key disk copy protection. While the program was hard disk installable, the user had to insert the original floppy disk when starting 1-2-3 up. This protection scheme was easily cracked and a minor inconvenience for home users, but proved a serious nuisance in an office setting. Starting with Release 3.0, Lotus no longer used copy protection. However, it was then necessary to \"initialize\" the System disk with one's name and company name so as to customize the copy of the program. Release 2.2 and higher had this requirement. This was an irreversible process unless one had made an exact copy of the original disk so as to be able to change names to transfer the program to someone else.\n",
        "\n",
        "The reliance on the specific hardware of the IBM PC led to 1-2-3 being utilized as one of the two stress test applications, along with Microsoft Flight Simulator, for true 100% compatibility when PC clones appeared in the early 1980s. 1-2-3 required two disk drives and at least 192K of memory, which made it incompatible with the IBM PCjr; Lotus produced a version for the PCjr that was on two cartridges but otherwise identical.\n",
        "\n",
        "By early 1984 the software was a killer app for the IBM PC and compatibles, while hurting sales of computers that could not run it. \"They're looking for 1-2-3. Boy, are they looking for 1-2-3!\" InfoWorld wrote. Noting that computer purchasers did not want PC compatibility as much as compatibility with certain PC software, the magazine suggested \"let's tell it like it is. Let's not say 'PC compatible,' or even 'MS-DOS compatible.' Instead, let's say '1-2-3 compatible.'\" PC clones' advertising did often prominently state that they were compatible with 1-2-3. An Apple II software company promised that its spreadsheet had \"the power of 1-2-3\". Because spreadsheets use large amounts of memory, 1‐2‐3 helped popularize greater RAM capacities in PCs, and especially the advent of expanded memory, which allowed greater than 640k to be accessed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWIsyF5AWw6p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP1Y6ixo+OLcTslVJPJGHia",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}