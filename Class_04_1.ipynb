{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEEW13uCtiJ"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/master/Class_04_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BIO 1173: Intro Computational Biology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Module 4: Training for Tabular Data**\n",
    "\n",
    "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
    "\n",
    "### Module 4 Material\n",
    "\n",
    "* **Part 4.1: Encoding a Feature Vector for Keras Deep Learning**\n",
    "* Part 4.2: Keras Multiclass Classification for Deep Neural Networks with ROC and AUC\n",
    "* Part 4.3: Keras Regression for Deep Neural Networks with RMSE\n",
    "* Part 4.4: Backpropagation, Nesterov Momentum, and ADAM Neural Network Training\n",
    "* Part 4.5: Neural Network RMSE and Log Loss Error Calculation from Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKQylnEiLDUM"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n",
    "  Running the following code will map your GDrive to ```/content/drive```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seXFCYH4LDUM",
    "outputId": "c05015aa-871e-4779-9265-5ad07e8bf617"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Setup\n",
    "\n",
    "Run the next code cell to load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You MUST run this code cell first\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "path = '/'\n",
    "memory = shutil.disk_usage(path)\n",
    "dirpath = os.getcwd()\n",
    "print(\"Your current working directory is : \" + dirpath)\n",
    "print(\"Disk\", memory)\n",
    "print(\"Numpy version =\", (np.__version__)) \n",
    "print(\"Tensorflow version =\", (tf.__version__))\n",
    "print(\"Available GPU acceleration =\", tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4.1: Encoding a Feature Vector for Keras Deep Learning\n",
    "\n",
    "Neural networks can accept many types of data. We will begin with tabular data, where there are well-defined rows and columns. This data is what you would typically see in Microsoft Excel spreadsheet.\n",
    "\n",
    "Neural networks require numeric input. This numeric form is called a **_feature vector_**. Each input neurons receive one feature (or column) from this vector. Each row of training data typically becomes one vector. \n",
    "\n",
    "In this lesson, we will focus on how to encode **_tabular data_** stored in a Pandas DataFrame into a feature vector that can be used by two types of neural networks, classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Read dataset and store values in a DataFrame\n",
    "\n",
    "The code in the cell below reads the Apple Quality dataset file, `apple_quality.csv`, located on the course HTTPS server [https://corgi.genomelab.utsa.edu](https://corgi.genomelab.utsa.edu). If you are working off campus, and you can't download the dataset, you will need to run the UTSA Virtual Private Network (vip.utsa.edu) in order to access this file.\n",
    "\n",
    "The code in the cell below uses the Pandas function `pd.read_csv()` to read the read data file over the internet. The argument for `pd.read_csv()`, includes the URL for server as well as the filepath and the filename of the data file. As the dataset is read, it is saved to a new DataFrame called `aqDF`. \n",
    "\n",
    "The code then sets the maximum number of rows to 6 and the maximum number of columns to 0, before displaying the DataFrame. Setting the maximum columns (or rows) to `0` means to display **all** columns, even if it means the output extends past the edge of the notebook.\n",
    "\n",
    "**WARNING:** Be careful **NEVER** set the maximum number of rows to `0`. Most datasets, especially the ones used in this course have hundreds or even thousands of rows. If you set `max_rows = 0`, you will end up with page-after-page of screen output! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Read dataset and store values in a DataFrame\n",
    "\n",
    "# Read in data and create DataFrame\n",
    "aqDF = pd.read_csv(\n",
    "    \"https://corgi.genomelab.utsa.edu/BIO1173/Datasets/apple_quality.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "# Set the max rows and columns\n",
    "pd.set_option('display.max_rows', 6) # NEVER set max_rows to 0\n",
    "pd.set_option('display.max_columns', 0) # 0 displays all the columns\n",
    "\n",
    "# Display the DataFrame\n",
    "display(aqDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following table.\n",
    "\n",
    "![___](https://corgi.genomelab.utsa.edu/BIO1173/images/Class_04_1_Table1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should make the following observations from the above tabular data:\n",
    "* The target column is the column that you seek to predict. By convention, the rightmost column is usually the target column, or _response variable_. In this DataFrame the target column is `Quality`.   \n",
    "* There is an `A_id` column. We should exclude this column from our analysis because it contains no information useful for making a prediction.\n",
    "* Many of these fields are numeric and might not require further processing.\n",
    "* Categorical values (strings) only found in the target column (`Quality`). Values in the target column do **not** need to be One-Hot Encoded until later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1: Read dataset and store values in a DataFrame**\n",
    "\n",
    "In the cell below, use the Pandas function `pd.read_csv()` to read the Heart Disease dataset file, `heart_disease.csv`, located on the course HTTPS server [https://corgi.genomelab.utsa.edu](https://corgi.genomelab.utsa.edu). If you are working off campus, you may need to be running the UTSA Virtual Private Network (vip.utsa.edu) in order to access this file.\n",
    "\n",
    "Set the display for 8 rows and **all** of the columns print out display of `hfDF`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following table.\n",
    "\n",
    "![Heart Failure DataFrame](https://corgi.genomelab.utsa.edu/BIO1173/images/Class_04_1_Table2.png \"Tabular Data Example\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should make the following observations from the above tabular data:\n",
    "* The target column is the column that you usually want to predict with a classification neural network. As above, the rightmost column, `HeartDisease`, would be the usual target column. \n",
    "* The column `FastingBS` doesn't appear to contain information that would be especially useful for predicting heart disease so it will be dropped. \n",
    "* Some fields are numeric and might not require further processing.\n",
    "* There are categorical values in 5 columns including: `Sex`, `ChestPainType`, `RestingECG`, `ExerciseAngina` and `ST_Slope`. The categorical values (strings) in these columns will need to be One-Hot Encoded before they can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Drop unecessary columns\n",
    "\n",
    "Since the column `A_id` in the Apple Quality dataset doesn't contain information that will be useful for predicting fruit quality, this column should not be included in the analysis. The code below uses the Pandas `pd.drop()` method to eliminate this column from the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 2: Drop unecesary columns \n",
    "\n",
    "# Drop the A_id column \n",
    "aqDF.drop('A_id', axis=1, inplace=True)\n",
    "\n",
    "# Set the max rows and max columns\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 8)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(aqDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you code is correct you should see the following table:\n",
    "\n",
    "![__](https://corgi.genomelab.utsa.edu/BIO1173/images/class_04_1_Exam2.png)\n",
    "\n",
    "You should note that the column `A_id` has been removed. Instead of the original 9 columns, there are now only 8 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2: Drop unecessary columns**\n",
    "\n",
    "Since the column `FastingBS` in the Heart Disease dataset doesn't contain information that will be especially useful for predicting heart disease, this column should not be included in the analysis. In the cell below, write the code to drop this column. Display 8 rows and 8 columns of your updated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: One-Hot encode categorical variables\n",
    "\n",
    "The Heart Failure dataset has 5 columns that have categorical variables (strings): Sex, ChestPainType, RestingECG, ExerciseAngina and ST_Slope. Example 3 illustrates how to One-Hot encode these categorical variables in one column `Sex`.\n",
    "\n",
    "The following line of code uses the Pandas function, `pd.get_dummies()` to One-Hot encode the string values in the `Sex` column and turn them into the integer values `0` and `1`. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get dummy values\n",
    "dummies = pd.get_dummies(hdDF['Sex'],prefix=\"Sex\", dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you created the dummies, you must complete two more steps. First, you need to use the Pandas `pd.concat()` function to **_add_** the dummies to your DataFrame. The line of code that accomplishes this is:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Add the dummies into the DataFrame\n",
    "hdDF = pd.concat([hdDF,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data in the column has been replaced by the dummy values, the next step is to **_drop_** the column containing the strings from the DataFrame. The line of code that does this is:  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Drop the column replaced by the dummies\n",
    "hdDF.drop('Sex', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code then sets the max rows and max columns to `8` and displays the contents of the updated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 3: One-Hot encode categorical variables\n",
    "\n",
    "# Get dummy values\n",
    "dummies = pd.get_dummies(hdDF['Sex'],prefix=\"Sex\", dtype=int)\n",
    "\n",
    "# Add the dummies into the DataFrame\n",
    "hdDF = pd.concat([hdDF,dummies],axis=1)\n",
    "\n",
    "# Drop the column replaced by the dummies\n",
    "hdDF.drop('Sex', axis=1, inplace=True)\n",
    "\n",
    "# Set the max rows and max columns\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 8)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(hdDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following table.\n",
    "\n",
    "![__](https://corgi.genomelab.utsa.edu/BIO1173/images/class_04_1_Ex3A.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3: One-Hot encode categorical values**\n",
    "\n",
    "Example 3 above, illustrated how to One-Hot encode the column, `Sex`, in the Heart Disease DataFrame, `hdDF`. For **Exercise 3** you will need to  One-Hot encode the remaining 4 columns, `ChestPainType`, `RestingECG`, `ExerciseAngina` and `ST_Slope`. For your convience, this exercise will be broken down into 4 separate steps, labeled Exercise 3A to 3D, one step for each column. \n",
    "\n",
    "**WARNING--WARNING--WARNING**\n",
    "\n",
    "Any time that you are making a major modification to a DataFrame, such as dropping a column, it is _very_ easy to start generating errors when you are working on your exercises. Problems arise after you drop a column from a DataFrame. If you try re-run the same code cell again, the column has already been dropped, you will generate an error. The only way to avoid these errors is to **GO BACK AND RE-RUN _ALL_ THE CODE CELLS** starting from **Exercise 1** where you originally created your complete DataFrame, `hdDF`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3A: One-Hot encode the column `ChestPainType`**\n",
    "\n",
    "In the cell below, One-Hot encode the column `ChestPainType` in the Heart Disease DataFrame, `hdDF`. Add the dummies to the DataFrame and then drop the column `ChestPainType`. Set the display for 9 columns and 8 rows and print out a display of your updated DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3A here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3B: One-Hot encode the column `RestingECG`**\n",
    "\n",
    "In the cell below, One-Hot encode the column `RestingECG` in the Heart Disease DataFrame, `hfDF`. Add the dummies to the DataFrame and then drop the column `RestingECG`. Set the display for 9 columns and 8 rows and print out a display of your updated DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3B here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3C: One-Hot encode the column `ExerciseAngina`**\n",
    "\n",
    "In the cell below, One-Hot encode the column `ExerciseAngina` in the Heart Disease DataFrame, `hdDF`. Add the dummies to the DataFrame and then drop the column `ExerciseAngina`. Set the display for 9 columns and 8 rows and print out a display of your updated DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3C here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3D: One-Hot encode the column `ST_Slope`**\n",
    "\n",
    "In the cell below, One-Hot encode the column `ST_Slope` in the Heart Disease DataFrame, `hdDF`. Add the dummies to the DataFrame and then drop the column `ST_Slope`. Set the display for 9 columns and 8 rows and print out a display of your updated DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3D here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see the following table.\n",
    "\n",
    "![__](https://corgi.genomelab.utsa.edu/BIO1173/images/class_04_1_Ex3E.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice that the number of columns in your DataFrame, `hfDF`, has increased from the original 12 columns to total of **20** columns. The \"column inflation` in an invariable consequence of One-Hot encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Code: Print out column names\n",
    "\n",
    "If your coding has been correct so far, your DataFrame, `hdDF` should have 20 columns. This is an inconviently large number of columns to display on your computer screen. In this situation, you can take advantage of the Pandas method `pd.columns` to print out a complete list of all the column names in DataFrame, using this line of code:\n",
    "\n",
    ">  `print(list(hdDF.columns))` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to check whether your code is correct before going on to the next part of the lesson. The code in this cell prints out a list of the column names in your updated DataFrame, `hdDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to print the column names\n",
    "\n",
    "print(list(hdDF.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your coding has been correct so far, you should see the following list of column names:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak', 'HeartDisease', 'Sex_F', 'Sex_M', 'ChestPainType_ASY', 'ChestPainType_ATA', 'ChestPainType_NAP', 'ChestPainType_TA', 'RestingECG_LVH', 'RestingECG_Normal', 'RestingECG_ST', 'ExerciseAngina_N', 'ExerciseAngina_Y', 'ST_Slope_Down', 'ST_Slope_Flat', 'ST_Slope_Up']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from `print(list(hfDF.columns))` doesn't match the sample output above, figure out which columns were not successfully One-Hot encoded and make the necessary code fixes. Remember, you will need to keep re-running all of the code cells starting with **Exercise 1** to restore your DataFrame `hdDF` to its original condition, before you debug the code cells in **Exercise 3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate X and Y for a Classification Neural Network\n",
    "\n",
    "Now that unecessary columns have been dropped, and all of the string data has been One-Hot encoded (except for the target column), we are ready to use the data stored in the updated DataFrame as input for a neural network. \n",
    "\n",
    "There are two basic ways to used tabular data (i.e. data stored in a DataFrame) as input into a neural network that peforms classification or as input for a neural network that performs regression. How you generate X and Y values will differ depending upon which type of neural network are are using.\n",
    "\n",
    "We will begin by building and training a **_classification_** neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Generate X and Y for _Classification_ Neural Network\n",
    "\n",
    "The goal of a classification neural network is to accurately categorize input data (X) into predefined classes or categories (Y). The network learns to identify patterns and features within the input data that are associated with each class, allowing it to make predictions about the class of new, unseen data. During training (fitting), the neural network tries to minimize the classification error as a way to improve the overall accuracy of the network's predictions.\n",
    "\n",
    "In a classification neural network, the output layer will have exactly _the same number of neurons as the number of predefined classes or categories_. For example, with the Apple Quality dataset there are two predifined classes/categories: (1) good and (2) bad. The output layer will have exactly two neurons. One neuron will represent `bad` and the other `good`. At the end of a run (epoch) the `bad` output neuron will have a \"voltage\" (numerical value) close to `1` if the neural network predicted the apple was bad while the `good` output neuron will have a much smaller value, closer to `0`. Conversely, if the neural network predicted the apple was `good`, the `good` output neuron will have a value close to `1` while the `bad` output neuron will have a much lower voltage, closer to `0`. In other words, the output neuron with the highest value represents the neural network's classification prediction.\n",
    "\n",
    "When using tabular data (i.e. data stored in a DataFrame), the first step is to figure out which columns in the DataFrame will be used to generate the X-values and which column will be used for the Y-values. For the Apple Quality dataset, our goal will be to classify apple **_quality_** so the information in the column `Quality` will be our Y-values and the remaining columns will be our X-values. \n",
    "\n",
    "In the code below, we start by creating a variable called `aqX_columns` by dropping the column `Quality`. In other words, the variable `aqX_columns` holds a list of all the columns in the DataFrame that we want to use as our X-values. The line of code that actually creates our X-values is:\n",
    "\n",
    "> `aqX = aqDF[aqX_columns].values`\n",
    "\n",
    "The Pandas method `pd.values` converts the numerical data in the `aqDF` DataFrame into the Numpy array, `aqX` that holds the numerical values. Keep in mind that neural networks, like most machine learning algorithms, work on Numpy numerical arrays, not numbers store in a DataFrame.\n",
    "\n",
    "The next step is to One-Hot encode the categorical values in target column `Quality`. The line of code that does this is:\n",
    "\n",
    "> `dummies = pd.get_dummies(aqDF['Quality'], dtype=int) # Classification`\n",
    "\n",
    "Finally, we create our Y-values from the dummy values using this line of code:\n",
    "\n",
    "> `aqY = dummies.values`\n",
    "\n",
    "Again, the Pandas method, `pd.values` converts the data into the Numpy array, `aqY`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Generate X and Y values\n",
    "\n",
    "# Drop column containing Y-values \n",
    "aqX_columns = aqDF.columns.drop('Quality')\n",
    "\n",
    "# Create X from the values in aqX_columns\n",
    "aqX = aqDF[aqX_columns].values\n",
    "\n",
    "# One-hot encode Y-values\n",
    "dummies = pd.get_dummies(aqDF['Quality'], dtype=int) # Classification\n",
    "\n",
    "# Create Y from dummy values\n",
    "aqY = dummies.values\n",
    "\n",
    "# Print out X and Y\n",
    "print(aqX)\n",
    "print(aqY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[-3.97004852 -2.51233638  5.34632961 ...  1.84490036  0.3298398\n",
    "  -0.49159048]\n",
    " [-1.19521719 -2.83925653  3.66405876 ...  0.8532858   0.86753008\n",
    "  -0.72280937]\n",
    " [-0.29202386 -1.35128199 -1.73842916 ...  2.83863551 -0.03803333\n",
    "   2.62163647]\n",
    " ...\n",
    " [-2.6345153  -2.13824672 -2.44046129 ...  2.19970859  4.76385918\n",
    "  -1.33461139]\n",
    " [-4.00800374 -1.77933711  2.36639697 ...  2.16143512  0.21448838\n",
    "  -2.22971981]\n",
    " [ 0.27853965 -1.71550503  0.12121725 ...  1.2666774  -0.77657147\n",
    "   1.59979646]]\n",
    "[[0 1]\n",
    " [0 1]\n",
    " [1 0]\n",
    " ...\n",
    " [1 0]\n",
    " [0 1]\n",
    " [0 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that our X and Y values for analysis by a regression neural network. All of the values are numerical (i.e. no strings) and stored in a Numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 4: Generate X and Y for Classification Neural Network**\n",
    "\n",
    "In the cell below generate X and Y values that can be used in a Heart Disease classification neural network. The Y-values are in the target column, `HeartDisease`, while the X-values are in all of the other columns. \n",
    "\n",
    "Even though the values in the column `HeartDisease` are already numerical (not strings), you will still need to One-Hot encode this column. The reason you need to One-Hot encode the `HeartDisease` column is to create the Y variable, `hdY`, with the correct format. \n",
    "\n",
    "Call your X-values, `hdX` and your Y-values, `hdY`. After generating these variables, print out their values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 4 here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[ 40. 140. 289. ...   0.   0.   1.]\n",
    " [ 49. 160. 180. ...   0.   1.   0.]\n",
    " [ 37. 130. 283. ...   0.   0.   1.]\n",
    " ...\n",
    " [ 57. 130. 131. ...   0.   1.   0.]\n",
    " [ 57. 130. 236. ...   0.   1.   0.]\n",
    " [ 38. 138. 175. ...   0.   0.   1.]]\n",
    "[[1 0]\n",
    " [0 1]\n",
    " [1 0]\n",
    " ...\n",
    " [0 1]\n",
    " [0 1]\n",
    " [1 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see any strings (words) in the output above, if means that you code had one (or more) errors in it. It will need to be corrected before you can use it will your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Construct a Classification Neural Network\n",
    "\n",
    "When building a classification neural network, there are two important points to remember:\n",
    "\n",
    "* Classification neural networks have an output neuron count equal to the number of classes.\n",
    "* Classification neural networks should use the **softmax** activation function on the output layer and **categorical_crossentropy** as the loss function when you compile your neural network.\n",
    "\n",
    "When building a new neural network, you must begin by telling Keras the name we what for our new network, what kind of neural network we want to build. In this example, we are building a simple linear network with the name `aqModel`, so we begin construction with the line:\n",
    "\n",
    "> `aqModel = Sequential()`\n",
    "\n",
    "Next we start adding \"hidden\" layers to our network in sequential order. There are no \"hard-and-fast\" rules when it comes to how many layers a network should have and how many neurons should be put in each layer. There are trade offs when it comes to the number of layers and neurons that will discussed later in this course. \n",
    "\n",
    "For now, we will construct a simple classification neural network with just 2 hidden layers and one output layer. We have to tell the first hidden layer how many inputs (X values) it will be receiving. We do this with the `input_dim` argument as shown here:\n",
    "\n",
    "> `input_dim=aqX.shape[1]`\n",
    "\n",
    "For this example, we will put 50 neurons in the first layer, and half that many (25) in the next (2nd) hidden layer. The argument `Dense` tell Keras to connect every neuron in that layer to every neuron in the next layer. At present, the activation function `relu` is considered to be the \"best\" for hidden layer neurons in this kind of simple neural network.\n",
    "\n",
    "As mentioned at the beginning of Example 5, we need to make sure there is one neuron in the output layer for each category that we want to classify. This is accomplished by the argument `aqY.shape[1]` in this line of code:\n",
    "\n",
    "> `aqModel.add(Dense(aqY.shape[1],activation='softmax')) # Output`\n",
    "\n",
    "The other point to remember was to use the loss function `categorical_crossentropy` and the `adam` optimizer when compiling the neural network. \n",
    "\n",
    "Once the neural network has been successfully compliled (one of the jobs of the compiler is to spot errors in your neural network), it can be \"fitted\" (trained) to the X and Y values. A complete \"run\" of the neural network is called an `epoch`. At the end of each epoch, the model evaluates its \"inaccuracy\" (loss), prints it out (if `verbose=2`), makes small modifications to the weigth/strength of each connection between neurons, and gets ready to run again. \n",
    "\n",
    "By fitting the model over-and-over again, the model will gradually find the best weight for each neural connection, by minimumizing the loss function. \n",
    "\n",
    "In this example, the number of epochs is set to 100.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the neural network\n",
    "\n",
    "# Build neural network\n",
    "aqModel = Sequential()\n",
    "aqModel.add(Dense(50, input_dim=aqX.shape[1], activation='relu')) # Hidden 1\n",
    "aqModel.add(Dense(25, activation='relu')) # Hidden 2\n",
    "aqModel.add(Dense(aqY.shape[1],activation='softmax')) # Output\n",
    "\n",
    "# Compile the model\n",
    "aqModel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model for 100 epochs\n",
    "aqModel.fit(aqX,aqY,verbose=2,epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see similiar to the following output. Notice that the loss value started at 0.4838 and gradually decreased to a value of 0.0675 after 100 epochs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/100\n",
    "125/125 - 1s - loss: 0.5091 - 809ms/epoch - 6ms/step\n",
    "Epoch 2/100\n",
    "125/125 - 0s - loss: 0.3584 - 417ms/epoch - 3ms/step\n",
    "Epoch 3/100\n",
    "125/125 - 0s - loss: 0.3173 - 390ms/epoch - 3ms/step\n",
    "Epoch 4/100\n",
    "125/125 - 0s - loss: 0.2950 - 411ms/epoch - 3ms/step\n",
    "Epoch 5/100\n",
    "125/125 - 0s - loss: 0.2807 - 394ms/epoch - 3ms/step\n",
    "............................\n",
    "Epoch 98/100\n",
    "125/125 - 0s - loss: 0.0675 - 397ms/epoch - 3ms/step\n",
    "Epoch 99/100\n",
    "125/125 - 0s - loss: 0.0712 - 395ms/epoch - 3ms/step\n",
    "Epoch 100/100\n",
    "125/125 - 0s - loss: 0.0675 - 405ms/epoch - 3ms/step\n",
    "\n",
    "<keras.callbacks.History at 0x234ba77e5e0>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 5: Construct, Compile and Fit a Classification Neural Network**\n",
    "\n",
    "In the cell below, construct, compile and fit a classification neural network to X values stored in `hdX` and the Y-values stores in `hdY`, using Example 5 as a template. Call your new neural network, `hdModel`. Train (fit) your network for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 5 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the output shown below. In this example, the loss function decreased from 3.2447 to 0.3265 after training 100 cycles (epochs)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/100\n",
    "29/29 - 0s - loss: 3.2447 - 378ms/epoch - 13ms/step\n",
    "Epoch 2/100\n",
    "29/29 - 0s - loss: 0.9699 - 144ms/epoch - 5ms/step\n",
    "Epoch 3/100\n",
    "29/29 - 0s - loss: 0.6530 - 118ms/epoch - 4ms/step\n",
    "Epoch 4/100\n",
    "29/29 - 0s - loss: 0.5964 - 101ms/epoch - 3ms/step\n",
    "Epoch 5/100\n",
    "29/29 - 0s - loss: 0.5657 - 101ms/epoch - 3ms/step\n",
    "...........................\n",
    "Epoch 95/100\n",
    "29/29 - 0s - loss: 0.3168 - 99ms/epoch - 3ms/step\n",
    "Epoch 96/100\n",
    "29/29 - 0s - loss: 0.3279 - 107ms/epoch - 4ms/step\n",
    "Epoch 97/100\n",
    "29/29 - 0s - loss: 0.3227 - 109ms/epoch - 4ms/step\n",
    "Epoch 98/100\n",
    "29/29 - 0s - loss: 0.3342 - 112ms/epoch - 4ms/step\n",
    "Epoch 99/100\n",
    "29/29 - 0s - loss: 0.3494 - 111ms/epoch - 4ms/step\n",
    "Epoch 100/100\n",
    "29/29 - 0s - loss: 0.3265 - 100ms/epoch - 3ms/step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate X and Y for a Regression Neural Network\n",
    "\n",
    "As mentioned above, the procedure for generating X and Y for a regression neural network is somewhat different the procedure used above. Even though these differences are not large, they are important. If your X and Y values are not generated in the correct format, your neural network will not compile and run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Generate X and Y for Regression Neural Network\n",
    "\n",
    "The goal of a regression neural network is to predict a **_continuous output value_** based on input data. The \"target\" column, `Quality` in the Apple Quality dataset, would **not** be a good candidate for a regression analysis. The reason is that data in this column is _not_ a continuous variable, but a binary variable with only two values, `0` (bad) or `1` (good). \n",
    "\n",
    "For regression, we want to predict a variable that has a range of values. By inspection of the statistical summary for `aqDF` (See the Appendix below), there are several possible candidates. Each of these columns have continuous numerical values  that would be suitable for a regression: `Weight`, `Sweetness`, `Crunchiness`, `Juiciness`, `Ripeness` and `Acidity`.  \n",
    "\n",
    "For Example 6, we will generate X and Y for a regression neural network designed to predict the `Sweetness` of an apple based on its other characteristics, including its quality. \n",
    "\n",
    "We begin by creating a new DataFrame called `aq2DF` from our already _updated_ DataFrame `aqDF` using the Pandas `pd.copy()` method. We will use `aq2DF` for creating X and Y. Note that we are **not** using a copy of the original DataFrame created in Example 1, since we don't want the column `A_id` that was dropped in Example 2.\n",
    "\n",
    "When trying to predict the `Sweetness` of an apple, the apple's `Quality` would seem like an important factor to include in the analysis. Since the column `Quality` has categorical values (i.e. `bad` and `good`) we will need to convert these strings into numerical values. However, instead of One-Hot encoding this column, we use the alternative approach of mapping these categorical values to `0` for `bad` and `1` for `good`. Also, since we are mapping the values _inside_ the column, we **don't** want to drop the `Quality` column as was done above when this column was One-Hot encoded.\n",
    "\n",
    "We do, however, need to drop the column `Sweetness` when creating our variable `aq2X_columns`. This should make sense since we don't want the actual sweetness values to be included as part of the X-values. That would defeat the entire purpose of the neural network! \n",
    "\n",
    "A very important difference between regression and catagorical network, when creating the Y data for a regression neural network, we **don't** want to One-Hot encode it, like we did above with the classification example. Ironically, One-Hot encoding in this instance will generate the _wrong_ format for the Y values. Instead, we simply generate the array `aq2Y` using numerical values in the target column:\n",
    "\n",
    "> `aq2Y = aq2DF['Sweetness']`\n",
    "\n",
    "Finally, the code prints out X and Y so we can visually inspect them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 6: Generate X and Y for regression\n",
    "\n",
    "# Create a copy and use it for X and Y\n",
    "aq2DF=aqDF.copy()\n",
    "\n",
    "# Map categorical values in Quality to integers\n",
    "mapping = {'bad': 0, 'good': 1}\n",
    "aq2DF['Quality'] = aq2DF['Quality'].map(mapping)\n",
    "\n",
    "# Drop column containing Y-values \n",
    "aq2X_columns = aq2DF.columns.drop('Sweetness')\n",
    "\n",
    "# Create X from the values in aq2X_columns\n",
    "aq2X = aq2DF[aq2X_columns].values\n",
    "\n",
    "# Assign Y to target column\n",
    "aq2Y = aq2DF['Sweetness']\n",
    "\n",
    "# Print out X and Y\n",
    "print(aq2X)\n",
    "print(aq2Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[-3.97004852 -2.51233638 -1.01200871 ...  0.3298398  -0.49159048\n",
    "   1.        ]\n",
    " [-1.19521719 -2.83925653  1.58823231 ...  0.86753008 -0.72280937\n",
    "   1.        ]\n",
    " [-0.29202386 -1.35128199 -0.34261593 ... -0.03803333  2.62163647\n",
    "   0.        ]\n",
    " ...\n",
    " [-2.6345153  -2.13824672  0.65722289 ...  4.76385918 -1.33461139\n",
    "   0.        ]\n",
    " [-4.00800374 -1.77933711 -0.20032937 ...  0.21448838 -2.22971981\n",
    "   1.        ]\n",
    " [ 0.27853965 -1.71550503 -1.15407476 ... -0.77657147  1.59979646\n",
    "   1.        ]]\n",
    "0       5.346330\n",
    "1       3.664059\n",
    "2      -1.738429\n",
    "3       1.324874\n",
    "          ...   \n",
    "3996   -0.204020\n",
    "3997   -2.440461\n",
    "3998    2.366397\n",
    "3999    0.121217\n",
    "Name: Sweetness, Length: 4000, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 6: Generate X and Y for Regression Neural Network**\n",
    "\n",
    "In the cell below, generate X and Y for a regression neural network that can predict the maximum heart rate,`MaxHR`, for the Heart Disease dataset. Start by making a copy of the DataFrame `hdDF` and calling it `hd2DF`. \n",
    "\n",
    "Use this new DataFrame, `hd2DF` for generating your X and Y values, `hd2X` and `hd2Y`, respectively. Since the values in the rightmost column `HeartDisease` are already in numerical form, you will **not** to map these values to integers as was done in Example 6. Don't forget to drop the column `MaxHR` before you generate your X-values!\n",
    "\n",
    "When you have generated X and Y, print out the values in `hd2X` and `hd2Y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 6 here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[ 40. 140. 289. ...   0.   0.   1.]\n",
    " [ 49. 160. 180. ...   0.   1.   0.]\n",
    " [ 37. 130. 283. ...   0.   0.   1.]\n",
    " ...\n",
    " [ 57. 130. 131. ...   0.   1.   0.]\n",
    " [ 57. 130. 236. ...   0.   1.   0.]\n",
    " [ 38. 138. 175. ...   0.   0.   1.]]\n",
    "0      172\n",
    "1      156\n",
    "2       98\n",
    "3      108\n",
    "      ... \n",
    "914    141\n",
    "915    115\n",
    "916    174\n",
    "917    173\n",
    "Name: MaxHR, Length: 918, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Construct, compile and fit a regression neural network\n",
    "\n",
    "The x and y values are now ready for a regression neural network. When building a neural network for regression, there are three points to remember. \n",
    "\n",
    "* **First:** a regression neural network only has a single neuron in its output layer. The \"voltage\" in this single output neuron at the end of each epoch, represents the network's numerical prediction. So in this example, the numerical value in the output neuron would be the `Sweetness` value. \n",
    "\n",
    "The difference between the predicted sweetness values, and the actual sweetness values stored in the Y variable, `ap2Y`, is the loss value. The better the neural network becomes at predicting sweetness based on all of the apple's other attributes (i.e., `Weight`, `Crunchiness`, `Juiciness`, `Ripeness`, `Acidity` and `Quality`), the smaller the loss value becomes. \n",
    "\n",
    "* **Second:** a regression neural network does **not** use an activation function in the output layer. \n",
    "\n",
    "* **Third:** when you compile a regression neural network, the loss function should be `mean_squared_error`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 7: Construct, compile and fit\n",
    "\n",
    "# Construct regression neural network\n",
    "aq2Model = Sequential()\n",
    "aq2Model.add(Dense(25, input_dim=aq2X.shape[1], activation='relu')) # Hidden 1\n",
    "aq2Model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "aq2Model.add(Dense(1)) # Output: 1 neuron, no activation\n",
    "\n",
    "# Compile model with MSE loss function\n",
    "aq2Model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fit model to the data\n",
    "aq2Model.fit(aq2X,aq2Y,verbose=2,epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/100\n",
    "125/125 - 1s - loss: 2.9494 - 840ms/epoch - 7ms/step\n",
    "Epoch 2/100\n",
    "125/125 - 0s - loss: 2.0785 - 435ms/epoch - 3ms/step\n",
    "Epoch 3/100\n",
    "125/125 - 0s - loss: 1.7271 - 468ms/epoch - 4ms/step\n",
    "Epoch 4/100\n",
    "125/125 - 0s - loss: 1.5429 - 439ms/epoch - 4ms/step\n",
    "Epoch 5/100\n",
    "125/125 - 0s - loss: 1.4220 - 425ms/epoch - 3ms/step\n",
    ".............\n",
    "Epoch 95/100\n",
    "125/125 - 0s - loss: 0.5116 - 420ms/epoch - 3ms/step\n",
    "Epoch 96/100\n",
    "125/125 - 0s - loss: 0.5110 - 477ms/epoch - 4ms/step\n",
    "Epoch 97/100\n",
    "125/125 - 0s - loss: 0.5107 - 423ms/epoch - 3ms/step\n",
    "Epoch 98/100\n",
    "125/125 - 0s - loss: 0.5151 - 426ms/epoch - 3ms/step\n",
    "Epoch 99/100\n",
    "125/125 - 0s - loss: 0.5112 - 421ms/epoch - 3ms/step\n",
    "Epoch 100/100\n",
    "125/125 - 0s - loss: 0.5095 - 420ms/epoch - 3ms/step\n",
    "\n",
    "<keras.callbacks.History at 0x1742cc497f0>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 7: Construct, compile and fit a regression neural network**\n",
    "\n",
    "In the cell below create a regression neural network for the Heart Disease dataset that can predict the maximum heart rate (`MaxHR`).  Use Example 7 as a template. Call your neural network, `hd2Model`. Train (fit) you model for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 7 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see something similar to the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/100\n",
    "29/29 - 1s - loss: 9691.7715 - 780ms/epoch - 27ms/step\n",
    "Epoch 2/100\n",
    "29/29 - 0s - loss: 4449.5981 - 148ms/epoch - 5ms/step\n",
    "Epoch 3/100\n",
    "29/29 - 0s - loss: 3322.9236 - 126ms/epoch - 4ms/step\n",
    "Epoch 4/100\n",
    "29/29 - 0s - loss: 2568.3320 - 111ms/epoch - 4ms/step\n",
    "Epoch 5/100\n",
    "29/29 - 0s - loss: 1853.4669 - 115ms/epoch - 4ms/step\n",
    ".............\n",
    "Epoch 95/100\n",
    "29/29 - 0s - loss: 678.9979 - 114ms/epoch - 4ms/step\n",
    "Epoch 96/100\n",
    "29/29 - 0s - loss: 676.7915 - 120ms/epoch - 4ms/step\n",
    "Epoch 97/100\n",
    "29/29 - 0s - loss: 669.3038 - 112ms/epoch - 4ms/step\n",
    "Epoch 98/100\n",
    "29/29 - 0s - loss: 685.5514 - 106ms/epoch - 4ms/step\n",
    "Epoch 99/100\n",
    "29/29 - 0s - loss: 671.1352 - 104ms/epoch - 4ms/step\n",
    "Epoch 100/100\n",
    "29/29 - 0s - loss: 669.3387 - 110ms/epoch - 4ms/step\n",
    "\n",
    "<keras.callbacks.History at 0x1742ad65760>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lesson Turn-in**\n",
    "\n",
    "When you have completed all of the code cells, run all of them in sequential order (the last code cell should be number 20, not counting the Appendix below). Then use the **File --> Print.. --> Save to PDF** to generate a PDF of your JupyterLab notebook. Save your PDF as `Class_04_1.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "The code in the cells use the Pandas method `pd.describe()` to print out a statistical summary of the data in the Apple Quality and in the Heart Disease datasets. DataFrame columns with categorical values are **not** included in the statistical summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
