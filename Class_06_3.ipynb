{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEEW13uCtiJ",
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/master/Class_06_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BIO 1173: Intro Computational Biology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module 6: Convolutional Neural Networks (CNN) for Computer Vision**\n",
    "\n",
    "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
    "\n",
    "### Module 6 Material\n",
    "\n",
    "* Part 6.1: Using Convolutional Neural Networks \n",
    "* Part 6.2: Using Pretrained Neural Networks with Keras\n",
    "* **Part 6.3: Looking at Keras Generators and Image Augmentation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Setup\n",
    "\n",
    "Run the next code cell to load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You MUST run this code cell first\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "path = '/'\n",
    "memory = shutil.disk_usage(path)\n",
    "dirpath = os.getcwd()\n",
    "print(\"Your current working directory is : \" + dirpath)\n",
    "print(\"Disk\", memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seXFCYH4LDUM",
    "outputId": "c05015aa-871e-4779-9265-5ad07e8bf617",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You must run this cell second\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "    import requests\n",
    "    gcloud_token = !gcloud auth print-access-token\n",
    "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "    print(gcloud_tokeninfo['email'])\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPa_ojR1mp9j"
   },
   "source": [
    "# Part 6.3: Using Image Augmentation\n",
    "\n",
    "The [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) class provides many options for image augmentation.  \n",
    "\n",
    "**_Image augmentation_** is a technique used in machine learning to artificially increase the size of a training dataset by applying various transformations to the existing images. In Keras, the `ImageDataGenerator` class is commonly used for image augmentation. This class allows for easily applying transformations such as rotation, flipping, zooming, shifting, and more to the images in the dataset during training, helping to improve the model's performance and generalization capabilities.\n",
    "\n",
    "Deciding which augmentations to use can impact the effectiveness of your model. In this lesson we will visualize some of these augmentations that you might use to train your neural network. Depending upon the composition of your images, some augmentations will be more useful than other ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Load Image Data\n",
    "\n",
    "The code in the cell below uses the function `urllib.request.urlopen()` to read an image file stored on an HTTPS server. This function, `urllib.request.urlopen()` is used in Python to open a URL and retrieve its contents. It is commonly used to interact with web resources such as downloading files, making HTTP requests, or reading web pages. This function allows you to access and retrieve data from a given URL, making it useful for tasks such as web scraping, data collection, and accessing APIs.\n",
    "\n",
    "In Example 1, the `urllib.request.urlopen()` function is used to open the specified URL (https://biologicslab.co) and retrieve its contents. The `read()` method of the response object is then used to read the data from the URL, which can be further processed or displayed as needed.\n",
    "\n",
    "The argument `URL` needs both the actual web address, including the image name, but the addition argument `raw=true` as shown in this code chunk:\n",
    "~~~text\n",
    "URL = \"https://biologicslab.co/BIO1173/images/cambrian.jpg?raw=true\"\n",
    "~~~\n",
    "\n",
    "The code assigns the variable `LOCAL_IMG_FILE1` to the image name and then reads the image data from the URL using a `with` statement to manage resources and ensure their proper cleanup or release after they are no longer needed. \n",
    "\n",
    "Here is the code chunk that actually reads and downloads the image data: \n",
    "~~~text\n",
    "with urllib.request.urlopen(URL) as response, \\\n",
    "  open(LOCAL_IMG_FILE1, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "~~~\n",
    "In this example, `shutil.copyfileobj` is used to copy the contents of the `response` to `out_file` by passing the file objects as arguments to the function. This function efficiently copies data in chunks without loading the entire file into memory, making it suitable for working with large files.\n",
    "\n",
    "\n",
    "In this example, the with statement is used to open a file ('example.txt') for reading. When the block of code inside the with statement completes execution, Python automatically closes the file, ensuring that the file handle is properly released. This helps in managing resources efficiently and avoiding memory leaks or file handle issues.\n",
    "\n",
    "Finally, the function `Image()` is used to display the downloaded image. In Example 1, the image is an artist's reconstruction of the [Cambrian Explosion](https://biologicslab.co/BIO1173/data/CambrianExplosion.pdf), an \"evolutionary burst\" that occurred 540 million years ago. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "id": "-vd3d3z1h80_",
    "outputId": "72f1f9b2-2a9f-44a2-aed1-7074b2d7a56f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 1: Load Image Data\n",
    "\n",
    "import urllib.request\n",
    "import shutil\n",
    "from IPython.display import Image\n",
    "\n",
    "# Specify the URL for the image\n",
    "URL = \"https://biologicslab.co/BIO1173/images/cambrian.jpg?raw=true\"\n",
    "\n",
    "# Create variable\n",
    "LOCAL_IMG_FILE1 = \"cambrian.jpg\"\n",
    "\n",
    "# Download image\n",
    "with urllib.request.urlopen(URL) as response, \\\n",
    "  open(LOCAL_IMG_FILE1, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "\n",
    "# Display image\n",
    "Image(filename=LOCAL_IMG_FILE1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code if correct you should see the following image:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/cambrian.jpg).\n",
    "\n",
    "In case you were wondering, the large creature in this image is called [Anomalocaris](https://en.wikipedia.org/wiki/Anomalocaris)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1: Load Image Data**\n",
    "\n",
    "In the cell below, write the code to download display the image `roadrunner.jpg` from the course HTTPS server. Create a variable called `LOCAL_IMG_FILE2` to refer to this image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "id": "-vd3d3z1h80_",
    "outputId": "72f1f9b2-2a9f-44a2-aed1-7074b2d7a56f"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following image of the [Greater Roadrunner](https://en.wikipedia.org/wiki/Roadrunner), (genus _Geococcyx_).\n",
    "\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/roadrunner.jpg).\n",
    "\n",
    "The primary food of the roadrunner consists of insects, small reptiles, rodents, birds, and fruits. They are opportunistic feeders that have a diverse diet, but insects such as grasshoppers, beetles, and scorpions are among their preferred food sources. Roadrunners are also known to consume snakes, lizards, small mammals, and occasionally fruits and seeds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL0qZm59lrsc"
   },
   "source": [
    "### Define Useful Functions\n",
    "\n",
    "Next, we introduce a simple utility function called `visualize_generator()` to visualize four images sampled from any generator. Using this utility function, we can see 4 different ways the Image Augmentation works at the same time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjsQ2JmOmp9j"
   },
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "def visualize_generator(img_file, gen):\n",
    "\t# Load the requested image\n",
    "  img = load_img(img_file)\n",
    "  data = img_to_array(img)\n",
    "  samples = expand_dims(data, 0)\n",
    "\n",
    "\t# Generat augumentations from the generator\n",
    "  it = gen.flow(samples, batch_size=1)\n",
    "  images = []\n",
    "  for i in range(4):\n",
    "    batch = it.next()\n",
    "    image = batch[0].astype('uint8')\n",
    "    images.append(image)\n",
    "\n",
    "  images = np.array(images)\n",
    "\n",
    "\t# Create a grid of 4 images from the generator\n",
    "  index, height, width, channels = images.shape\n",
    "  nrows = index//2\n",
    "    \n",
    "  grid = (images.reshape(nrows, 2, height, width, channels)\n",
    "            .swapaxes(1,2)\n",
    "            .reshape(height*nrows, width*2, 3))\n",
    "  \n",
    "  fig = plt.figure(figsize=(15., 15.))\n",
    "  plt.axis('off')\n",
    "  plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qdE5gmwl8Ak"
   },
   "source": [
    "### Example 2: Flip Image \n",
    "\n",
    "We begin by flipping the image. Some images may not make sense to flip, such as this landscape.  However, if you expect \"noise\" in your data where some images may be flipped, then this augmentation may be useful, even if it violates physical reality.\n",
    "\n",
    "You should note that you are able to control the \"flipping axis\", either horizontally and vertically. By design the process has a random component so that if you run the next code cell several times, you will get different outputs. As you might imagine, this would usually be a positive thing if your objective was to increae the size of your training image dataset, without having to add additional images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "QtXgiFgqM3Mx",
    "outputId": "5cccd37c-4a76-4a56-ec6c-049bfda63492"
   },
   "outputs": [],
   "source": [
    "# Example 2: Flip image\n",
    "\n",
    "visualize_generator(\n",
    "  LOCAL_IMG_FILE1,\n",
    "  ImageDataGenerator(horizontal_flip=True, vertical_flip=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qdE5gmwl8Ak"
   },
   "source": [
    "### **Exercise 2: Flip Image** \n",
    "\n",
    "In the cell below, write the code to flip your Roadrunner image both vertically and horizontally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "QtXgiFgqM3Mx",
    "outputId": "5cccd37c-4a76-4a56-ec6c-049bfda63492"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 2 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7fvbDxImBV9"
   },
   "source": [
    "### Example 3: Move image\n",
    "\n",
    "Next, we will try moving the image. Notice how part of the image is missing? There are various ways to fill in the missing data, as controlled by **fill_mode**. In this case, we simply use the nearest pixel to fill. It is also possible to rotate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "g8G7R9xbmHbB",
    "outputId": "aedc74ca-3c87-4dc1-e9f7-5788df536a66"
   },
   "outputs": [],
   "source": [
    "# Example 3: Move image\n",
    "\n",
    "visualize_generator(\n",
    "    LOCAL_IMG_FILE1,\n",
    "    ImageDataGenerator(width_shift_range=[-200,200], \n",
    "        fill_mode='nearest'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7fvbDxImBV9"
   },
   "source": [
    "### **Exercise 3: Move image**\n",
    "\n",
    "In the cell below write the code to move your Roadrunner image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "g8G7R9xbmHbB",
    "outputId": "aedc74ca-3c87-4dc1-e9f7-5788df536a66"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf12lhVPmS_9"
   },
   "source": [
    "### Example 4: Adjust Brightness\n",
    "\n",
    "We can also adjust brightness. Training Convolutional Neural Networks (CNNs) on the same image with different levels of brightness is a form of data augmentation that helps improve the model's robustness and generalization capabilities. By presenting the network with variations of the same image (e.g., brighter and darker versions), the CNN learns to be invariant to changes in lighting conditions, thereby improving its ability to recognize objects under different lighting conditions in real-world scenarios. This practice helps the CNN become more robust and perform better when presented with new, unseen data during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "AsU4Yh1lXMvT",
    "outputId": "64b97581-dcdc-40ac-d398-5b59d9aafccf"
   },
   "outputs": [],
   "source": [
    "# Example 4: Adjust brightness\n",
    "\n",
    "visualize_generator(\n",
    "  LOCAL_IMG_FILE1,\n",
    "  ImageDataGenerator(brightness_range=[0,1]))\n",
    "\n",
    "# brightness_range=None, shear_range=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf12lhVPmS_9"
   },
   "source": [
    "### **Exercise 4: Adjust Brightness**\n",
    "\n",
    "In the cell below, write the code to display your Roadrunner image with different levels of brightness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "AsU4Yh1lXMvT",
    "outputId": "64b97581-dcdc-40ac-d398-5b59d9aafccf"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 4 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8JiokxFmXkS"
   },
   "source": [
    "### Example 5: Shear Image\n",
    "\n",
    "To **_shear_** an image means to apply a geometric transformation that shifts the position of pixels in the image along a specified direction, resulting in a distorted or skewed version of the original image. \n",
    "\n",
    "Shearing is a linear transformation that tilts the image along one axis while keeping the other axis unchanged. This transformation can be used for various purposes in image processing and computer vision tasks, such as correcting perspective distortion, creating artistic effects, or augmenting a dataset for training machine learning models.\n",
    "\n",
    "Shearing may not be appropriate for all image types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "Pbp1pYKEX_Hf",
    "outputId": "7b1070f1-82ba-493e-a62d-a5fa6dd34087"
   },
   "outputs": [],
   "source": [
    "# Example 5: Shear Image\n",
    "\n",
    "visualize_generator(\n",
    "  LOCAL_IMG_FILE1,\n",
    "  ImageDataGenerator(shear_range=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8JiokxFmXkS"
   },
   "source": [
    "### **Exercise 5: Shear Image**\n",
    "\n",
    "In the cell below, write the code to shear your Roadrunner image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "Pbp1pYKEX_Hf",
    "outputId": "7b1070f1-82ba-493e-a62d-a5fa6dd34087"
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 5 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6WJLtJSoHPs"
   },
   "source": [
    "### Example 6: Rotate Image\n",
    "\n",
    "It is also possible to rotate images. Like the other examples shown above, adding rotated images to the training set, the CNN learns to be flexible to changes in position, thereby improving its ability to recognize objects in real-world scenarios. This practice helps the CNN become more robust and perform better when presented with new, unseen data during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "-vwbjaVTYOpi",
    "outputId": "dcf74b3b-3964-4387-8928-602dbf97b25b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 6: Rotate Image\n",
    "\n",
    "visualize_generator(\n",
    "  LOCAL_IMG_FILE1,\n",
    "  ImageDataGenerator(rotation_range=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6WJLtJSoHPs"
   },
   "source": [
    "### **Exercise 6: Rotate Image**\n",
    "\n",
    "In the cell below, write the code to rotate your Roadrunner image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "-vwbjaVTYOpi",
    "outputId": "dcf74b3b-3964-4387-8928-602dbf97b25b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 6 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXHwP_hXwKwZ"
   },
   "source": [
    "If we wanted to, we could zip-up the preprocessed files and store them somewhere for latter use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lesson Turn-in**\n",
    "\n",
    "When you have completed all of the code cells, and run them in sequential order (the last code cell should be number 15) use the **File --> Print.. --> Save to PDF** to generate a PDF of your JupyterLab notebook. Save your PDF as `Class_06_3.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tf-sum24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
