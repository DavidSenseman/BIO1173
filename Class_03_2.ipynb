{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/main/Class_03_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZVwSpdbE3Y"
      },
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExN-OzpYbE3Y"
      },
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4imk1kbE3Y"
      },
      "source": [
        "##### **Module 3: Convolutional Neural Networks (CNN's)**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Biology, Health and the Environment](https://sciences.utsa.edu/bhe/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "### Module 3 Material\n",
        "\n",
        "* Part 3.1: Using Convolutional Neural Networks\n",
        "* **Part 3.2: Using Pre-Trained Neural Networks with Keras**\n",
        "* Part 3.3: Facial Recognition and Analysis\n",
        "* Part 3.4: Introduction to GAN's for Image and Data Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Change your Runtime Now!**\n",
        "\n",
        "For this lesson you must have a GPU hardware accelerator (e.g. `A100`)."
      ],
      "metadata": {
        "id": "Ult76BB_wSzg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_-lPkxLbE3Z"
      },
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. By running this code cell, you will map your GDrive to /content/drive and print out your Google GMAIL address. Your Instructor will use your GMAIL address to verify the author of this class lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seXFCYH4LDUM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# You must run this cell first\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    COLAB = True\n",
        "    print(\"Note: Using Google CoLab\")\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"**WARNING**: Your GMAIL address was **not** printed in the output below.\")\n",
        "    print(\"**WARNING**: You will NOT receive credit for this lesson.\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see the following output except your GMAIL address should appear on the last line.\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_01/class_01_6_image01A.png)\n",
        "\n",
        "If your GMAIL address does not appear your lesson will **not** be graded."
      ],
      "metadata": {
        "id": "xG3_sXTDfyjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TIME WARNING!**\n",
        "\n",
        "This lesson will probably **require close to 3 hours to complete**. Besides the normal issues there are two instances in which you are required to train a neural network. Training time for both neural networks is about 1 hour.\n",
        "\n",
        "Don't start working on this lesson if you don't have sufficient free time to finish it."
      ],
      "metadata": {
        "id": "BYHuoONPZGtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accelerated Run-time Check\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. The code in this cell checks what hardware acceleration you are using. To run this lesson, you must be running a Graphics Processing Unit (GPU)."
      ],
      "metadata": {
        "id": "LKhQzBV1wu2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You must run this cell second\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 0️⃣  Create check_device() function\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "def check_device():\n",
        "    # Check for available devices\n",
        "    devices = tf.config.list_physical_devices()\n",
        "\n",
        "    # Initialize device flags\n",
        "    cpu = False\n",
        "    gpu = False\n",
        "    tpu = False\n",
        "\n",
        "    # Check device types\n",
        "    for device in devices:\n",
        "        if device.device_type == 'CPU':\n",
        "            cpu = True\n",
        "        elif device.device_type == 'GPU':\n",
        "            gpu = True\n",
        "        elif device.device_type == 'TPU':\n",
        "            tpu = True\n",
        "\n",
        "    # Output device status\n",
        "    if tpu:\n",
        "        print(\"Running on TPU\")\n",
        "        print(\"WARNING: You must run this assigment using a GPU to earn credit\")\n",
        "        print(\"Change your RUNTIME now!\")\n",
        "    elif gpu:\n",
        "        print(\"Running on GPU\")\n",
        "        gpu_info = !nvidia-smi\n",
        "        gpu_info = '\\n'.join(gpu_info)\n",
        "        print(gpu_info)\n",
        "        print(\"You are using a GPU hardware accelerator--You're good to go!\")\n",
        "    elif cpu:\n",
        "        print(\"Running on CPU\")\n",
        "        print(\"WARNING: You must run this assigment using a GPU to earn credit\")\n",
        "        print(\"Change your RUNTIME now!\")\n",
        "    else:\n",
        "        print(\"No compatible device found\")\n",
        "        print(\"WARNING: You must run this assigment using either a GPU or a TPU to earn credit\")\n",
        "        print(\"Change your RUNTIME now!\")\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 1️⃣  Call function\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "check_device()"
      ],
      "metadata": {
        "id": "8kty-X7j9tDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you current `Runtime` is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image11A.png)\n",
        "\n",
        "However, if you received this warning message\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_05/class_05_4_image14A.png)\n",
        "\n",
        "You **MUST** go back and change your `Runtime` **NOW** before you continue."
      ],
      "metadata": {
        "id": "HIAs3kcq-WSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Custom Function\n",
        "\n",
        "The cell below creates a custom function called `hms_string()`. This function is needed to record the time required to train your neural network model.\n",
        "\n",
        "If you fail to run this cell now, you will receive one (or more) error message(s) later in this lesson."
      ],
      "metadata": {
        "id": "Mu5xJAWl_9vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom function\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 0️⃣  Create hms_string()\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "# Simple function to print out elasped time\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "metadata": {
        "id": "STtFj1QKTVcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DOWNLOAD AND INSTALL PRE-TRAINED NEURAL NETWORKS**\n",
        "\n",
        "We will be using two pre-trained neural networks in this lesson, `ResNet50` and `ResNet101`. Run the next couple of code cells to download these neural networks to your COLAB environment."
      ],
      "metadata": {
        "id": "w5gvsd-lxR3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download `ResNet50`"
      ],
      "metadata": {
        "id": "8YQBCLR3ZGil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ResNet50\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "ResNet50_model_244 = ResNet50(weights='imagenet',include_top=True)"
      ],
      "metadata": {
        "id": "tKZNxQ4kZHfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image26C.png)"
      ],
      "metadata": {
        "id": "qN828uR85VKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download`ResNet101`"
      ],
      "metadata": {
        "id": "-NKUT1cv4rTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ResNet101\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "\n",
        "ResNet101_model_512 = ResNet101(weights='imagenet',include_top=True)"
      ],
      "metadata": {
        "id": "z0LTPBQv4rTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image26C.png)"
      ],
      "metadata": {
        "id": "utSoi75H4rTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Helper Functions for Examples and **Exercises**\n",
        "\n",
        "The code in the cell below creates a two functions that we will need to use classify images in Examples 1 and 2.\n",
        "\n",
        "* **make_square()** Since MobileNet is designed to classify images with the same number of horizontal and vertical pixels (i.e. a 'square' image), this function uses a combination of padding and cropping to convert any image into a 'square` image.\n",
        "\n",
        "* **classify_image()** This function does most of the work. It first retrives the image from the HTTPS server and resizes it before processing it by the `ResNet50 model` that we previously downloaded. The actual prediction is made by this line of code:\n",
        "```text\n",
        "preds = ResNet50_model_244.predict(x)\n",
        "```"
      ],
      "metadata": {
        "id": "mDMqH7jsZuuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install helper functions\n",
        "\n",
        "# %matplotlib inline   # uncomment if you are in a Jupyter notebook\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Imports\n",
        "# ----------------------------------------------------------------------\n",
        "from PIL import Image, ImageFile, UnidentifiedImageError\n",
        "import requests\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from IPython.display import display\n",
        "\n",
        "from tensorflow.keras.applications.resnet import ResNet50, decode_predictions, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Global settings\n",
        "# ----------------------------------------------------------------------\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT = 224, 224          # target resolution\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = False       # keep the default behaviour\n",
        "\n",
        "# Load the pretrained ResNet‑50 model\n",
        "ResNet_model_244 = ResNet50(weights='imagenet')\n",
        "\n",
        "# Base URL of the images\n",
        "ROOT = \"https://biologicslab.co/BIO1173/images/class_03/\"\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Utility functions\n",
        "# ----------------------------------------------------------------------\n",
        "def make_square(img):\n",
        "    \"\"\"\n",
        "    Crop the image to a square (center‑aligned).\n",
        "    \"\"\"\n",
        "    width, height = img.size\n",
        "    side = min(width, height)\n",
        "    left   = (width  - side) // 2\n",
        "    top    = (height - side) // 2\n",
        "    right  = left + side\n",
        "    bottom = top  + side\n",
        "    return img.crop((left, top, right, bottom))\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Core function\n",
        "# ----------------------------------------------------------------------\n",
        "def classify_image(url):\n",
        "    \"\"\"\n",
        "    Download an image from *url*, preprocess it, run it through ResNet‑50,\n",
        "    display the image and print the top‑5 ImageNet predictions.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()          # raise an error on bad status\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "    except UnidentifiedImageError:\n",
        "        print(\"Error: Cannot identify image file. Check the image URL or file format.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error while downloading or opening the image: {e}\")\n",
        "        return\n",
        "\n",
        "    # Resize (or square‑crop first if you prefer)\n",
        "    img = img.resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.LANCZOS)\n",
        "\n",
        "    # Preprocess\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    # Predict\n",
        "    preds = ResNet50_model_244.predict(x)\n",
        "\n",
        "    # Show the image\n",
        "    display(img)\n",
        "\n",
        "    # Print the top‑5 predictions\n",
        "    print(\"\\nTop‑5 predictions:\")\n",
        "    for pred in decode_predictions(preds, top=5)[0]:\n",
        "        print(f\"  {pred[1]:<25} : {pred[2]*100:5.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3yjALGfL6qZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should **not** see any output."
      ],
      "metadata": {
        "id": "Jbe54CjtWtSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1: Classify Images with ResNet50\n",
        "\n",
        "The code in the cell below downloads an image of a dog from the course fileserver, https://biologicslab.co and then uses the pre-trained `ResNet50` neural network  `ResNet50` to to classify it.\n",
        "\n",
        "The image name is \"pembroke_corgi.jpg\""
      ],
      "metadata": {
        "id": "qiYyHO41Zurj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Classify Image with ResNet50\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "\n",
        "# Enter image name\n",
        "image_name=\"pembroke_corgi.jpg\"\n",
        "\n",
        "# Generate image path\n",
        "image_path=ROOT+image_name\n",
        "\n",
        "# Print path\n",
        "print(f\"Analyzing \", image_path)\n",
        "\n",
        "# Use ResNet50 to classify image\n",
        "classify_image(image_path)"
      ],
      "metadata": {
        "id": "Tc_bGTfaaiRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image25C.png)\n",
        "\n",
        "`ResNet50` has been trained to recognize a wide range of common objectes. Here is a basic list:\n",
        "\n",
        "| Domain                           | Example classes (just a few from each)                                   |\n",
        "|----------------------------------|--------------------------------------------------------------------------|\n",
        "| Animals – mammals                | chimpanzee, tiger, lion, zebra, elephant                                |\n",
        "| Animals – birds                  | eagle, sparrow, penguin, flamingo, crane                                 |\n",
        "| Animals – reptiles & amphibians  | alligator, snake, frog, turtle                                          |\n",
        "| Animals – fish & crustaceans     | goldfish, salmon, shrimp, lobster                                       |\n",
        "| Animals – insects                | bee, butterfly, ant, dragonfly                                          |\n",
        "| Plants & flowers                 | daisy, sunflower, orchid, cactus                                        |\n",
        "| Fruits & vegetables              | apple, orange, broccoli, carrot                                         |\n",
        "| Vegetables & nuts                | potato, tomato, almond, cashew                                          |\n",
        "| Instruments & musical equipment  | guitar, piano, violin, saxophone                                        |\n",
        "| Sports & equipment               | tennis racket, golf ball, basketball, soccer ball                       |\n",
        "| Vehicles – land                  | car, truck, motorcycle, bicycle                                         |\n",
        "| Vehicles – air                   | airplane, helicopter, jet, glider                                       |\n",
        "| Vehicles – water                 | boat, ship, submarine, ferry                                            |\n",
        "| Buildings & architecture         | bridge, house, church, skyscraper                                       |\n",
        "| Furniture                        | chair, table, sofa, bed                                                  |\n",
        "| Home appliances                  | microwave, refrigerator, toaster, blender                               |\n",
        "| Tools & hardware                 | hammer, screwdriver, wrench, drill                                      |\n",
        "| Clothing & accessories           | t‑shirt, hat, shoes, glasses                                            |\n",
        "| Food & drinks                    | coffee, tea, pizza, cake                                                |\n",
        "| Miscellaneous                    | toilet paper, keyboard, watch, trophy                                   |\n",
        "\n",
        "\n",
        "Clearly `ResNet50` was trained to classify dogs. What is somewhat interesting, is that `ResNet50` appears to be quite good as to correctly identify a dog's breed. `ResNet50` was absolutedly correct that the image showed a `Welsh Pembroke Corgi`.\n",
        "\n",
        "The **Pembroke Welsh Corgi** is a spirited, compact herding dog originally from Wales. Known for its short legs, fox-like ears, and expressive eyes, it's affectionate, intelligent, and highly trainable. Pembrokes thrive on activity, enjoy family life, and are renowned for their loyal, playful nature and distinctive “corgi grin.”"
      ],
      "metadata": {
        "id": "tWiRgSgP0lPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1: Classify Images with ResNet50**\n",
        "\n",
        "In the cell below write the code to download an another dog image from the course fileserver:\n",
        "\n",
        "```type\n",
        "image_name=\"bouvier_des_flandres.jpg\"\n",
        "```\n",
        "and then uses `ResNet50` to classify it. This species is much less common than Corgis.\n",
        "\n",
        "The **Bouvier des Flandres**, or **Bouvier de Flanders**, is a muscular, medium‑to‑large herding dog originally bred in the Flemish region of Belgium to manage cattle, sheep and pack loads. With a dense, double‑coated coat that comes in black, brown, red or tricolor, they are built for endurance and can thrive in both wet and dry climates. Their temperament is confident and affectionate, yet they possess a strong work ethic and a naturally protective instinct, making them excellent companion animals as well as valuable in search‑and‑rescue, therapy, and police work. Bouviers are intelligent and trainable, but they require consistent socialization and mental stimulation to prevent stubbornness or frustration. Health concerns are relatively few—chiefly hip dysplasia, gastric dilatation‑volvulus (bloat) and certain eye conditions—so with proper care, they can live 10–12 years."
      ],
      "metadata": {
        "id": "nKO_1OUi8rCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Classify Image with ResNet50\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "\n",
        "# Enter image name\n",
        "image_name=\"bouvier_des_flandres.jpg\"\n",
        "\n",
        "# Generate image path\n",
        "image_path=ROOT+image_name\n",
        "\n",
        "# Print path\n",
        "print(f\"Analyzing \", image_path)\n",
        "\n",
        "# Use ResNet50 to classify image\n",
        "classify_image(image_path)"
      ],
      "metadata": {
        "id": "dPlaG9CW8rCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image27C.png)\n",
        "\n",
        "This time `ResNet50` got a little confused. It was \"pretty sure\" (62%) that the dog in the image was an `Irish water spaniel`.\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_03/IrishWaterSpaniel.jpg)\n",
        "\n",
        "**Irish Water Spaniel**\n",
        "\n",
        "However, `ResNet50` second guess (with a 29% certainty) was correct.\n",
        "\n",
        "This mis-identification nonwithstanding, I suspect `ResNet50` is still probably better at identifying dog breeds than the average person."
      ],
      "metadata": {
        "id": "qWXHzH8o8rC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Classify Retinal Image with ResNet50\n",
        "\n",
        "What about medical image data? Can `ResNet50` analyze a **color fundus photograph** of the interior surface of a human retina?\n",
        "\n",
        "Run the code in the Example 2 to see how `ResNet50` does with the following retinal image:\n",
        "\n",
        "```text\n",
        "\"Retina_Score_0.png\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "unspA6MzAzOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Classify Retinal Image with ResNEt50\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "\n",
        "# Enter image name\n",
        "image_name=\"Retina_Score_0.png\"\n",
        "\n",
        "# Generate image path\n",
        "image_path=ROOT+image_name\n",
        "\n",
        "# Print path\n",
        "print(f\"Analyzing \", image_path)\n",
        "\n",
        "# Use ResNet50 to classify image\n",
        "classify_image(image_path)"
      ],
      "metadata": {
        "id": "EizJPv3-atyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image20C.png)\n",
        "\n",
        "\n",
        "As expected, `ResNet50` was not trained to recognize retinal images. For this particular retinal image, `ResNet50` was pretty certain (84.5% probability) that this image was a lampshade. Here is an image of a lampshade that is vaguely similar:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image49C.png)\n",
        "\n",
        "**Metal Pendant Lamp Shade Retro Style Lampshade for Kitchen Dining Room water drop - Walmart.com**"
      ],
      "metadata": {
        "id": "CBP5nv_i_E8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2: Classify Retinal Image with `ResNet50`**\n",
        "\n",
        "In the cell below write the code to analyze the another retinal color fundus image:\n",
        "```text\n",
        "\"Retina_Score_1.png\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "Dvc2IU6q6gmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 2 here\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "\n",
        "# Enter image name\n",
        "image_name=\"Retina_Score_1.png\"\n",
        "\n",
        "# Generate image path\n",
        "image_path=ROOT+image_name\n",
        "\n",
        "# Print path\n",
        "print(f\"Analyzing \", image_path)\n",
        "\n",
        "# Use ResNet50 to classify image\n",
        "classify_image(image_path)"
      ],
      "metadata": {
        "id": "2wm9QvDlAzOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output:\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image21C.png)\n",
        "\n",
        "Once again, it would be charitable to say that `ResNet50` was a little weak when it comes to analyzing clinical images."
      ],
      "metadata": {
        "id": "9L694Na2AzOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning for Computer Vision**\n",
        "\n",
        "## **`ResNet`**\n",
        "\n",
        "Many advanced prebuilt neural networks are available for computer vision, and Keras provides direct access to many networks. **Transfer Learning** is the technique where you use these prebuilt neural networks.\n",
        "\n",
        "There are several different levels of transfer learning.\n",
        "\n",
        "* Use a prebuilt neural network in its entirety\n",
        "* Use a prebuilt neural network's structure\n",
        "* Use a prebuilt neural network's weights\n",
        "\n",
        "In this lesson we will use a popular prebuilt CNN called **`ResNet (Residual Network)`** built by Microsoft Research in 2015. The name comes from the fact that this network was designed to address the **vanishing gradient problem** that occurs when training very deep neural networks.\n",
        "\n",
        "Instead of learning the direct mapping from input to output, `ResNet` learns the residual (i.e., the difference between the input and the output).\n",
        "This is achieved using **skip connections** (also called shortcut connections), which allow the input to bypass one or more layers and be added directly to the output."
      ],
      "metadata": {
        "id": "wCjV86HnxkND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transfer Learning**\n",
        "\n",
        "**Transfer learning** is a machine learning technique where a model developed for one task is reused as the starting point for a model on a second task. In the context of image recognition, this approach is particularly effective when using deep convolutional neural networks (CNNs) like **`ResNet`**.\n",
        "\n",
        "### **Why Use Transfer Learning?**\n",
        "\n",
        "Training deep neural networks from scratch requires large datasets and significant computational resources. Transfer learning mitigates this by leveraging pre-trained models—typically trained on large benchmark datasets like ImageNet—to extract general features from images. These features can then be fine-tuned for a specific task with a smaller, domain-specific dataset.\n",
        "\n",
        "### **How `ResNet` Supports Transfer Learning**\n",
        "\n",
        "`ResNet` is a widely used CNN architecture known for its use of **residual connections**, which help in training very deep networks by addressing the vanishing gradient problem. Pre-trained versions of `ResNet` (e.g., `ResNet-50`, `ResNet-101`) are commonly used as feature extractors in transfer learning workflows.\n",
        "\n",
        "### **Benefits**\n",
        "\n",
        "- **Reduced Training Time**: Leverages existing learned features.\n",
        "- **Improved Performance**: Often achieves better accuracy with less data.\n",
        "- **Flexibility**: Can be adapted to a wide range of image classification tasks.\n",
        "\n",
        "Transfer learning with `ResNet` is a powerful and efficient approach for developing high-performing image recognition models, especially when data or computational resources are limited.\n"
      ],
      "metadata": {
        "id": "z9O3j51Kh6yS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3: Improving `ResNet` Classification Accuracy of Diabetic Retinopathy\n",
        "\n",
        "We know from from above that the native (base) `ResNet50` neural network is unable to effectively analyze clinical retinal images.\n",
        "\n",
        "Example 3 will demonstrate how **transfer learning** can leverage `ResNet50` as a starting point to create a new neural network that can effectively classify retinal images as to their degree of diabetic retinopathy.  \n",
        "\n",
        "#### **`Diabetic Retinopathy Image Dataset` Classes**\n",
        "\n",
        "The dataset we will be using is called the **`Diabetic Retinopathy Image Dataset`**. This image dataset consists of color fundus photographs—high‑resolution RGB images of the interior surface of the eye (the retina).\n",
        "\n",
        "These are standard clinical retinal images obtained with a fundus camera (usually a 45° or 50° field-of-view, non‑mydriatic or mydriatic camera) and capture the posterior pole (macula, optic disc, retinal vessels, and surrounding retinal tissue). The images are typically stored as JPEG/PNG files with dimensions on the order of several thousand pixels (e.g., 3500x2333 px) and are used for grading the severity of diabetic retinopathy.\n",
        "\n",
        "The severity of diabetic retinopathy was divided into **five classes** as follows:\n",
        "1. **Class 0** - No Diabetic Retinopathy (No_DR)\n",
        "2. **Class 1** - Mild Non-Proliferative Diabetic Retinopathy (NPDR)\n",
        "3. **Class 2** - Moderate NPDR\n",
        "4. **Class 3** - Severe NPDR\n",
        "5. **Class 4** - Proliferative Diabetic Retinopathy (PDR)\n",
        "\n",
        "An example of each class is shown below:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/DiabeticRetinopathyData.png)\n",
        "\n",
        "It should be noted that differences in apparent retinal size has nothing to do with the degree of retinopathy but instead reflects the fact that the retinal images were taken by a large number of clinicians, with different imaging equipment and procedures. In other words, there is considerable \"noise\" in the image set.\n",
        "\n"
      ],
      "metadata": {
        "id": "_2qSKv8AyFMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install `keras_preprocessing` Package\n",
        "\n",
        "As part of Example 3 and **Exercise 3** we need to install the Keras function `ImageDataGenerator` which is part of the Keras package `keras_preprocessing`.\n",
        "\n",
        "Run the code in the next cell to install `keras_preprocessing` and its `ImageDataGenerator`."
      ],
      "metadata": {
        "id": "nLssdpL749pZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Keras package\n",
        "\n",
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "id": "zDfZJ5064-JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image06C.png)"
      ],
      "metadata": {
        "id": "0QtItokWvZM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 1: Set ENVIRONMENTAL VARIABLES\n",
        "\n",
        "The code in the cell below defines a number of `ENVIRONMENTAL VARIABLES` that are needed for later code cells.\n",
        "\n",
        "The use of **Enivornment Variables** can allow code to be **configurable without modification**. For example, you might use different database URLs for development, testing, and production environments. As you will see later, you will re-use this code cell for **Exercise 3 - Step 1** below."
      ],
      "metadata": {
        "id": "3LFjCGJIpjat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3 - Step 1: Set ENVIRONMENTAL VARIABLES\n",
        "\n",
        "import os\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 1️⃣  Create variables for downloading loading Zip file\n",
        "# ------------------------------------------------------------------------\n",
        "URL = \"https://biologicslab.co/BIO1173/data/\"\n",
        "DOWNLOAD_SOURCE = URL+\"diabetic_retinopathy_train_244.zip\"\n",
        "DOWNLOAD_NAME = DOWNLOAD_SOURCE[DOWNLOAD_SOURCE.rfind('/')+1:]\n",
        "print(\"DOWNLOAD_SOURCE=\",DOWNLOAD_SOURCE)\n",
        "print(\"DOWNLOAD_NAME=\",DOWNLOAD_NAME)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 2️⃣  Create variables for extracting the Zip file\n",
        "# ------------------------------------------------------------------------\n",
        "PATH = \"./\"\n",
        "EXTRACT_TARGET = os.path.join(PATH,\"retinopathy_244\")\n",
        "SOURCE = os.path.join(EXTRACT_TARGET, \"train_244\")\n",
        "print(\"EXTRACT_TARGET=\",EXTRACT_TARGET)\n",
        "print(\"SOURCE=\",SOURCE)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 3️⃣  Print variables for debugging\n",
        "# ------------------------------------------------------------------------\n",
        "print(\"ENVIRONMENTAL VARIABLES were successfully created.\")"
      ],
      "metadata": {
        "id": "4D5kdxBeJeCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image08C.png)"
      ],
      "metadata": {
        "id": "97lHNy8gLTu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 2: Download and Extract Image Data\n",
        "\n",
        "The code in the cell below downloads a zip file and extracts it. The names of the file server, zip file and folders were set in above as ENVIRONMENTAL VARIABLES in the previous step.\n",
        "\n",
        "**TIME WARNING:** Even when compressed (i.e. \"zipped\"), image data file are typically quite large to download and extraction times can often take a few minutes."
      ],
      "metadata": {
        "id": "6LfOSfJZpWB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3 - Step 2: Download and Extract Data\n",
        "\n",
        "import os\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1️⃣  Create directories\n",
        "# --------------------------------------------------------------\n",
        "print(\"Creating necessary directories...\", end='')\n",
        "# Create necessary directories\n",
        "os.makedirs(SOURCE, exist_ok=True)\n",
        "os.makedirs(EXTRACT_TARGET, exist_ok=True)\n",
        "print(\"done.\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2️⃣  Download Zip file\n",
        "# --------------------------------------------------------------\n",
        "print(\"Downloading the Zip file...\", end='')\n",
        "# Define paths and URLs\n",
        "download_path = os.path.join(PATH, DOWNLOAD_NAME)\n",
        "extract_path = os.path.join(EXTRACT_TARGET, DOWNLOAD_NAME)\n",
        "# Download the file\n",
        "os.system(f\"wget -O {DOWNLOAD_NAME} {DOWNLOAD_SOURCE}\")\n",
        "print(\"done.\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3️⃣  Extract Zip file\n",
        "# --------------------------------------------------------------\n",
        "print(\"Extracting the Zip file...\", end='')\n",
        "# Extract the file\n",
        "os.system(f\"unzip -q {DOWNLOAD_NAME} -d {EXTRACT_TARGET}\")\n",
        "print(\"done.\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4️⃣  Verity Extraction was sucessful\n",
        "# --------------------------------------------------------------\n",
        "print(\"Verify Extraction\")\n",
        "!ls -l {EXTRACT_TARGET} | head"
      ],
      "metadata": {
        "id": "X0lTagzVKGtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image28C.png)\n",
        "\n",
        "**NOTE:** Unless you see this last line in the output:\n",
        "```text\n",
        "-rw-rw---- 1 root root  465317 Feb  6  2015 trainLabels.csv\n",
        "```\n",
        "it means your download and extraction has failed! As a TA or your Instructor for help."
      ],
      "metadata": {
        "id": "SSZWjAy503F8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 3: Check Image Data\n",
        "\n",
        "## Why Image Data Can Become Corrupted During File Transfers\n",
        "\n",
        "When you move an image file from one location to another—whether over a local network, the Internet, a USB stick, or a cloud storage service—many things can go wrong. Image files are just sequences of bytes; if those bytes get altered or dropped, the image will no longer render correctly. Below are the most common causes (and a few less‑common ones) of corruption.\n",
        "\n",
        "| Cause | What Happens | Why It Corrupts the Image |\n",
        "|-------|--------------|---------------------------|\n",
        "| **Packet Loss / Transmission Errors** | A packet of data disappears or is damaged in transit. | The receiver reconstructs the file without those bytes, leaving gaps or wrong values. |\n",
        "| **Missing or Extra Packets** | A packet is duplicated or omitted. | The file size becomes inconsistent, causing the image loader to misinterpret subsequent data. |\n",
        "| **Checksum/CRC Mismatch** | The integrity check fails because data changed. | The application may silently use the corrupted data instead of aborting the transfer. |\n",
        "| **Buffer Overruns / Stack Corruption** | Software writes beyond the buffer allocated for a packet. | Corrupted memory can overwrite adjacent data, including image bytes. |\n",
        "| **File System or Storage Media Errors** | Bad sectors, power failure, or faulty flash memory. | Bits stored on disk get flipped or erased. |\n",
        "| **Software Bugs in Transfer Tools** | A bug in `scp`, `rsync`, a cloud sync client, etc. | The bug can truncate or append data incorrectly. |\n",
        "| **Encoding / Compression Mismatch** | Image saved in JPEG, but the transfer tool mis‑interprets or re‑compresses it. | Loss of fidelity or structural corruption. |\n",
        "| **Inadequate or Corrupted Encryption** | Encrypted payload gets altered before decryption. | The decryption process may produce garbled data. |\n",
        "| **Version/Protocol Mismatch** | Sender uses a newer protocol that the receiver doesn’t support. | The receiver mis‑parses the data stream. |\n",
        "| **Interrupted or Partial Transfers** | Transfer is stopped by user, network timeout, or power outage. | The file ends abruptly; loaders may treat it as corrupt or display only a partial image. |\n",
        "| **Operating‑System / Driver Issues** | Disk driver misreads sectors, or OS kernel mismanages the buffer. | Low‑level corruption of stored bytes. |\n",
        "| **Malware / Intentional Tampering** | Malicious software modifies the file. | Deliberate corruption of the image data. |\n",
        "\n",
        "---\n",
        "\n",
        "## How Corruption Manifests in Images\n",
        "\n",
        "1. **Blurry or Random Noise** – Bits were flipped, causing pixels to display as wrong colors.  \n",
        "2. **Missing Sections** – Large areas are blank or show a repeated pattern (because the file was truncated).  \n",
        "3. **File Not Openable** – Image viewers complain about “file format error” or “unexpected end of file.”  \n",
        "4. **Artifacts in Specific Channels** – Only RGB or alpha channels look wrong if only part of the data is corrupted.  \n",
        "5. **Mosaic of Repeated Tiles** – The file may contain duplicate image segments (e.g., if a packet was duplicated).  \n",
        "\n",
        "---\n",
        "\n",
        "## Common Mitigation Strategies\n",
        "\n",
        "| Strategy | How It Helps |\n",
        "|----------|--------------|\n",
        "| **Use checksums (SHA‑256, MD5, CRC32)** | Verify that the file received matches the original. |\n",
        "| **Enable error‑correction (e.g., `rsync` with `--checksum`, or cloud providers that use erasure coding)** | Detect and correct lost or altered blocks. |\n",
        "| **Employ reliable protocols (TCP, SFTP, FTPS)** | TCP guarantees packet order and retransmission. |\n",
        "| **Use multipart uploads with integrity checks (AWS S3, Azure Blob)** | Each part can be verified individually. |\n",
        "| **Store backups on multiple media** | If one copy is corrupted, another may be intact. |\n",
        "| **Check disk health (SMART, surface scans)** | Prevents future storage‑related corruption. |\n",
        "| **Use versioned storage (Git LFS, cloud versioning)** | Allows rollback to a known good state. |\n",
        "| **Validate image after transfer** | Open it in a viewer, run a tool like `identify` (ImageMagick) or `exiftool`. |\n",
        "\n",
        "---\n",
        "\n",
        "### Bottom Line\n",
        "\n",
        "Image files are vulnerable to corruption at **every stage** where data moves—from the original camera capture, through storage, over a network, to the destination. The corruption usually arises from lost, duplicated, or altered **bytes**. Using proper protocols, integrity checks, and storage hygiene significantly reduces the risk, but it can never be 100 % eliminated without end‑to‑end verification.\n",
        "\n",
        "\n",
        "The code in the next cell will ckeck the data integrity of every image file."
      ],
      "metadata": {
        "id": "V3go8b88hTl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example  3 - Step 3: Check image data\n",
        "\n",
        "import os\n",
        "import io\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# Set Delete\n",
        "DELETE  = True     # set to False if you only want to *report* the bad files\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1️⃣  Utility: test a single file (exactly how ImageDataGenerator does it)\n",
        "# ------------------------------------------------------------------\n",
        "def _is_good_image(path: Path) -> bool:\n",
        "    \"\"\"Return True if Pillow can read the image, False otherwise.\"\"\"\n",
        "    try:\n",
        "        with path.open(\"rb\") as f:\n",
        "            data = f.read()\n",
        "        Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2️⃣  Scan the whole directory tree\n",
        "# ------------------------------------------------------------------\n",
        "bad_files = []\n",
        "\n",
        "for root, _dirs, files in os.walk(SOURCE):\n",
        "    for fn in files:\n",
        "        p = Path(root) / fn\n",
        "        if not _is_good_image(p):\n",
        "            bad_files.append(p)\n",
        "\n",
        "print(f\"Found {len(bad_files)} corrupt / unreadable images in {SOURCE}\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3️⃣  Delete (or rename) the bad files\n",
        "# ------------------------------------------------------------------\n",
        "if bad_files:\n",
        "    if DELETE:\n",
        "        for p in bad_files:\n",
        "            try:\n",
        "                # rename so you still have a copy you can inspect\n",
        "                backup = p.with_suffix(p.suffix + \".corrupt\")\n",
        "                p.rename(backup)\n",
        "                print(f\"  → renamed {p} → {backup}\")\n",
        "            except OSError as e:\n",
        "                print(f\"  !! could not rename {p}: {e}\")\n",
        "        print(f\"All {len(bad_files)} bad files have been renamed.\")\n",
        "    else:\n",
        "        print(\"Set DELETE=True if you want to actually delete/rename them.\")\n",
        "else:\n",
        "    print(\"No bad files to delete – you’re good to go!\")"
      ],
      "metadata": {
        "id": "6UifAeMAhUGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image29C.png)"
      ],
      "metadata": {
        "id": "v3Oikd8NKFg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 4: Load Labels for the Training Set\n",
        "\n",
        "CNNs are trained by _supervised_ learning, which means that during each training step the network's prediction must be compared to a known correct answer. The label supplies this target: it allows a loss function (e.g., cross‑entropy, IoU, etc.) to be computed, which in turn provides gradients that tell the optimizer how to adjust the weights. Without a label, the loss cannot be evaluated, no gradients can be derived, and the network has no signal to improve its predictions. Thus, labels are essential for defining the training objective and enabling the network to learn from data.\n",
        "\n",
        "The file `trainLabels.csv` contains the label information for our retinal images. This file has just two columns, **image** and **level**. The `image` specifies the image's filename and from which eye the image was obtained; for example, `10_left.png`. The `level` column contains the a numerical value between 0 and 4 which indicates the serverity of diabetic retinopathy. So in this example the **_level_** is the **image label**.\n",
        "\n",
        "The code in the cell below reads the file `trainLabels.csv` and creates a Pandas dataframe called `df_raw` to store the label information. A short amount of `df_raw` is printed out for inspection to make sure the code worked as expected."
      ],
      "metadata": {
        "id": "ksYDMhoSzVQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3 - Step 4: Load the labels for the training set\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read labels and create dataframe\n",
        "df_raw = pd.read_csv(\n",
        "        os.path.join(EXTRACT_TARGET,\"trainLabels.csv\"),\n",
        "        na_values=['NA', '?'])\n",
        "\n",
        "# Add file extention\n",
        "image_col = 'image'\n",
        "df_raw[image_col] = df_raw[image_col].astype(str) + '.png'\n",
        "\n",
        "# Print sample for verification\n",
        "df_raw"
      ],
      "metadata": {
        "id": "6Y3dlgXu15Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image04C.png)"
      ],
      "metadata": {
        "id": "Oy1q3kKwNTtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 5: Split Images into Training and Validation sets\n",
        "\n",
        "If you judge the model only on the same data you used to update its weights, you’ll get an *optimistic* estimate of its performance – the model will look perfect on the training set but will usually fail on new images.  \n",
        "Splitting the data into **training + validation** lets you:\n",
        "\n",
        "1. **Measure true generalization** - see how the network behaves on unseen samples.  \n",
        "2. **Tune hyper‑parameters** - learning rate, number of layers, data‑augmentation policies, etc.  \n",
        "3. **Detect & prevent over‑fitting** - monitor validation loss/accuracy during training and stop or adjust when the model starts to degrade.  \n",
        "4. **Select the best model** - keep the checkpoint that had the lowest validation error.  \n",
        "\n",
        "Without a validation set, you'll be blind to over-fitting, you'll have no reliable metric for early stopping, and you'll have no principled way to pick the best architecture or hyper-parameters.\n",
        "\n",
        "The code in the cell below, splits the retinal images into a training set and a validation set. How much of the train set is used for the validation set depends on the variable `FRAC`. In the cell below, `FRAC` is set to 0.8 which means 80% of the images will be put into the training set (`df_train`)and the remaining 20% will be put into the validation set (`df_val`). Which images are used in each set is randomize.\n",
        "\n",
        "The number images in both sets is printed out."
      ],
      "metadata": {
        "id": "MyRcw-DlXoNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3 - Step 5: Split images into training and validation sets\n",
        "\n",
        "# Set split fraction\n",
        "FRAC=0.8\n",
        "\n",
        "# Convert the class column to string – required for `flow_from_dataframe`\n",
        "df_raw['level'] = df_raw['level'].astype(str)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "#  1️⃣ Randomly split data into training and validation sets\n",
        "# ------------------------------------------------------------------\n",
        "df_train = df_raw.sample(frac=FRAC, random_state=42)\n",
        "df_val   = df_raw.drop(df_train.index)\n",
        "\n",
        "# Calculate the split fraction as sanity check\n",
        "split_fraction = len(df_train) / (len(df_val) + len(df_train))\n",
        "\n",
        "# Print out numbers\n",
        "print(f\"Training set size   : {len(df_train)}\")\n",
        "print(f\"Validation set size : {len(df_val)}\")\n",
        "print(f\"Calculated split fraction =\", split_fraction)\n",
        "\n",
        "# Quick sanity check\n",
        "print(\"\\nSample training rows:\")\n",
        "print(df_train[['image', 'level']].head())\n",
        "\n",
        "print(\"\\nSample validation rows:\")\n",
        "print(df_val[['image', 'level']].head())\n"
      ],
      "metadata": {
        "id": "rQug5gEpYZ24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image30C.png)"
      ],
      "metadata": {
        "id": "sF4iuKw5KpBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 6: Create Image Generator\n",
        "\n",
        "The code in the cell uses the `TensorFlow/Keras` utility `ImageDataGenerator` to creates an **Image Generator**.  \n",
        "\n",
        "**`ImageDataGenerator`** is a powerful utility in Keras that allows you to efficiently load, preprocess, and augment image data for training deep learning models. It helps improve model generalization by applying random transformations to training images, such as rotations, shifts, flips, and more.\n",
        "\n",
        "#### **Key Features**\n",
        "- **Real-time data augmentation**: Applies transformations on the fly during training.\n",
        "- **Memory efficiency**: Loads images in batches, reducing memory usage.\n",
        "- **Preprocessing**: Includes rescaling, normalization, and standardization.\n",
        "\n",
        "#### **Common Parameters**\n",
        "```python\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,              # Normalize pixel values\n",
        "    rotation_range=40,           # Random rotation\n",
        "    width_shift_range=0.2,       # Horizontal shift\n",
        "    height_shift_range=0.2,      # Vertical shift\n",
        "    shear_range=0.2,             # Shear transformation\n",
        "    zoom_range=0.2,              # Zoom in/out\n",
        "    horizontal_flip=True,        # Flip images horizontally\n",
        "    fill_mode='nearest'          # Fill in new pixels\n",
        ")\n",
        "```\n",
        "**IMPORTANT NOTE:**\n",
        "\n",
        "You need to be very careful to correctly set the **IMAGE SIZE**. This is especially true when performing transfer learning with pre-trained neural networks like `ResNet50`. `ResNet50` is designed to work with square images of exactly `244` pixels wide and `244` pixels high (i.e. `244 X 244`) that have 3 color channels (i.e. `RGB`) and no `alpha` channel.\n",
        "\n",
        "In the cell below, here is the code that specifies the image size:\n",
        "```type\n",
        "# Specify Image Size\n",
        "IMG_W, IMG_H = 244, 244\n",
        "```"
      ],
      "metadata": {
        "id": "We_gaIXnoWbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3 - Step 6: Create image generator\n",
        "\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# Specify Image Size\n",
        "IMG_W, IMG_H = 244, 244\n",
        "\n",
        "BATCH_TRAIN  = 32\n",
        "BATCH_VAL    = 32\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 1️⃣ Training generator – augmentations\n",
        "# --------------------------------------------------------------------\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,  # for *ResNet* pre‑proc\n",
        "    width_shift_range=0.2,       # Horizontal shift\n",
        "    height_shift_range=0.2,      # Vertical shift\n",
        "    horizontal_flip=True,        # Flip images horizontally\n",
        "    zoom_range=0.2,              # Zoom in/out\n",
        "    fill_mode='nearest',         # Fill in new pixels\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    dataframe=df_train,\n",
        "    directory=str(SOURCE),\n",
        "    x_col='image',          # column that holds the file name\n",
        "    y_col='level',          # column that holds the class string\n",
        "    target_size=(IMG_H, IMG_W),\n",
        "    batch_size=BATCH_TRAIN,\n",
        "    class_mode='categorical',   # one‑hot (shape (batch, 5))\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 2️⃣ Validation generator -- no augmentation\n",
        "# --------------------------------------------------------------------\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "val_gen = val_datagen.flow_from_dataframe(\n",
        "    dataframe=df_val,\n",
        "    directory=str(SOURCE),\n",
        "    x_col='image',\n",
        "    y_col='level',\n",
        "    target_size=(IMG_H, IMG_W),\n",
        "    batch_size=BATCH_VAL,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Sanity Check\n",
        "x_train, y_train = next(train_gen)\n",
        "x_val,   y_val   = next(val_gen)\n",
        "\n",
        "print(\"TRAIN batch  : \", x_train.shape, y_train.shape)   # should be (32, 244, 244, 3) , (32, 5)\n",
        "print(\"VAL   batch  : \", x_val.shape,   y_val.shape)     # same, but 32 samples if 7025>batch\n"
      ],
      "metadata": {
        "id": "IlfeePBlL8Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image31C.png)"
      ],
      "metadata": {
        "id": "VV9ozYJQLDMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 7: Check Class Distribution\n",
        "\n",
        "The code in the cell below generates a histogram showing the distribution of the 5 classes in the validation data set.\n",
        "\n",
        "#### **Why Check Class Distribution in CNN Classification?**\n",
        "\n",
        "\n",
        "When training a Convolutional Neural Network (CNN) for image classification, examining the distribution of classes in your dataset helps ensure that your model learns effectively and generalizes well. Here's why it's important:\n",
        "\n",
        "#### **1. Detecting Class Imbalance**\n",
        "If one class has significantly more samples than others, the model may become biased toward predicting the majority class. This can lead to:\n",
        "- High accuracy but poor performance on minority classes.\n",
        "- Misleading evaluation metrics.\n",
        "\n",
        "#### **2. Choosing the Right Metrics**\n",
        "In imbalanced datasets, accuracy alone is not a reliable metric. You may need to use:\n",
        "- Precision, recall, F1-score\n",
        "- Confusion matrix\n",
        "- ROC-AUC (for binary classification)\n",
        "\n",
        "#### **3. Designing Better Validation Strategies**\n",
        "Knowing the class distribution helps in:\n",
        "- Stratified sampling for train/test splits\n",
        "- Ensuring each class is represented in validation and test sets\n",
        "\n",
        "#### **4. Applying Corrective Techniques**\n",
        "If imbalance is detected, you can apply:\n",
        "- **Data augmentation** for minority classes\n",
        "- **Class weighting** in the loss function\n",
        "- **Oversampling** or **undersampling**\n",
        "- **Synthetic data generation** (e.g., SMOTE)\n",
        "\n",
        "#### **5. Improving Interpretability**\n",
        "Understanding class distribution helps interpret model behavior and debug issues like:\n",
        "- Why the model is misclassifying certain classes\n",
        "- Why training loss is low but validation performance is poor\n",
        "\n",
        "\n",
        "### ✅ **Best Practice**\n",
        "Always visualize class distribution before training using a bar chart or value counts.\n",
        "\n",
        "Following **Best Practice**, the code in the cell below generates a bar chart showing the class distribution before we start our training."
      ],
      "metadata": {
        "id": "-gh7tqrUXn8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3 - Step 7: Check Class Distribution\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count class distribution\n",
        "val_labels = val_gen.classes\n",
        "class_counts = np.bincount(val_labels)\n",
        "\n",
        "# Plot distribution\n",
        "plt.bar(range(len(class_counts)), class_counts)\n",
        "plt.xlabel(\"Class Index\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.title(\"Validation Set Class Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JtpEnRwuPtar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image32C.png)\n",
        "\n",
        "The classes are clearly **NOT** balanced! Healthy retinal images (Class `0`) vastly out number the other classes. Unfortunately this situation is quite common in medical imaging of pathological states. The problem is that our neural network model can quickly learn that it picks `0` as the image label, it will be correct _most_ of the time.  "
      ],
      "metadata": {
        "id": "xXzm6mpsLfaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 8: Setup and Compile Neural Network\n",
        "\n",
        "The code in the cell below demonstrates how to use **transfer learning** with the **ResNet50** architecture for a custom image classification task involving 5 classes (i.e. degrees of diabetic retinopathy).\n",
        "\n",
        "#### **What It Does**\n",
        "\n",
        "- **Loads a pretrained `ResNet50 model`** (trained on ImageNet) without its top classification layer.\n",
        "- **Freezes the base model's weights** to retain learned features and prevent them from being updated during training.\n",
        "- **Adds custom layers** on top of the base model:\n",
        "  - Global average pooling to reduce spatial dimensions.\n",
        "  - Dense layer with ReLU activation for learning task-specific features.\n",
        "  - Dropout for regularization to prevent overfitting.\n",
        "  - Final softmax layer for multi-class classification (5 classes).\n",
        "- **Compiles the model** using the `Adam optimizer` and `categorical crossentropy loss`, suitable for multi-class classification.\n",
        "\n",
        "#### **Use Case**\n",
        "\n",
        "This approach is ideal when:\n",
        "- You have limited training data.\n",
        "- You want to leverage powerful pretrained models.\n",
        "- You need to adapt a general-purpose model to a specific classification task.\n",
        "\n",
        "The code in the cell first generates a `base` model from `ResNet50`. It then modifies this base by adding several input layers and an output layer that are tailored to meet our specific use. The finished model called `ResNet50_model_244`. Once out model `ResNet50_model_244` is assembled, it is compiled with the appropiate optimizer (`Adam`), loss function (`categorical_crossentropy`) and metric (`accuracy`) for a _classification_ neural network."
      ],
      "metadata": {
        "id": "5bK4Z_Xigj5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Example 3 - Step 8: Setup and compile neural network\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "base = ResNet50(weights='imagenet', include_top=False, input_shape=(244, 244, 3))\n",
        "base.trainable = False          # keep the pretrained weights frozen\n",
        "\n",
        "x = base.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predictions = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "ResNet50_model_244 = models.Model(inputs=base.input, outputs=predictions)\n",
        "ResNet50_model_244.compile(optimizer=optimizers.Adam(1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ARASBgmmglHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image33C.png)"
      ],
      "metadata": {
        "id": "dy1wH-0ML_qT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 9: Train Neural Network\n",
        "\n",
        "The code in the cell below trains the neural network `ResNet50_model_244` for the number of epochs specified by the variable `EPOCHS`. A second variable, `PATIENCE`, controls the Early Stopping monitor. To keep training time reasonable the variable EPOCH has been set to 10 and the variable PATIENCE has been set to 3.\n",
        "\n",
        "**TIME WARNING!**\n",
        "\n",
        "We are analyzing a **LARGE** image dataset so training will take time. Even using Google fastest GPU hardware acceleration, it will probably take more than **1 hour to complete**. So don't start training if you can't afford to wait.\n",
        "\n",
        "**DON'T WASTE YOUR MONEY WARNING!**\n",
        "\n",
        "To get feedback on how long the training takes, the code contains a \"timer function\". Specifically, the last line of code reads:\n",
        "```text\n",
        "print(f\"Elapsed time: {hms_string(elapsed_time)}\")\n",
        "```\n",
        "This code snippet prints out how long the training required.\n",
        "\n",
        "If you weren't careful and skipped over running the cell that defined the custom function `hms_string()` at the start of this lesson, your model will train for an hour but then **FAIL** with an error message.\n",
        "\n",
        "Since every time you use a COLAB GPU **costs you money**, don't waste your time and _money_ by running this code cell if you didn't run _all_ of the code cells above before you run the next one.\n",
        "\n",
        "**You have been warned.**"
      ],
      "metadata": {
        "id": "Zqiz6uT7Psx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Example 3 - Step 8: Train neural network\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set number of epochs\n",
        "EPOCHS=10\n",
        "\n",
        "# Set Patience\n",
        "PATIENCE=3\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 1️⃣  Start training\n",
        "# ------------------------------------------------------------------------\n",
        "print(f\"-- Training (classification) is starting for {EPOCHS} epochs----------------------------\")\n",
        "start_time = time.time()\n",
        "history_244 = ResNet50_model_244.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=len(train_gen),\n",
        "    validation_steps=len(val_gen),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Record end time\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Print elapsed time\n",
        "print(f\"Elapsed time: {hms_string(elapsed_time)}\")"
      ],
      "metadata": {
        "id": "Njg5JHXrg3lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image35C.png)\n",
        "\n",
        "With COLABs best GPU accerator (`A100`) training for 10 epochs require a little over one hour to complete.\n",
        "\n",
        "If you tried to train this model using just a CPU without GPU hardware acceleration, it would take more than 6 hours to complete 10 epochs!"
      ],
      "metadata": {
        "id": "3FRIhXrVyrJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------\n",
        "\n",
        "### **What the training output tells you**\n",
        "\n",
        "Here is an itemtize explaination of each item is the particular line of training output:\n",
        "```text\n",
        "Epoch 4/10\n",
        "879/879 ━━━━━━━━ 396s 451ms/step - accuracy: 0.9237 - loss: 0.2092 - val_accuracy: 0.7089 - val_loss: 0.9596\n",
        "```\n",
        "\n",
        "* **Epoch 4/10** - You are currently in the 4th epoch out of a 10-Epoch training session.\n",
        "\n",
        "* **879/879** - 879 **batches** were processed in this epoch.\n",
        "\n",
        "There are **28101** images in the training set and we have set the batch size = 32. If we divide the 28,191 images into 32 batches, the model will have process **879** images in each batch to see all of the training images.\n",
        "\n",
        "* **381s** - Total time for the epoch to complete in seconds (~6 1/2 minutes).\n",
        "\n",
        "* **451ms/step** - Average time per batch in milliseconds (~ 1/2 second).\n",
        "\n",
        "* **accuracy: 0.9237** - The accuracy of the model for classifying **_training_** images during this epoch.\n",
        "\n",
        "* **loss: 0.2092** - The training loss for this epoch\n",
        "\n",
        "* **val_accuracy: 0.7089** - The accuracy of the model in classifying **_validation_** images during this epoch\n",
        "\n",
        "* **val_loss: 9596** - The validation loss for this epoch.\n",
        "---------------------"
      ],
      "metadata": {
        "id": "_LHZrtb8KFUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 10: Plot Training/Validation Accuracy\n",
        "\n",
        "A **Training-versus-Validation Accuracy Plot** provides a quick visual gauge of how well a model is learning and generalising. As training progresses, a rising training accuracy shows that the model is fitting the data, while the validation accuracy tracks performance on unseen samples.\n",
        "\n",
        "When both curves rise together and plateau, the model is likely well-balanced. If training accuracy climbs while validation accuracy lags or dips, the model is over-fitting; conversely, if both stay low, the model is under-fitting or too simple.\n",
        "\n",
        "The shape of the curves also reveals training issues—sharp jumps or oscillations can signal an inappropriate learning rate, and noisy validation performance may indicate label noise or class imbalance. Thus, the plot informs decisions about early stopping, regularisation, architecture changes, or hyper-parameter tuning.\n",
        "\n",
        "\n",
        "#### **Interpreting Common Patterns**\n",
        "\n",
        "| Curve Shape | Interpretation | Suggested Action |\n",
        "|-------------|----------------|------------------|\n",
        "| **Both curves rise together and plateau at high accuracy** | Good fit & generalisation. | Continue training if you want to squeeze a bit more. |\n",
        "| **Training rises, validation rises then drops** | Over‑fitting. | Add regularisation, dropout, data augmentation, or stop early. |\n",
        "| **Both curves rise slowly and stay low** | Under‑fitting. | Increase model capacity, train longer, or reduce regularisation. |\n",
        "| **Validation lags behind training by a fixed margin, but both improve** | Model learns but generalises less well. | Consider a larger training set, better augmentation, or a different architecture. |\n",
        "| **Validation fluctuates wildly** | High variance due to small batch or high learning rate. | Reduce learning rate, increase batch size, or use a learning‑rate scheduler. |\n",
        "\n"
      ],
      "metadata": {
        "id": "2ORsbZqckdC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example 3 = Step 10:\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Pull the metrics\n",
        "val_acc = history_244.history.get('val_accuracy')\n",
        "train_acc = history_244.history.get('accuracy')\n",
        "\n",
        "# --- Find the epoch with the highest validation accuracy -------------\n",
        "# np.argmax returns the index (0‑based). Add 1 if you want to show it as \"epoch 1, 2, …\"\n",
        "best_epoch_idx = np.argmax(val_acc)          # 0‑based index\n",
        "best_epoch_num = best_epoch_idx + 1          # 1‑based for display\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(val_acc, label='val_accuracy')\n",
        "plt.plot(train_acc, label='accuracy')\n",
        "\n",
        "# Vertical line at the best epoch (0‑based index)\n",
        "plt.axvline(best_epoch_idx, color='r', linestyle='--',\n",
        "            label=f'Best epoch (epoch {best_epoch_num})')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training / Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Optional: annotate the exact accuracy value at the best epoch\n",
        "best_val_acc = val_acc[best_epoch_idx]\n",
        "plt.text(best_epoch_idx, best_val_acc,\n",
        "         f'{best_val_acc:.4f}',\n",
        "         va='bottom', ha='right', color='r', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "zziMTssvVoWj",
        "outputId": "155e82f4-5e4f-43b7-e8c4-529b7c991fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image50C.png)\n",
        "\n",
        "alternatively, it might look more similar to this one\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image55C.png)\n",
        "\n",
        "Either graph is acceptable.\n"
      ],
      "metadata": {
        "id": "1jADKuEQrDei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3 - Step 11: Save Model to GDrive\n",
        "\n",
        "Run the next cell to save your retrained `ResNet50_model_244` model to your GDrive."
      ],
      "metadata": {
        "id": "3M2meHM83wzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1️⃣  Mount Google Drive (do this only once per session)\n",
        "# --------------------------------------------------------------\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2️⃣  Define the names / paths\n",
        "# --------------------------------------------------------------\n",
        "model_name     = \"ResNet50_model_244\"                    # model object name\n",
        "gdrive_dir     = f\"/content/drive/My Drive/{model_name}\"  # folder on Drive\n",
        "gdrive_file    = f\"{gdrive_dir}.keras\"                    # the file we want to keep\n",
        "\n",
        "local_dir      = f\"/content/{model_name}\"                 # the *local* folder you want to delete\n",
        "local_file     = f\"{local_dir}.keras\"                     # if you saved a single file locally\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3️⃣  Make sure the Drive folder exists\n",
        "# --------------------------------------------------------------\n",
        "os.makedirs(gdrive_dir, exist_ok=True)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4️⃣  Save the model *on* Drive (kept forever)\n",
        "# --------------------------------------------------------------\n",
        "ResNet50_model_244.save(gdrive_file)   # <-- this writes the file into /content/drive/My Drive/\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5️⃣  OPTIONAL: Verify the Drive copy exists\n",
        "# --------------------------------------------------------------\n",
        "print(\"Drive copy present:\", os.path.exists(gdrive_file))\n",
        "!ls ./drive/MyDrive"
      ],
      "metadata": {
        "id": "haZzQ6UUBwP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image54C.png)"
      ],
      "metadata": {
        "id": "ibbgwTSACd1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------\n",
        "\n",
        "\n",
        "# **EXERCISE 3**\n",
        "\n",
        "In **Exercise 3** you are going to re-analyze the Diabetic Retinopathy data set using `ResNet101` in conjunction with larger retinal images that are 512 X 512 pixels.\n",
        "\n",
        "**`ResNet-101`** was built to give a **deeper**, **larger-receptive-field** backbone that can be trained stably thanks to residual connections. That extra depth—and the corresponding increase in receptive field and representational capacity—makes the network particularly suited to the high-resolution, high-complexity images that dominate modern clinical imaging datasets (e.g., whole-slide pathology, high‑res CT/MRI, retinal photographs).  \n",
        "\n",
        "#### **1. Depth matters for large, complex images**\n",
        "\n",
        "| Aspect                       | Why it matters in clinical imaging                                                                                     |\n",
        "|------------------------------|------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Receptive field**         | • Deeper network ⇒ larger receptive field.<br>• Captures micro‑details (nuclei, capillaries) *and* macro‑context (lobule shape). |\n",
        "| **Hierarchical feature extraction** | • Early layers learn edges & textures.<br>• Deeper layers combine them into complex motifs.<br>• Needed for multi‑level abstraction (malignant vs. normal). |\n",
        "| **Parameter efficiency**    | • Residual blocks add depth without exploding the number of weights.<br>• 101‑layer stack packs more power while staying manageable. |\n",
        "\n",
        "\n",
        "#### **2. Residual connections: the training engine that makes depth feasible**\n",
        "\n",
        "* **Vanishing / exploding gradients** are especially problematic when you try to back‑propagate through dozens of nonlinear layers. Residual connections add a *shortcut* that lets the gradient flow almost unchanged from the output back to the input, so deeper models can be trained from scratch (or fine‑tuned on a new domain) without catastrophic loss of signal.\n",
        "* In medical-image research, practitioners often *fine-tune* ImageNet‑pretrained models on limited clinical data. Because residual connections preserve gradient flow, a 101‑layer network can be adapted with fewer epochs and fewer data points than a comparable plain CNN.\n",
        "\n",
        "#### **3. ResNet‑101 and typical clinical datasets**\n",
        "\n",
        "| Dataset type              | Typical image size                                    | Typical complexity                                   | ResNet‑101 benefits                                                                                                                                                 |\n",
        "|---------------------------|-------------------------------------------------------|-------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Whole‑slide pathology     | 10k‑40k px × 10k‑40k px (usually tiled to 512×512)   | Ultra‑fine texture + large‑scale architecture        | • Deep residual layers capture both micro‑ and macro‑features.<br>• Receptive field ≈ 400 px after 5 stages                                                      |\n",
        "| Chest CT                  | 512×512 or larger                                    | Subtle texture changes, large organs                 | • Deeper encoder gives more context for slice‑to‑slice variation                                                                                                      |\n",
        "| Retinal fundus            | 5000×5000 px (often cropped to 1024×1024)            | Fine vascular patterns + large vessels               | • Extra depth boosts sensitivity to minute capillary changes                                                                         \n",
        "> **Bottom line**: ResNet‑101 was *not* invented *solely* for medical imaging, but its architectural traits (depth, residual links, large receptive field) make it a natural fit for the high‑resolution, highly variable images found in clinical datasets.\n",
        "\n",
        "#### **4. Practical use-cases that illustrate the point**\n",
        "\n",
        "1. **Whole‑slide analysis**  \n",
        "   *U‑Net + ResNet‑101 encoder* is the standard backbone for segmentation of tumor vs. normal tissue. The encoder’s depth allows the network to produce rich multi‑scale feature maps that are essential for accurate boundary delineation.\n",
        "\n",
        "2. **Histopathology classification**  \n",
        "   A 101‑layer residual network fine‑tuned on 2048×2048 patches yields a 2‑fold improvement in AUC over a 50‑layer variant, especially on datasets where subtle nuclear pleomorphism is the key discriminant.\n",
        "\n",
        "3. **Radiology reporting**  \n",
        "   ResNet‑101 pre‑trained on ImageNet is used as the feature extractor for a downstream transformer that produces radiology reports. The larger depth improves the semantic quality of the extracted features, translating into more coherent, clinically relevant reports.\n",
        "\n",
        "#### **5. What the “larger image size” means**\n",
        "\n",
        "When people say ResNet‑101 was created “in part to analyze larger image sizes,” they're really referring to two intertwined design goals:\n",
        "\n",
        "1. **Scale-aware receptive fields** - As the input resolution grows, the network’s receptive field must grow proportionally so that each unit still sees a meaningful portion of the image. Deeper networks naturally achieve this.\n",
        "\n",
        "2. **Robust training** - High-resolution images contain many more pixels, which can amplify the effects of noise, small mis-alignments, or class imbalance. Residual learning keeps gradients stable, allowing the model to learn meaningful patterns from a massive pixel set without **over-fitting** or getting stuck.\n",
        "\n",
        "---\n",
        "\n",
        "#### **TL;DR**\n",
        "\n",
        "ResNet‑101’s 101 layers give it a large receptive field and the capacity to learn complex, hierarchical features, which is vital for interpreting the fine‑grained details and global context in large medical images. Residual connections make training such a deep network feasible, allowing it to be fine‑tuned on the often limited clinical datasets that are typical in healthcare. That combination is why the architecture was chosen, and later adopted, for many high‑resolution clinical image‑analysis tasks.\n",
        "\n",
        "#### **Image Size Comparison**\n",
        "\n",
        "You should realize that `512×512×3` image is more than **4X larger** than a `244×244×3` image. Here's the math:\n",
        "\n",
        "\\begin{aligned}\n",
        "512 \\times 512 \\times 3 &= 786{,}432 \\\\\n",
        "244 \\times 244 \\times 3 &= 178{,}608 \\\\\n",
        "\\frac{786{,}432}{178{,}608} &\\approx 4.4\n",
        "\\end{aligned}\n",
        "\n",
        "\n",
        "So, the **512x512x3** image is approximately **4.4 times larger** than the **244×244×3** image in terms of pixel data."
      ],
      "metadata": {
        "id": "SofmEo6JmCZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 1: Set ENVIRONMENTAL VARIABLES**\n",
        "\n",
        "In the cell below write the code to define a your `ENVIRONMENTAL VARIABLES`. It is important to make the all of the following changes exactly as suggested.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. Change this line of code\n",
        "```text\n",
        "DOWNLOAD_SOURCE = URL+\"diabetic_retinopathy_train_244.zip\"\n",
        "```\n",
        "to read\n",
        "```text\n",
        "DOWNLOAD_SOURCE = URL+\"diabetic_retinopathy_train_512.zip\"\n",
        "```\n",
        "2. Change this line of code\n",
        "```text\n",
        "EXTRACT_TARGET = os.path.join(PATH,\"retinopathy_244\")\n",
        "```\n",
        "to read\n",
        "```text\n",
        "EXTRACT_TARGET = os.path.join(PATH,\"retinopathy_512\")\n",
        "```\n",
        "3. Change this line of code\n",
        "```text\n",
        "SOURCE = os.path.join(EXTRACT_TARGET, \"train_244\")\n",
        "```\n",
        "to read\n",
        "```text\n",
        "SOURCE = os.path.join(EXTRACT_TARGET, \"train_512\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "EyqunLqtmQLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 1 here\n",
        "\n",
        "import os\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 1️⃣  Create variables for downloading loading Zip file\n",
        "# ------------------------------------------------------------------------\n",
        "URL = \"https://biologicslab.co/BIO1173/data/\"\n",
        "DOWNLOAD_SOURCE = URL+\"diabetic_retinopathy_train_512.zip\"\n",
        "DOWNLOAD_NAME = DOWNLOAD_SOURCE[DOWNLOAD_SOURCE.rfind('/')+1:]\n",
        "print(\"DOWNLOAD_SOURCE=\",DOWNLOAD_SOURCE)\n",
        "print(\"DOWNLOAD_NAME=\",DOWNLOAD_NAME)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 2️⃣  Create variables for extracting the Zip file\n",
        "# ------------------------------------------------------------------------\n",
        "PATH = \"./\"\n",
        "EXTRACT_TARGET = os.path.join(PATH,\"retinopathy_512\")\n",
        "SOURCE = os.path.join(EXTRACT_TARGET, \"train_512\")\n",
        "print(\"EXTRACT_TARGET=\",EXTRACT_TARGET)\n",
        "print(\"SOURCE=\",SOURCE)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 3️⃣  Print variables for debugging\n",
        "# ------------------------------------------------------------------------\n",
        "print(\"ENVIRONMENTAL VARIABLES were successfully created.\")"
      ],
      "metadata": {
        "id": "FTJS3d5tmQLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image37C.png)"
      ],
      "metadata": {
        "id": "Z7ehx51EmQLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 2: Download and Extract Image Data**\n",
        "\n",
        "In the cell below write the code to (1) create the necessary directories, (2) download the Zip file containing the image data, (3) extract this data into the appropiate folder and (4) verify the sucess\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "You can re-use the code in Example 3 - Step 2 _without_ making any code changes.\n",
        "\n",
        "**TIME WARNING:** This Zip file is _substantially_ larger than the one you downloaded in Example 3. You can expect it to take approximately **7 minutes** to download and unzip the image files."
      ],
      "metadata": {
        "id": "owF95gW0mQLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 2 here\n",
        "\n",
        "import os\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1️⃣  Create directories\n",
        "# --------------------------------------------------------------\n",
        "print(\"Creating necessary directories...\", end='')\n",
        "# Create necessary directories\n",
        "os.makedirs(SOURCE, exist_ok=True)\n",
        "os.makedirs(EXTRACT_TARGET, exist_ok=True)\n",
        "print(\"done.\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2️⃣  Download Zip file\n",
        "# --------------------------------------------------------------\n",
        "print(\"Downloading the Zip file...\", end='')\n",
        "# Define paths and URLs\n",
        "download_path = os.path.join(PATH, DOWNLOAD_NAME)\n",
        "extract_path = os.path.join(EXTRACT_TARGET, DOWNLOAD_NAME)\n",
        "# Download the file\n",
        "os.system(f\"wget -O {DOWNLOAD_NAME} {DOWNLOAD_SOURCE}\")\n",
        "print(\"done.\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3️⃣  Extract Zip file\n",
        "# --------------------------------------------------------------\n",
        "print(\"Extracting the Zip file...\", end='')\n",
        "# Extract the file\n",
        "os.system(f\"unzip -q {DOWNLOAD_NAME} -d {EXTRACT_TARGET}\")\n",
        "print(\"done.\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4️⃣  Verity Extraction was successful\n",
        "# --------------------------------------------------------------\n",
        "print(\"Verify Extraction\")\n",
        "!ls -l {EXTRACT_TARGET} | head"
      ],
      "metadata": {
        "id": "AErrPkd7mQLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image38C.png)\n",
        "\n",
        "If you don't see the last line\n",
        "```text\n",
        "-rw-rw---- 1 root root  465317 Feb  6  2015 trainLabels.csv\n",
        "```\n",
        "it means your download and/or unzipping has failed. You need to fix your problem before you can continue."
      ],
      "metadata": {
        "id": "LX3hmd-omQLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 3: Check Image Data**\n",
        "\n",
        "In the cell below write the code to check the images that you downloaded in **Step 2**.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "You do **no**t need to modify any of the code from Example 3 - Step 3."
      ],
      "metadata": {
        "id": "-6wK_ScDmQLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 3 here\n",
        "\n",
        "import os\n",
        "import io\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# Set Delete\n",
        "DELETE  = True     # set to False if you only want to *report* the bad files\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1️⃣  Utility: test a single file (exactly how ImageDataGenerator does it)\n",
        "# ------------------------------------------------------------------\n",
        "def _is_good_image(path: Path) -> bool:\n",
        "    \"\"\"Return True if Pillow can read the image, False otherwise.\"\"\"\n",
        "    try:\n",
        "        with path.open(\"rb\") as f:\n",
        "            data = f.read()\n",
        "        Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2️⃣  Scan the whole directory tree\n",
        "# ------------------------------------------------------------------\n",
        "bad_files = []\n",
        "\n",
        "for root, _dirs, files in os.walk(SOURCE):\n",
        "    for fn in files:\n",
        "        p = Path(root) / fn\n",
        "        if not _is_good_image(p):\n",
        "            bad_files.append(p)\n",
        "\n",
        "print(f\"Found {len(bad_files)} corrupt / unreadable images in {SOURCE}\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3️⃣  Delete (or rename) the bad files\n",
        "# ------------------------------------------------------------------\n",
        "if bad_files:\n",
        "    if DELETE:\n",
        "        for p in bad_files:\n",
        "            try:\n",
        "                # rename so you still have a copy you can inspect\n",
        "                backup = p.with_suffix(p.suffix + \".corrupt\")\n",
        "                p.rename(backup)\n",
        "                print(f\"  → renamed {p} → {backup}\")\n",
        "            except OSError as e:\n",
        "                print(f\"  !! could not rename {p}: {e}\")\n",
        "        print(f\"All {len(bad_files)} bad files have been renamed.\")\n",
        "    else:\n",
        "        print(\"Set DELETE=True if you want to actually delete/rename them.\")\n",
        "else:\n",
        "    print(\"No bad files to delete – you’re good to go!\")"
      ],
      "metadata": {
        "id": "z1Owa1bMPAQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image39C.png)"
      ],
      "metadata": {
        "id": "AvRLDWEp3ieF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 4: Load Labels for the Training Set**\n",
        "\n",
        "In the cell below write the code to extract the label information from the file `trainLabel.csv` located in your `./retinopathy_512` folder and create a DataFrame called `df_raw`.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "You do **no**t need to modify any of the code from Example 3 - Step 4."
      ],
      "metadata": {
        "id": "69raKQFgmQLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 4 here\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read labels and create dataframe\n",
        "df_raw = pd.read_csv(\n",
        "        os.path.join(EXTRACT_TARGET,\"trainLabels.csv\"),\n",
        "        na_values=['NA', '?'])\n",
        "\n",
        "# Add file extention\n",
        "image_col = 'image'\n",
        "df_raw[image_col] = df_raw[image_col].astype(str) + '.png'\n",
        "\n",
        "# Print sample for verification\n",
        "df_raw"
      ],
      "metadata": {
        "id": "fpmGEfHEmQLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image40C.png)"
      ],
      "metadata": {
        "id": "lkYpMY5MmQLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 5: Split Images into Training and Validation Sets**\n",
        "\n",
        "In the cell below write the code to split your retinal images into a training set and a validation set, with 80% of the images going into the training set. After splitting, print out the number images in both sets and a short sample of both the training set and the validation set.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "You do **no**t need to modify any of the code from Example 3 - Step 5."
      ],
      "metadata": {
        "id": "Z9FsUIsDmQLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 5 here\n",
        "\n",
        "# Set split fraction\n",
        "FRAC=0.8\n",
        "\n",
        "# Convert the class column to string – required for `flow_from_dataframe`\n",
        "df_raw['level'] = df_raw['level'].astype(str)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "df_train = df_raw.sample(frac=FRAC, random_state=42)\n",
        "df_val   = df_raw.drop(df_train.index)\n",
        "\n",
        "# Calculate the split fraction as sanity check\n",
        "split_fraction = len(df_train) / (len(df_val) + len(df_train))\n",
        "\n",
        "# Print out numbers\n",
        "print(f\"Training set size   : {len(df_train)}\")\n",
        "print(f\"Validation set size : {len(df_val)}\")\n",
        "print(f\"Calculated split fraction =\", split_fraction)\n",
        "\n",
        "# Quick sanity check\n",
        "print(\"\\nSample training rows:\")\n",
        "print(df_train[['image', 'level']].head())\n",
        "\n",
        "print(\"\\nSample validation rows:\")\n",
        "print(df_val[['image', 'level']].head())\n"
      ],
      "metadata": {
        "id": "Nhe1zpqPmQLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image41C.png)"
      ],
      "metadata": {
        "id": "WoNzAXAA4Pez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 6: Create Image Generator**\n",
        "\n",
        "In the cell below write the code to create an Image Generator using the `Tensorflow/Keras` utility `ImageDataGenerator`.\n",
        "\n",
        "**Code Notes:**\n",
        "\n",
        "Is is _very_ important that you change your image size.\n",
        "\n",
        "Specifically you must change this code snippet:\n",
        "```text\n",
        "# Specify Image Size\n",
        "IMG_W, IMG_H = 244, 244\n",
        "```\n",
        "to be\n",
        "```text\n",
        "# Specify Image Size\n",
        "IMG_W, IMG_H = 512, 512\n",
        "```\n",
        "The main objective of **Exercise 3** is to analyze larger retinal imagee (512 X 512 pixels) to see if that will improve classification accuracy."
      ],
      "metadata": {
        "id": "nWCh6S_kmQLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 6 here\n",
        "\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# Specify Image Size\n",
        "IMG_W, IMG_H = 512, 512\n",
        "\n",
        "BATCH_TRAIN  = 32\n",
        "BATCH_VAL    = 32\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 1️⃣ Training generator – augmentations\n",
        "# --------------------------------------------------------------------\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,  # for *ResNet* pre‑proc\n",
        "    width_shift_range=0.2,       # Horizontal shift\n",
        "    height_shift_range=0.2,      # Vertical shift\n",
        "    horizontal_flip=True,        # Flip images horizontally\n",
        "    zoom_range=0.2,              # Zoom in/out\n",
        "    fill_mode='nearest',         # Fill in new pixels\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    dataframe=df_train,\n",
        "    directory=str(SOURCE),\n",
        "    x_col='image',          # column that holds the file name\n",
        "    y_col='level',          # column that holds the class string\n",
        "    target_size=(IMG_H, IMG_W),\n",
        "    batch_size=BATCH_TRAIN,\n",
        "    class_mode='categorical',   # one‑hot (shape (batch, 5))\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 2️⃣ Validation generator -- no augmentation\n",
        "# --------------------------------------------------------------------\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "val_gen = val_datagen.flow_from_dataframe(\n",
        "    dataframe=df_val,\n",
        "    directory=str(SOURCE),\n",
        "    x_col='image',\n",
        "    y_col='level',\n",
        "    target_size=(IMG_H, IMG_W),\n",
        "    batch_size=BATCH_VAL,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Sanity Check\n",
        "x_train, y_train = next(train_gen)\n",
        "x_val,   y_val   = next(val_gen)\n",
        "\n",
        "print(\"TRAIN batch  : \", x_train.shape, y_train.shape)   # should be (32, 244, 244, 3) , (32, 5)\n",
        "print(\"VAL   batch  : \", x_val.shape,   y_val.shape)     # same, but 32 samples if 7025>batch\n"
      ],
      "metadata": {
        "id": "gEnt94M3mQLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image42C.png)"
      ],
      "metadata": {
        "id": "gaCyU5oz4p_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 7: Check Class Distribution**\n",
        "\n",
        "In the cell below write the code to generate a bar graph showing the number of images in each of the 5 output classes.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "You do **no**t need to modify any of the code from Example 3 - Step 7.\n"
      ],
      "metadata": {
        "id": "Ry1JMAnfmQLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 7 here\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count class distribution\n",
        "val_labels = val_gen.classes\n",
        "class_counts = np.bincount(val_labels)\n",
        "\n",
        "# Plot distribution\n",
        "plt.bar(range(len(class_counts)), class_counts)\n",
        "plt.xlabel(\"Class Index\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.title(\"Validation Set Class Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3xWfbRnmmQLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image43C.png)"
      ],
      "metadata": {
        "id": "T9hzpBna4-MB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 8: Setup `ResNet101` Base Network**\n",
        "\n",
        "In the cell below write the code to setup your base network using `ResNet101` instead of `ResNet50`. Called your new model `ResNet101_model_512`.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. Change this line of code\n",
        "```text\n",
        "base = ResNet50(weights='imagenet', include_top=False, input_shape=(244, 244, 3))\n",
        "```\n",
        "to read\n",
        "```text\n",
        "base = ResNet101(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
        "```\n",
        "2. Change this line of code\n",
        "```text\n",
        "ResNet50_model_244 = models.Model(inputs=base.input, outputs=predictions)\n",
        "```\n",
        "to read\n",
        "```text\n",
        "ResNet101_model_512 = models.Model(inputs=base.input, outputs=predictions)\n",
        "```\n",
        "3. Change this line of code\n",
        "```text\n",
        "ResNet50_model_244.compile(optimizer=optimizers.Adam(1e-4),\n",
        "```\n",
        "to read\n",
        "```text\n",
        "ResNet101_model_512.compile(optimizer=optimizers.Adam(1e-4),\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4hsAaWRfmQLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 8 here\n",
        "\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "base = ResNet101(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
        "base.trainable = False          # keep the pretrained weights frozen\n",
        "\n",
        "x = base.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predictions = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "ResNet101_model_512 = models.Model(inputs=base.input, outputs=predictions)\n",
        "ResNet101_model_512.compile(optimizer=optimizers.Adam(1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "dJYq6DONmQLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image44C.png)"
      ],
      "metadata": {
        "id": "vMSFZmOW5k-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 9: Train Neural Network**\n",
        "\n",
        "In the cell below write the code to train your neural network `ResNet101_model_512`. Set the number of epochs to `10` and patience to `3`.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "Change this line of code\n",
        "```text\n",
        "history_244 = ResNet50_model_244.fit(\n",
        "```\n",
        "to read\n",
        "```text\n",
        "history_512 = ResNet101_model_512.fit(\n",
        "```"
      ],
      "metadata": {
        "id": "Wi1Fbo8NmQLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 9 here\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set number of epochs\n",
        "EPOCHS=10\n",
        "\n",
        "# Set Patience\n",
        "PATIENCE=3\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 1️⃣  Start training\n",
        "# ------------------------------------------------------------------------\n",
        "print(f\"-- Training (classification) is starting for {EPOCHS} epochs----------------------------\")\n",
        "start_time = time.time()\n",
        "history_512 = ResNet101_model_512.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=len(train_gen),\n",
        "    validation_steps=len(val_gen),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Record end time\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Print elapsed time\n",
        "print(f\"Elapsed time: {hms_string(elapsed_time)}\")"
      ],
      "metadata": {
        "id": "yLrkkjH5mQLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image45C.png)\n",
        "\n",
        "It should be noted that while the images in `train_512` were more than 4X larger (by pixel count) the training time was essentially the same as in Example 3 - Step 9 for the smaller 244X244 px images."
      ],
      "metadata": {
        "id": "lALh-nnSmQLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 10: Plot Training History**\n",
        "\n",
        "In the cell below write the code to plot the training history of your `ResNet101_model_512`.\n",
        "\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. Change this line of code\n",
        "```text\n",
        "val_acc = history_244.history.get('val_accuracy')\n",
        "```\n",
        "to read\n",
        "```text\n",
        "val_acc = history_512.history.get('val_accuracy')\n",
        "```\n",
        "2. Change this line of code\n",
        "```text\n",
        "train_acc = history_244.history.get('accuracy')\n",
        "```\n",
        "to read\n",
        "```text\n",
        "train_acc = history_512.history.get('accuracy')\n",
        "```\n"
      ],
      "metadata": {
        "id": "1pSv_2shmQLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Exercise 3 - Step 10 here\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Pull the metrics\n",
        "val_acc = history_512.history.get('val_accuracy')\n",
        "train_acc = history_512.history.get('accuracy')\n",
        "\n",
        "# --- Find the epoch with the highest validation accuracy -------------\n",
        "# np.argmax returns the index (0‑based). Add 1 if you want to show it as \"epoch 1, 2, …\"\n",
        "best_epoch_idx = np.argmax(val_acc)          # 0‑based index\n",
        "best_epoch_num = best_epoch_idx + 1          # 1‑based for display\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(val_acc, label='val_accuracy')\n",
        "plt.plot(train_acc, label='accuracy')\n",
        "\n",
        "# Vertical line at the best epoch (0‑based index)\n",
        "plt.axvline(best_epoch_idx, color='r', linestyle='--',\n",
        "            label=f'Best epoch (epoch {best_epoch_num})')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training / Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Optional: annotate the exact accuracy value at the best epoch\n",
        "best_val_acc = val_acc[best_epoch_idx]\n",
        "plt.text(best_epoch_idx, best_val_acc,\n",
        "         f'{best_val_acc:.4f}',\n",
        "         va='bottom', ha='right', color='r', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aFm1IkVlwue1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image51C.png)\n",
        "\n",
        "\n",
        "### **Analysis**\n",
        "\n",
        "1. **Training vs Validation Accuracy:**\n",
        "\n",
        "* Both curves show a general upward trend, indicating that the model is learning over time.\n",
        "* The training accuracy is consistently higher than the validation accuracy, which is typical and suggests the model is fitting the training data well.\n",
        "\n",
        "2. **Best Epoch at 9:**\n",
        "\n",
        "* Although the x-axis only goes up to 8, the best validation accuracy is noted at epoch 9. This might imply that the training continued beyond what's shown in the plot, or the plot is cropped.\n",
        "* The peak validation accuracy of **`0.7634`** suggests a decent generalization performance.\n",
        "\n",
        "3. **Possible Overfitting:**\n",
        "\n",
        "* If the training accuracy continues to rise while validation accuracy plateaus or drops (not fully visible here), it could indicate overfitting. However, from the visible data, the gap between training and validation accuracy is not extreme."
      ],
      "metadata": {
        "id": "OjnUgGZSRYZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 - Step 11: Save Model to GDrive**\n",
        "\n",
        "In the next cell write the code to save your `ResNet101_model_512` to your GDrive.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "Change this line of code\n",
        "```text\n",
        "model_name     = \"ResNet50_model_244\"                    # model object name\n",
        "```\n",
        "to read\n",
        "```text\n",
        "model_name     = \"ResNet101_model_512\"                    # model object name\n",
        "```"
      ],
      "metadata": {
        "id": "G9yqR3rQmQLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code for Example 3 - Step 11 here\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1️⃣  Mount Google Drive (do this only once per session)\n",
        "# --------------------------------------------------------------\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2️⃣  Define the names / paths\n",
        "# --------------------------------------------------------------\n",
        "model_name     = \"ResNet101_model_512\"                    # model object name\n",
        "gdrive_dir     = f\"/content/drive/My Drive/{model_name}\"  # folder on Drive\n",
        "gdrive_file    = f\"{gdrive_dir}.keras\"                    # the file we want to keep\n",
        "\n",
        "local_dir      = f\"/content/{model_name}\"                 # the *local* folder you want to delete\n",
        "local_file     = f\"{local_dir}.keras\"                     # if you saved a single file locally\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3️⃣  Make sure the Drive folder exists\n",
        "# --------------------------------------------------------------\n",
        "os.makedirs(gdrive_dir, exist_ok=True)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4️⃣  Save the model *on* Drive (kept forever)\n",
        "# --------------------------------------------------------------\n",
        "ResNet101_model_512.save(gdrive_file)   # <-- this writes the file into /content/drive/My Drive/\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5️⃣  OPTIONAL: Verify the Drive copy exists\n",
        "# --------------------------------------------------------------\n",
        "print(\"Drive copy present:\", os.path.exists(gdrive_file))\n",
        "!ls ./drive/MyDrive"
      ],
      "metadata": {
        "id": "dLu0bTR4TByG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the code is correct you should see something similar to the following output\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_03/class_03_2_image53C.png)\n",
        "\n",
        "Your `ResNet101_model_512` is now safely stored on your GDrive. If you wanted to you could easily copy your model back from your GDrive into you current Google COLAB directory and use it analyze new retinal fundus images, looking for signs of diabetic retinopathy.\n",
        "\n",
        "Always keep in mind a common sayings among members of the ML/AI community:\n",
        "\n",
        "> **_“Train-once, deploy-many”_**\n",
        "\n"
      ],
      "metadata": {
        "id": "IN2bqt7V_C1S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MhC_-6ebE3l"
      },
      "source": [
        "## **Lesson Turn-in**\n",
        "\n",
        "When you have completed and run all of the code cells, use the **File --> Print.. --> Save to PDF** to generate a PDF of your Colab notebook. Save your PDF as `Class_03_2.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lizard Tail**\n",
        "\n",
        "\n",
        "## **BASIC**\n",
        "\n",
        "![__](https://upload.wikimedia.org/wikipedia/commons/7/7b/AtariBASIC.png)\n",
        "\n",
        "# Introduction to BASIC Programming Language\n",
        "\n",
        "## What is BASIC?\n",
        "\n",
        "**BASIC** (Beginner's All-purpose Symbolic Instruction Code) is a high-level programming language designed to be easy to learn and use. It was created with the goal of providing access to computing power for students and non-professional programmers, emphasizing simplicity and readability.\n",
        "\n",
        "BASIC uses straightforward syntax and commands that resemble English, making it an ideal first language for beginners. Over time, it has evolved into many dialects and influenced the development of numerous other programming languages.\n",
        "\n",
        "---\n",
        "\n",
        "## Historical Summary\n",
        "\n",
        "### Origins\n",
        "\n",
        "- **Year Created**: 1964  \n",
        "- **Creators**: John G. Kemeny and Thomas E. Kurtz  \n",
        "- **Institution**: Dartmouth College\n",
        "\n",
        "Kemeny and Kurtz developed BASIC to enable students in fields other than science and mathematics to use computers. At the time, most programming languages were complex and required deep technical knowledge. BASIC was designed to democratize computing.\n",
        "\n",
        "### Key Milestones\n",
        "\n",
        "- **1964**: First implementation of BASIC on a GE-225 mainframe at Dartmouth College.\n",
        "- **1970s**: BASIC became widely adopted on microcomputers, especially with the rise of personal computing.\n",
        "- **1975**: Microsoft was founded to develop a version of BASIC (Altair BASIC) for the Altair 8800, marking the beginning of Microsoft's software empire.\n",
        "- **1980s**: Variants like GW-BASIC, QuickBASIC, and Turbo BASIC became popular on MS-DOS systems.\n",
        "- **1991**: Microsoft introduced Visual Basic, combining BASIC with a graphical user interface (GUI) development environment.\n",
        "- **2000s–Present**: Modern dialects like VB.NET continue to be used, especially in enterprise and educational settings.\n",
        "\n",
        "### Legacy\n",
        "\n",
        "BASIC played a crucial role in the early days of personal computing. It introduced millions of people to programming and laid the foundation for many modern languages. While its use has declined in favor of more powerful and flexible languages, its influence remains significant in the history of computer science.\n",
        "\n",
        "---\n",
        "\n",
        "## Example BASIC Code\n",
        "\n",
        "```basic\n",
        "10 PRINT \"HELLO, WORLD!\"\n",
        "20 END\n",
        "\n",
        "**BASIC (Beginners' All-purpose Symbolic Instruction Code)** is a family of general-purpose, high-level programming languages designed for ease of use. The original version was created by John G. Kemeny and Thomas E. Kurtz at Dartmouth College in 1963. They wanted to enable students in non-scientific fields to use computers. At the time, nearly all computers required writing custom software, which only scientists and mathematicians tended to learn.\n",
        "\n",
        "In addition to the programming language, Kemeny and Kurtz developed the Dartmouth Time-Sharing System (DTSS), which allowed multiple users to edit and run BASIC programs simultaneously on remote terminals. This general model became popular on minicomputer systems like the PDP-11 and Data General Nova in the late 1960s and early 1970s. Hewlett-Packard produced an entire computer line for this method of operation, introducing the HP2000 series in the late 1960s and continuing sales into the 1980s. Many early video games trace their history to one of these versions of BASIC.\n",
        "\n",
        "The emergence of microcomputers in the mid-1970s led to the development of multiple BASIC dialects, including Microsoft BASIC in 1975. Due to the tiny main memory available on these machines, often 4 KB, a variety of Tiny BASIC dialects were also created. BASIC was available for almost any system of the era, and became the de facto programming language for home computer systems that emerged in the late 1970s. These PCs almost always had a BASIC interpreter installed by default, often in the machine's firmware or sometimes on a ROM cartridge.\n",
        "\n",
        "BASIC declined in popularity in the 1990s, as more powerful microcomputers came to market and programming languages with advanced features (such as Pascal and C) became tenable on such computers. By then, most nontechnical personal computer users relied on pre-written applications rather than writing their own programs. In 1991, Microsoft released Visual Basic, combining an updated version of BASIC with a visual forms builder. This reignited use of the language and \"VB\" remains a major programming language in the form of VB.NET, while a hobbyist scene for BASIC more broadly continues to exist.\n",
        "\n",
        "**Origin**\n",
        "\n",
        "John G. Kemeny was the chairman of the Dartmouth College Mathematics Department. Based largely on his reputation as an innovator in math teaching, in 1959 the college won an Alfred P. Sloan Foundation award for \\$500,000 to build a new department building. Thomas E. Kurtz had joined the department in 1956, and from the 1960s Kemeny and Kurtz agreed on the need for programming literacy among students outside the traditional STEM fields. Kemeny later noted that \"Our vision was that every student on campus should have access to a computer, and any faculty member should be able to use a computer in the classroom whenever appropriate. It was as simple as that.\"\n",
        "\n",
        "Kemeny and Kurtz had made two previous experiments with simplified languages, DARSIMCO (Dartmouth Simplified Code) and DOPE (Dartmouth Oversimplified Programming Experiment). These did not progress past a single freshman class. New experiments using Fortran and ALGOL followed, but Kurtz concluded these languages were too tricky for what they desired. As Kurtz noted, Fortran had numerous oddly formed commands, notably an \"almost impossible-to-memorize convention for specifying a loop: DO 100, I = 1, 10, 2. Is it '1, 10, 2' or '1, 2, 10', and is the comma after the line number required or not?\"\n",
        "\n",
        "Moreover, the lack of any sort of immediate feedback was a key problem; the machines of the era used batch processing and took a long time to complete a run of a program. While Kurtz was visiting MIT, John McCarthy suggested that time-sharing offered a solution; a single machine could divide up its processing time among many users, giving them the illusion of having a (slow) computer to themselves.[8] Small programs would return results in a few seconds. This led to increasing interest in a system using time-sharing and a new language specifically for use by non-STEM students.\n",
        "\n",
        "Kemeny wrote the first version of BASIC. The acronym BASIC comes from the name of an unpublished paper by Thomas Kurtz.The new language was heavily patterned on FORTRAN II; statements were one-to-a-line, numbers were used to indicate the target of loops and branches, and many of the commands were similar or identical to Fortran. However, the syntax was changed wherever it could be improved. For instance, the difficult to remember DO loop was replaced by the much easier to remember FOR I = 1 TO 10 STEP 2, and the line number used in the DO was instead indicated by the NEXT I. Likewise, the cryptic IF statement of Fortran, whose syntax matched a particular instruction of the machine on which it was originally written, became the simpler IF I=5 THEN GOTO 100. These changes made the language much less idiosyncratic while still having an overall structure and feel similar to the original FORTRAN.\n",
        "\n",
        "The project received a $300,000 grant from the National Science Foundation, which was used to purchase a GE-225 computer for processing, and a Datanet-30 realtime processor to handle the Teletype Model 33 teleprinters used for input and output. A team of a dozen undergraduates worked on the project for about a year, writing both the DTSS system and the BASIC compiler. The first version BASIC language was released on 1 May 1964.\n",
        "\n",
        "Initially, BASIC concentrated on supporting straightforward mathematical work, with matrix arithmetic support from its initial implementation as a batch language, and character string functionality being added by 1965. Usage in the university rapidly expanded, requiring the main CPU to be replaced by a GE-235,[7] and still later by a GE-635. By the early 1970s there were hundreds of terminals connected to the machines at Dartmouth, some of them remotely.\n",
        "\n",
        "Wanting use of the language to become widespread, its designers made the compiler available free of charge. In the 1960s, software became a chargeable commodity; until then, it was provided without charge as a service with expensive computers, usually available only to lease. They also made it available to high schools in the Hanover, New Hampshire, area and regionally throughout New England on Teletype Model 33 and Model 35 teleprinter terminals connected to Dartmouth via dial-up phone lines, and they put considerable effort into promoting the language. In the following years, as other dialects of BASIC appeared, Kemeny and Kurtz's original BASIC dialect became known as Dartmouth BASIC.\n",
        "\n",
        "New Hampshire recognized the accomplishment in 2019 when it erected a highway historical marker in Hanover describing the creation of \"the first user-friendly programming language\"."
      ],
      "metadata": {
        "id": "Z5Xdnb5nXH1z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dYdsR4-MH9uu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}