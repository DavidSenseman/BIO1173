{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmGnq9V8SZVdCMC1awxP0U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/main/Assignment_01_Multiclass_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ],
      "metadata": {
        "id": "ZNirsAlIEuxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ],
      "metadata": {
        "id": "HhOPZPgmEus_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment 1: Neural Networks for Analysis of Tabular Data**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
        "\n"
      ],
      "metadata": {
        "id": "tS0hL9bkEum_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **READ CAREFULLY**\n",
        "\n",
        "The **_first_**  digit in your myUTSA ID (e.g. \"abc123\") will determine which dataset you are to analyze for this assignment and which type of neural network (i.e. classification or regression) you will need to construct. For example, if your myUTSA ID was **vue682**, then your first digit is the number `6`.\n",
        "\n",
        "**---WARNING------WARNING------WARNING------WARNING------WARNING------WARNING---**\n",
        "\n",
        "You are **not** free to choose any dataset for this assignment. If analyze the wrong dataset, your assignment will **NOT BE GRADED** and you will automatically receive  **`1 point`** out of 100. Since you are only allowed a single submission, you will automatically fail this assignment.\n",
        "\n",
        "If you are uncertain which dataset you should be working on, contact your Instructor for help. Remember, your score in this assignment will have a large impact on your course grade so please be careful.\n",
        "\n",
        "\n",
        "| First Digit myUTSA ID   | Dataset to Analyze     | Neural Network Type\n",
        "--------------------------|-------------------------|-----------------\n",
        "0                         | Hepatitis               | Binary Classification\n",
        "1                         | Coimbra Breast Cancer   | Binary Classification\n",
        "2                         | Parkinson Speech        | Binary Classification\n",
        "3                         | Indian Liver            | Binary Classification\n",
        "4                         | Fetal Health            | Multiclass Classification\n",
        "5                         | Dermatology             | Multiclass Classification\n",
        "6                         | Maternal Health         | Multiclass Classification\n",
        "7                         | Bone Marrow Transplant  | Regression\n",
        "8                         | German Breast Cancer    | Regression\n",
        "9                         | Diabetes Progression    | Regression\n",
        "\n",
        "#### **NOTE: You can only use this Colab notebook if the first digit of your _myUTSA_ ID  is between `4` and `6`.**"
      ],
      "metadata": {
        "id": "x0SZ0iP-EuYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Purpose of Assignments**\n",
        "\n",
        "In this course, **_Assignments_** are designed to help me (and you) assess your ability to transfer knowledge gained in completing class coding exercises to solving more realistic problems.\n",
        "\n",
        "Assignments play a pivotal role in reinforcing your learning, as they require you to apply theoretical concepts to practical scenarios. This helps solidify your understanding and enhances your problem-solving skills. By tackling these assignments independently, you develop critical thinking and the ability to synthesize information from various sources. Moreover, assignments encourage you to explore topics more deeply, fostering intellectual curiosity and promoting a deeper engagement with the subject matter. Ultimately, these assignments are not just a measure of your learning, but a means to equip you with the skills needed for real-world applications and future challenges."
      ],
      "metadata": {
        "id": "Ze8uywoTFYx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MAKE A COPY OF THIS NOTEBOOK!**\n",
        "\n",
        "For your assignment to be graded, you **must** make a copy of this Colab notebook in your Google Drive and use this copy as your worksheet."
      ],
      "metadata": {
        "id": "S5SeEYKrFcYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. By running this code cell, you will map your Google Drive to /content/drive and print out your Google GMAIL address. Your Instructor will use your GMAIL address to verify the author of this assignment."
      ],
      "metadata": {
        "id": "OZA5LczUFcvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C50uDh3DodE"
      },
      "outputs": [],
      "source": [
        "# YOU MUST RUN THIS CELL FIRST\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    Colab = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"**WARNING**: Your GMAIL address was **not** printed in the output below.\")\n",
        "    print(\"**WARNING**: You will NOT receive credit for this assignment.\")\n",
        "    Colab = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your GMAIL address **must** appear in the output in order for your work to be graded. If your GMAIL is not visible you will receive `1` point out of 100 for your grade. You will not be given a second chance to fix this problem!"
      ],
      "metadata": {
        "id": "4vxXQyP-FpAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 1: Multiclass Classification**\n",
        "\n",
        "**Assignment_01** is specifically designed to assess your ability to write the Python/Tensorflow/Keras code necessary to build neural networks that can analyze tabular data stored in a Pandas DataFrame. These analyzes include: (1) binary classification, (2) multiclass classification and (3) regression.\n",
        "\n",
        "You will use this Colab notebook **only** if the first digit in your myUTSA ID is between `4` and `6`. If that is correct, you have been assigned to perform **multiclass classification**.\n",
        "\n",
        "Unlike your class lessons, you will **not** be given examples that you can use to simply copy-and-paste code. Rather, you will be given a problem to solve and it will be up to you to use code snippets that you have been given previously to solve different aspects of this assignment. And unlike your class lessons, your will **not** be given the correct output. In other words, this assignment is basically how you would solve an actual biomedical problem.\n",
        "\n",
        "## **---AI WARNING---AI WARNING---AI WARNING---**\n",
        "\n",
        "You are **NOT** allowed to use AI anywhere in your assignment. If you use AI you will receive a grade of only **1** out of 100 for this assignment. In other words, you will fail your assignment if you use AI.\n",
        "\n",
        "If you encounter an error it probably means that you didn't read the instructions carefully. Your Instructor and TA's are here to help you fix any errors that you encounter. Don't lose a good grade in this course by using AI."
      ],
      "metadata": {
        "id": "N5vwK5mM1dp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multiclass Classification by Neural Networks**\n",
        "**Multiclass classification** of tabular data is a type of supervised learning task where the goal is to categorize observations into one of three or more possible classes based on their attributes.\n",
        "\n",
        "#### **Multiclass Classification:**\n",
        "Multiclass classification deals with problems where there are multiple possible outcomes. Examples include:\n",
        "1. **Disease Diagnosis:**\n",
        "   - What type of diabetes does the patient have? (Type 1/Type 2/Gestational)\n",
        "   - What stage is this breast tumor in? (Stage 0/Stage 1/Stage 2/Stage 3/Stage 4)\n",
        "   - What type of hypertension does the patient have? (Primary/Secondary)\n",
        "   - What variant of COVID-19 is the patient infected with? (Alpha/Beta/Delta/Omicron)\n",
        "2. **Medical Outcomes:**\n",
        "   - What is the prognosis for the patient after a heart attack? (Good/Fair/Poor)\n",
        "   - What type of response will the patient have to a specific treatment? (Positive/Negative/Neutral)\n",
        "   - What risk level does the patient have for developing heart disease? (Low/Medium/High)\n",
        "3. **Medical Conditions and Symptoms:**\n",
        "   - What type of depression is the patient experiencing? (Mild/Moderate/Severe)\n",
        "   - What severity of sleep apnea does the patient have? (Mild/Moderate/Severe)\n",
        "   - What is the patient's risk level for osteoporosis? (Low/Medium/High)\n",
        "   - What genetic condition does the patient have a predisposition for? (Condition A/Condition B/Condition C)\n",
        "4. **Medical Procedures:**\n",
        "   - What type of surgery is recommended for this patient? (Surgery A/Surgery B/Surgery C)\n",
        "   - What blood transfusion type does the patient need? (Type A/Type B/Type AB/Type O)\n",
        "   - What category does the patient fall into for a particular clinical trial? (Group 1/Group 2/Group 3)\n",
        "\n",
        "Here’s a step-by-step guide on how to perform multiclass classification using neural networks:\n",
        "#### **Data Preparation:**\n",
        "- **Collect Data:** Obtain a dataset with numerical features and a categorical target variable with multiple classes.\n",
        "- **Clean Data:** Handle missing values, outliers, and erroneous entries.\n",
        "- **Data Normalization:** Normalize your data (e.g. convert to Z-scores) to help the neural network learn more efficiently.\n",
        "- **Data Pre-Processing:** Create X- and Y-feature vectors and encode the target variable into numerical format (e.g., one-hot encoding).\n",
        "- **Split Data:** Divide your data into training and test sets.\n",
        "#### **Neural Network Model**\n",
        "- **Build the Neural Network Model:** Use TensorFlow and Keras to define the neural network architecture suitable for multiclass classification (e.g., using softmax activation in the output layer).\n",
        "- **Train the Model:** Fit the model to your training data, using the validation set to monitor performance.\n",
        "- **Evaluate the Model:** Assess the model’s performance on the test set using metrics like accuracy, precision, recall, F1-score, and Confusion Matrix:"
      ],
      "metadata": {
        "id": "LIlyrBUw1sWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Descriptions of Data Sets for Multiclass Classification**\n",
        "\n",
        "This section describes the various datasets, information for downloading them, and what variable(s) your network should predict. Remember, you do **not** earn and credit if you analyze the wrong dataset. Pay particular attention to the **output** variable, `target column`, for Multiclass Classification because this column will contain the `y- values` for your assigned dataset. You will need to know the name of the output feature when you are constructing your `X-` and `y-feature vectors`."
      ],
      "metadata": {
        "id": "2e3ndell10n0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fetal Health Classification Dataset - 1st myUTSA Digit = 4**\n",
        "\n",
        "#### **Filename:** `fetal_health.csv`\n",
        "#### **Output Variable (target column):** `fetal_health`\n",
        "\n",
        "### **Fetal Health Dataset**\n",
        "\n",
        "**Context**\n",
        "\n",
        "Reduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals and is a key indicator of human progress.\n",
        "The UN expects that by 2030, countries end preventable deaths of newborns and children under 5 years of age, with all countries aiming to reduce under‑5 mortality to at least as low as 25 per 1,000 live births.\n",
        "\n",
        "Parallel to notion of child mortality is of course maternal mortality, which accounts for **295 000 deaths** during and following pregnancy and childbirth (as of 2017). The vast majority of these deaths (94%) occurred in low-resource settings, and most **could have been prevented**.\n",
        "\n",
        "In light of what was mentioned above, **Cardiotocograms (CTGs)** are a simple and cost accessible option to assess fetal health, allowing healthcare professionals to take action in order to prevent child and maternal mortality. The equipment itself works by sending ultrasound pulses and reading its response, thus shedding light on fetal heart rate (FHR), fetal movements, uterine\n",
        "\n",
        "This dataset contains 2126 records of features extracted from Cardiotocogram exams, which were then classified by three expert obstetritians into 3 classes:\n",
        "\n",
        "* **Normal**\n",
        "* **Suspect**\n",
        "* **Pathological**\n",
        "\n",
        "#### Features:\n",
        "1. **baseline value**\n",
        "2. **accelerations**\n",
        "3. **fetal_movement**\n",
        "4. **uterine_contractions**\n",
        "5. **light_decelerations**\n",
        "6. **severe_decelerations**\n",
        "7. **prolongued_decelerations**\n",
        "8. **abnormal_short_term_variability**\n",
        "9. **mean_value_of_short_term_variability**\n",
        "10. **percentage_of_time_with_abnormal_long_term_variability**\n",
        "11. **mean_value_of_long_term_variability**\n",
        "12. **histogram_width**\n",
        "13. **histogram_min**\n",
        "14. **histogram_max**\n",
        "15. **histogram_number_of_peaks**\n",
        "16. **histogram_number_of_zeroes**\n",
        "17. **histogram_mode**\n",
        "18. **histogram_mean**\n",
        "19. **histogram_median**\n",
        "20. **histogram_variance**\n",
        "21. **histogram_tendency**\n",
        "22. **fetal_health**\n",
        "\n",
        "#### Target: (\"y values\"):\n",
        "**fetal_health** (class labels)\n",
        "* **Normal**\n",
        "* **Suspect**\n",
        "* **Pathological**\n"
      ],
      "metadata": {
        "id": "91WoI7Cb18OH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dematology Dataset - 1st myUTSA Digit = 5**\n",
        "\n",
        "#### **Filename:** `dermatology_dataset.csv`\n",
        "#### **Output Variable (target_column):** `esd_type`\n",
        "\n",
        "### **Dermatology Dataset**\n",
        "\n",
        "Aim for this dataset is to determine the type of **Eryhemato-Squamous Disease**.\n",
        "The differential diagnosis of erythemato-squamous diseases is a real problem in dermatology. They all share the clinical features of erythema and scaling, with very little differences. The diseases in this group are psoriasis, seboreic dermatitis, lichen planus, pityriasis rosea, cronic dermatitis, and pityriasis rubra pilaris. Usually a biopsy is necessary for the diagnosis but unfortunately these diseases share many histopathological features as well. Another difficulty for the differential diagnosis is that a disease may show the features of another disease at the beginning stage and may have the characteristic features at the following stages. Patients were first evaluated clinically with 12 features. Afterwards, skin samples were taken for the evaluation of 22 histopathological features. The values of the histopathological features are determined by an analysis of the samples under a microscope.\n",
        "\n",
        "In the dataset constructed for this domain, the family history feature has the value 1 if any of these diseases has been observed in the family, and 0 otherwise. The age feature simply represents the age of the patient. Every other feature (clinical and histopathological) was given a degree in the range of 0 to 3. Here, 0 indicates that the feature was not present, 3 indicates the largest amount possible, and 1, 2 indicate the relative intermediate values.\n",
        "\n",
        "#### Features:\n",
        "1. **erythema**\n",
        "2. **scaling**\n",
        "3. **definite-borders**\n",
        "4. **itching**\n",
        "5. **koebner phenomenon**\n",
        "6. **polygonal papules**\n",
        "7. **follicular papules**\n",
        "8. **oral-mucosal involvement**\n",
        "9. **knee elbow involvement**\n",
        "10. **scalp involvement**\n",
        "11. **family history**\n",
        "12. **melanin incontinence**\n",
        "13. **eosinophils in the infiltrate**\n",
        "14. **pnl infiltrate**\n",
        "15. **fibrosis of the papillary dermis**\n",
        "16. **exocytosis**\n",
        "17. **acanthosis**\n",
        "18. **hyperkeratosis**\n",
        "19. **parakeratosis**\n",
        "20. **clubbing of the rete ridges**\n",
        "21. **elongation of the rete ridges**\n",
        "22. **thinning of the suprapapillary epidermis**\n",
        "23. **spongiform pustule**\n",
        "24. **munro microabcess**\n",
        "25. **focal hypergranulosis**\n",
        "26. **disappearance of the granular layer**\n",
        "27. **vacuolisation and damage of the basal layer**\n",
        "28. **spongiosis**\n",
        "29. **saw-tooth_appearance of retes**\n",
        "30. **follicular horn plug**\n",
        "31. **perifollicular parakeratosis**\n",
        "32 **inflammatory monoluclear infiltrate**\n",
        "33. **band-like infiltrate**\n",
        "34. **age**\n",
        "\n",
        "#### Target: (y-values):\n",
        "\n",
        "**esd_type** (class labels)\n",
        "* **psoriasis**\t\t\t            \n",
        "* **seboreic dermatitis**        \n",
        "* **lichen planus**              \n",
        "* **pityriasis rosea**            \n",
        "* **cronic dermatitis**               \n",
        "* **pityriasis rubra pilaris**  \n"
      ],
      "metadata": {
        "id": "GshqhMtp16nU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Maternal Health Risk - 1st myUTSA Digit = 6**\n",
        "\n",
        "#### **Filename:** `maternal_health_risk.csv`\n",
        "#### **Output Variable (\"target column\"):** `RiskLevel`\n",
        "\n",
        "\n",
        "### **Maternal Health Risk**\n",
        "\n",
        "Data has been collected from different hospitals, community clinics, maternal health cares through the IoT based risk monitoring system.\n",
        "\n",
        "#### Features:\n",
        "1. **Age**: Age in years when a woman is pregnant.\n",
        "2. **SystolicBP**: Upper value of Blood Pressure in mmHg, another significant attribute during pregnancy.\n",
        "3. **DiastolicBP**P: Lower value of Blood Pressure in mmHg, another significant attribute during pregnancy.\n",
        "4. **BS**: Blood glucose levels is in terms of a molar concentration, mmol/L.\n",
        "4. **BodyTemp**: F\n",
        "5. **HeartRate**: A normal resting heart rate in beats per minute.\n",
        "6. **RiskLevel**: Predicted Risk Intensity Level during pregnancy\n",
        "\n",
        "#### Target: (y-values):\n",
        "**RiskLevel** (class labels)\n",
        "* **low_risk**\n",
        "* **mid_risk**\n",
        "* **high_risk**\n"
      ],
      "metadata": {
        "id": "kKi75N2k2Es1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Instructions**\n",
        "\n",
        "To make the assignment more manageable, you will given a number of specific steps to perform. To help guide you in writing your code, you will be given a specific example in a particular class lesson that you can use for a reference. For example, in **Step 1: Download and Extract Data** you are given **REF: Class_01_6: Example 1**. That means Examples 1 in `Class_01_6` provide code that you can use to complete that step of this assignment.\n",
        "\n",
        "### **Variable Names**\n",
        "\n",
        "In writing your code for this assignment, you are free to give your variables any name that makes sense to you. This includes the name of the DataFrame that holds your data. When you `copy-and-paste` code from earlier Class assignments, you always have to edit the name of the DataFrame to match the name you select for this assignment in **Step 1**.\n",
        "\n",
        "When it has been necessary to give an example that includes a DataFrame name, the DataFrame has been called simply `df` without any prefix. You will need to edit any variable names that you copy-and-paste from code examples to match the actual name you give to your DataFrame in **Step 1**.\n",
        "\n",
        "### **Can I Use AI?**\n",
        "\n",
        "**You can NOT use AI to help you complete this assignment**. If you use AI you will automatically receive a grade of `1` point (out of a possible 100 points) and you will fail this assignment. Since you are only allowed 1 submission, you will not be given a second chance. A significant pedagolical component of assignments in this course is to see if you can carefully read instructions. If you can't figure out how to solve a coding error, get help from your course Instructor and/or your course TA's."
      ],
      "metadata": {
        "id": "zglo_zTrG4d9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Custom Function\n",
        "\n",
        "The cell below creates a custom function needed for this assignment. If you don't run this cell, you will receive errors later when you try to run some cells."
      ],
      "metadata": {
        "id": "M2aQbHe5G4P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create functions for this lesson\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 0️⃣  Create hms_string()\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "# Simple function to print out elasped time\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "metadata": {
        "id": "6vuDFK-5HKg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Download and Extract Data**\n",
        "\n",
        "**REF: Class_01_6: Example 1**\n",
        "\n",
        "In the cell below, write the code to download your assigned datafile from the course server and create a `Pandas` DataFrame to store your data. Are are free to use any name for your DataFrame, just make sure to keep it consistent throughout the assignment. In this assignment the name `df` will be used for any examples given in the instructions.\n",
        "\n",
        "After you download your datafile, use the `df.head()` method to display the contents.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. When using the command `pd.read_csv()` the file separator argument `sep` will be always be a comma **`,`**, **not** a tab.\n",
        "\n",
        "2. You can **only** use the assigned dataset downloaded from the course file server https://biologicslab.co/BIO1173/data/, even if you happy to find a dataset with the same name at a different web location.\n",
        "\n",
        "**If you don't download your assigned datafile from the course file server, you will receive a score of `1` point out of 100.**\n",
        "\n",
        "3. Use this code to set your display settings:\n",
        "```text\n",
        "# Set max columns and max rows\n",
        "pd.set_option('display.max_columns', df.shape[1])\n",
        "pd.set_option('display.max_rows', 8)\n",
        "```\n"
      ],
      "metadata": {
        "id": "I8o6hPfSG301"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download and Extract Data\n",
        "\n"
      ],
      "metadata": {
        "id": "6wueN8hyIYDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct you should see a table with a relatively large number of columns that may very well extend beyond the right edge of your notebook display."
      ],
      "metadata": {
        "id": "hClhWLb8IdNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Print Summary Statistics**\n",
        "\n",
        "**REF: Class_01_6: Example 3**\n",
        "\n",
        "In the cell below use `df.describe()` to print put the summary statistics of your DataFrame.  \n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "Use this code to set your print output:\n",
        "```text\n",
        "# Set max columns and max rows\n",
        "pd.set_option('display.max_columns', 12)\n",
        "pd.set_option('display.max_rows', 8)\n",
        "```\n"
      ],
      "metadata": {
        "id": "9JXxQm3QNTPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Print summary statistics\n",
        "\n"
      ],
      "metadata": {
        "id": "zmIr8IptNsMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your output should be table showing summary statistics for each _numeric_ column in your DataFrame."
      ],
      "metadata": {
        "id": "kAgUPj80N8bV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Find Missing Values**\n",
        "\n",
        "**REF: Class_01_6: Example 4**\n",
        "\n",
        "Use `df.isnull()` to find any missing values in your DataFrame. Print out the missing locations in two vertical columns titled `column_name` and `has_missing`.  \n"
      ],
      "metadata": {
        "id": "Fs6Id0FRImr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Find missing values\n",
        "\n"
      ],
      "metadata": {
        "id": "HpF_DeydIwkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct, you should see two columns: a left column called `column_name` and a right column called `has_missing`. If the `has_missing` column has the entry `True`, it means that column has one (or more) missing datapoints. Make a careful note of the name of any column that has missing data since you will need to replace these missing datapoints in the next step."
      ],
      "metadata": {
        "id": "8DEOVMzkIzAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4: Replace Missing Values**\n",
        "\n",
        "**REF: Class_01_6: Example 5**\n",
        "\n",
        "If you downloaded the correct datafile from the course file server, one of your columns will have missing data.\n",
        "\n",
        "Use `df.fillna()` to replace the missing values in your DataFrame with the median value of that column. Use the same print commands as in `Class_01_6: Example 5` to show what was done."
      ],
      "metadata": {
        "id": "jG2dMQGBiG7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Replace missing values\n",
        "\n"
      ],
      "metadata": {
        "id": "2UEmD6aglnf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see the same list that was generated by Step 3 except now all of the values in the `has_missing` column should be `False`.  "
      ],
      "metadata": {
        "id": "vTneGIKoVvT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5: Display Data Types**\n",
        "\n",
        "**REF: Class_02_2: Example 1 - Step2**\n",
        "\n",
        "Display the different data types in your DataFrame using `df.info()` method.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "Set your print option using this code chunk:\n",
        "```text\n",
        "# Set max rows to the number of columns\n",
        "pd.set_option('display.max_rows', len(df.columns))\n",
        "```\n",
        "where `df` is the name of your DataFrame."
      ],
      "metadata": {
        "id": "9lhujPUbXL7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Display data types\n",
        "\n"
      ],
      "metadata": {
        "id": "n_9WMRbEZsQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the column `Dtype` for the word `object`. This means the column contains string values that need to be mapped to an integer value or one-hot encoded when generating the X- and y- feature vectors."
      ],
      "metadata": {
        "id": "1zjIf9Z8apIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6: One-Hot Encode Categorical Variables**\n",
        "\n",
        "**REF: Class_02_2: Example 3**\n",
        "\n",
        "In the cell below, write the code to one-hot encode all of the categorical variables in your DataFrame. Your code should follow Example 3 in Class_02_2 so you will end up with a new dataframe contained the encoded values.\n",
        "\n",
        "**WARNING:** It is important **_not_** to one-hot encode the **target_column** in this step. The name of the `target_column` was given to you as part of your datafile description near the beginning of this assignment. If you accidently encode the target_column, you will have to start over from Step 1.\n",
        "\n",
        "Use the `display()` function to print the values in your DataFrame before encoding and then print out the values in your new, encoded DataFrame."
      ],
      "metadata": {
        "id": "DxIEjoG7W4Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: One-Hot Encode Categorical Variables\n",
        "\n"
      ],
      "metadata": {
        "id": "azMbzvHr9kXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see two tables. The top table should show your DataFrame `Before One-hot encoding` while the bottom table should show your DataFrame `After One-hot encoding`. The `target_column` should **not** be one-hot encoded!"
      ],
      "metadata": {
        "id": "y2di5K_Tei4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 7: Create Feature Vector for Classification Neural Network**\n",
        "\n",
        "**REF: Class_02_2: Example 5**\n",
        "\n",
        "In the cell below, write the code to preprocess the data in your DataFrame to create a feature vector. In creating your feature vector you should use the `encoded DataFrame` that you generated in the preceding step.\n",
        "\n",
        "**Code Hints:**\n",
        "\n",
        "1. The name of the target column was given as part of the description of your assigned dataset at the beginning of this assignment. You will need the name of the target column for this step.\n",
        "\n",
        "2. Print out your `Feature matrix shape` and your `Target matrix shape` along with the first four values of your feature vector and their corresponding one-hot targets as shown in `Class_02_2: Example 5`."
      ],
      "metadata": {
        "id": "PC9W0pgzJ6uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Create Feature Vector for Classification Neural Network\n",
        "\n"
      ],
      "metadata": {
        "id": "4-RuESlOweej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you code is correct you should see at the top of the output the shape of your `Feature maxtrix` and your `Target maxtrix`.\n",
        "\n",
        "Immediately below you should see the `First 4 feature vectors` followed by the `Corresponding targets` at the bottom."
      ],
      "metadata": {
        "id": "2wNV9kzCaUwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 8: Construct and Train a Classification Neural Network**\n",
        "\n",
        "**REF: Class_02_2 Example 6**\n",
        "\n",
        "In the cell below write the code to construct and train a classification neural network using PyTorch. Your model should have all of the features of the example code in `Class_02_2, Example 6` (i.e. early stopping, training history, code to inspect training, etc)."
      ],
      "metadata": {
        "id": "ZDz5O3hkKOAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Construct and Train a Classification Neural Network\n",
        "\n"
      ],
      "metadata": {
        "id": "iVrSehsC_ysY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct, you should see the training output."
      ],
      "metadata": {
        "id": "-CNJISn-KN0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 9: Visualize Training Curves**\n",
        "\n",
        "**REF: Class_02_4 Example 7**\n",
        "\n",
        "In the cell below, write the code to generate two side-by-side plots, an **Accuracy Curve** and a **Loss Curve** to visualized what happened during training of your model. Each plot should show the value of the `train` accuracy/loss and the `val` accuracy/loss."
      ],
      "metadata": {
        "id": "3k0Bzdp9K6Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Visualize training\n",
        "\n"
      ],
      "metadata": {
        "id": "mI42cck5LEET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct you should see two side-by-side plots showing `Model Loss` on the left and `Model Accuracy` on the right."
      ],
      "metadata": {
        "id": "GDX9-4otW9H8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Assignment Turn-in**\n",
        "\n",
        "When you have completed and run all of the code cells, use the **File --> Print.. --> Save to PDF** to generate a PDF of your Colab notebook. Save your PDF as `Copy of Assignment_01.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas.\n",
        "\n",
        "## **---WARNING---WARNING--WARNING---**\n",
        "\n",
        "Unlike class lessons, you are **only given 1 submission** for assignments. If you failed to carefully follow directions and make a bad mistake you won't have a 2nd chance to correct your errors.\n",
        "\n",
        "Therefore, you are **STRONGLY ENCOURAGED** to have your completed assignment checked by an Instructor **_before_** you submit your PDF to Canvas. Every semester one (or more) students fail to follow directions and receive an automatic `0` on an assignment--which virtually assures that the student just had their final course grade lower by a letter. Don't be that student!"
      ],
      "metadata": {
        "id": "x_Ls8jsIK6Nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lizard's Tail**\n",
        "\n",
        "## **DeepSeek**\n",
        "\n",
        "![__](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/DeepSeek_logo.svg/1920px-DeepSeek_logo.svg.png)\n",
        "\n",
        "**DeepSeek** (Chinese: 深度求索; pinyin: Shēndù Qiúsuǒ) is a Chinese artificial intelligence company that develops open-source large language models (LLMs). Based in Hangzhou, Zhejiang, it is owned and funded by Chinese hedge fund High-Flyer, whose co-founder, Liang Wenfeng, established the company in 2023 and serves as its CEO.\n",
        "\n",
        "The DeepSeek-R1 model provides responses comparable to other contemporary large language models, such as OpenAI's GPT-4o and o1. It is trained at a significantly lower cost—stated at US$6 million compared to $100 million for OpenAI's GPT-4 in 2023—and approximately a tenth of the computing power used for Meta's comparable model, LLaMA 3.1. DeepSeek's AI models were developed amid United States sanctions on China and other countries for chips used to develop artificial intelligence, which were intended to restrict the ability of these countries to develop advanced AI systems. Lesser restrictions were later announced that would affect all but a few countries.\n",
        "\n",
        "On 10 January 2025, DeepSeek released its first free chatbot app, based on the DeepSeek-R1 model, for iOS and Android; by 27 January, DeepSeek had surpassed ChatGPT as the most-downloaded free app on the iOS App Store in the United States,[10] causing Nvidia's share price to drop by 18%. DeepSeek's success against larger and more established rivals has been described as \"upending AI\"[10] and ushering in \"a new era of AI brinkmanship\". DeepSeek's compliance with Chinese government censorship policies and its data collection practices have also raised concerns over privacy and information control in the model, prompting regulatory scrutiny in multiple countries.\n",
        "\n",
        "DeepSeek makes its generative artificial intelligence algorithms, models, and training details open-source, allowing its code to be freely available for use, modification, viewing, and designing documents for building purposes.However, reports indicate that the API version hosted in China applies content restrictions in accordance with local regulations, limiting responses on topics such as the Tiananmen Square massacre and Taiwan’s status. The company reportedly vigorously recruits young AI researchers from top Chinese universities, and hires from outside the computer science field to diversify its models' knowledge and abilities.\n",
        "\n",
        "**Background**\n",
        "\n",
        "In February 2016, High-Flyer was co-founded by AI enthusiast Liang Wenfeng, who had been trading since the 2007–2008 financial crisis while attending Zhejiang University. They began stock-trading with a deep learning model running on GPU on October 21, 2016. Prior to this, they used CPU-based models, mainly linear models. Most trading was done by AI by the end of 2017.\n",
        "\n",
        "By 2019, he established High-Flyer as a hedge fund focused on developing and using AI trading algorithms. By 2021, High-Flyer exclusively used AI in trading, often using Nvidia chips. DeepSeek has made its generative artificial intelligence chatbot open source, meaning its code is freely available for use, modification, and viewing. This includes permission to access and use the source code, as well as design documents, for building purposes.\n",
        "\n",
        "In 2021, while running High-Flyer, Liang began stockpiling Nvidia GPUs for an AI project.[20] According to 36Kr, Liang had built up a store of 10,000 Nvidia A100 GPUs, which are used to train AI, before the United States federal government imposed AI chip restrictions on China.\n",
        "\n",
        "On 14 April 2023,[22] High-Flyer announced the start of an artificial general intelligence lab dedicated to research developing AI tools separate from High-Flyer's financial business. Incorporated on 17 July 2023, with High-Flyer as the investor and backer, the lab became its own company, DeepSeek. Venture capital firms were reluctant to provide funding, as they considered it unlikely that the venture would be able to generate an \"exit\" in a short period of time.\n",
        "\n",
        "On May 16, 2023, the company Beijing DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd. incorporated under the control of Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd. As of May 2024, Liang Wenfeng held 84% of DeepSeek through two shell corporations.\n",
        "\n",
        "After releasing DeepSeek-V2 in May 2024, which offered strong performance for a low price, DeepSeek became known as the catalyst for China's AI model price war. It was quickly dubbed the \"Pinduoduo of AI\", and other major tech giants such as ByteDance, Tencent, Baidu, and Alibaba began to cut the price of their AI models to compete with the company. Despite the low price charged by DeepSeek, it was profitable compared to its rivals that were losing money.\n",
        "\n",
        "DeepSeek is focused on research and has no detailed plans for commercialization, which also allows its technology to avoid the most stringent provisions of China's AI regulations, such as requiring consumer-facing technology to comply with the government's controls on information.\n",
        "\n",
        "DeepSeek's hiring preferences target technical abilities rather than work experience, resulting in most new hires being either recent university graduates or developers whose AI careers are less established. Likewise, the company recruits individuals without any computer science background to help its technology understand other topics and knowledge areas, including being able to generate poetry and perform well on the notoriously difficult Chinese college admissions exams (Gaokao).\n",
        "\n",
        "**Training framework**\n",
        "\n",
        "High-Flyer/DeepSeek has built at least two computing clusters, Fire-Flyer (萤火一号) and Fire-Flyer 2 (萤火二号). Fire-Flyer began construction in 2019 and finished in 2020, at a cost of 200 million yuan. It contained 1,100 GPUs interconnected at a rate of 200 Gbps. It was 'retired' after 1.5 years in operation. Fire-Flyer 2 began construction in 2021 with a budget of 1 billion yuan.[18] It was reported that in 2022, Fire-Flyer 2's capacity had been utilized at over 96%, totaling 56.74 million GPU hours. Of those GPU hours, 27% was used to support scientific computing outside the company.\n",
        "\n",
        "Fire-Flyer 2 consisted of co-designed software and hardware architecture. On the hardware side, there are more GPUs with 200 Gbps interconnects. The cluster is divided into two \"zones\", and the platform supports cross-zone tasks. The network topology was two fat trees, chosen for its high bisection bandwidth. On the software side, there are\n",
        "\n",
        "* **3FS (Fire-Flyer File System):** A distributed parallel file system. It was specifically designed for asynchronous random reads from a dataset, and uses Direct I/O and RDMA Read. In contrast to standard Buffered I/O, Direct I/O does not cache data. Caching is useless for this case, since each data read is random, and would not be reused.\n",
        "* **hfreduce:** Library for asynchronous communication, originally designed to replace Nvidia Collective Communication Library (NCCL).[30] It was mainly used for allreduce, especially of gradients during backpropagation. It is asynchronously run on the CPU to avoid blocking kernels on the GPU.[28] It uses two-tree broadcast like NCCL.\n",
        "* **hfai.nn:** Software library of commonly used operators in neural network training, similar to torch.nn in PyTorch.\n",
        "* **HaiScale Distributed Data Parallel (DDP):** Parallel training library that implements various forms of parallelism in deep learning such as Data Parallelism (DP), Pipeline Parallelism (PP), Tensor Parallelism (TP), Experts Parallelism (EP), Fully Sharded Data Parallel (FSDP) and Zero Redundancy Optimizer (ZeRO). It is similar to PyTorch DDP, which uses NCCL on the backend.\n",
        "* **HAI Platform:** Various applications such as task scheduling, fault handling, and disaster recovery.\n",
        "During 2022, Fire-Flyer 2 had 5000 PCIe A100 GPUs in 625 nodes, each containing 8 GPUs. At the time, they chose to exclusively use PCIe instead of DGX version of A100, since at the time the models they trained could fit within a single 40 GB GPU VRAM, so there was no need for the higher bandwidth of DGX (i.e. they required only data parallelism but not model parallelism).[30] Later, they also incorporated NVLinks and NCCL, to train larger models that required model parallelism.\n",
        "\n",
        "# DeepSeek: A Comprehensive Overview\n",
        "\n",
        "## Introduction\n",
        "\n",
        "DeepSeek is a Chinese artificial intelligence company that has rapidly emerged as a significant player in the global AI landscape. Founded in July 2023 and headquartered in Hangzhou, Zhejiang province, the company has garnered international attention for developing large language models that rival those of leading Western AI companies—but at a fraction of the cost. The company's meteoric rise has been described as an \"AI Sputnik moment,\" challenging long-held assumptions about American dominance in the artificial intelligence industry.\n",
        "\n",
        "## Origins and Founding\n",
        "\n",
        "DeepSeek's origins trace back to High-Flyer Capital Management, a Chinese quantitative hedge fund that uses AI to inform trading decisions. The hedge fund was co-founded in 2015 by Liang Wenfeng, who studied AI at Zhejiang University and began experimenting with trading while still a student. High-Flyer distinguished itself from other hedge funds through its early adoption of AI models for determining stock positions, building a talented team of AI researchers beginning in 2017.\n",
        "\n",
        "In April 2023, High-Flyer announced the establishment of an artificial general intelligence research lab dedicated to developing AI tools separate from its financial operations. By July 2023, this lab was incorporated as an independent company named DeepSeek, with High-Flyer serving as its principal investor and backer. Notably, venture capital investors were initially reluctant to fund the venture, skeptical that it could quickly generate profitable exits. The company received approximately $50 million in investment from High-Flyer and has operated without institutional or angel investors.\n",
        "\n",
        "## Technical Innovations and Cost Efficiency\n",
        "\n",
        "What sets DeepSeek apart from competitors is its remarkable cost efficiency. The company claims to have trained its V3 model for approximately $6 million—dramatically less than the estimated $100 million OpenAI spent on GPT-4 in 2023—while using roughly one-tenth the computing power consumed by comparable models like Meta's Llama 3.1.\n",
        "\n",
        "DeepSeek achieved this efficiency through several technical innovations. First, the company employs a Mixture-of-Experts (MoE) architecture, which functions like a team of specialists rather than a single generalist model. When processing a query, only the most relevant portions of the AI activate while the rest remain idle, significantly reducing computational demands.\n",
        "\n",
        "Second, DeepSeek optimized its models to run on Nvidia H800 GPUs—less powerful but more widely available chips that were designed for the Chinese market after U.S. export restrictions limited access to higher-performance H100 and A100 chips. The company used PTX, an assembly-like programming method that allows developers to control how AI interacts with hardware at a lower level, squeezing more performance from less powerful equipment.\n",
        "\n",
        "Third, DeepSeek reduced expensive human fine-tuning by automating much of the training process using reinforcement learning. While most AI models rely on large teams of human reviewers to manually refine responses, DeepSeek's approach allows the AI to learn more efficiently from experience.\n",
        "\n",
        "## Major Model Releases\n",
        "\n",
        "DeepSeek has released a series of increasingly capable models since its founding. The company's first model, DeepSeek Coder, launched in November 2023, followed by the DeepSeek-LLM series later that month. Throughout 2024, the company released specialized models including DeepSeek-MoE, DeepSeek-Math, and DeepSeek-V2.\n",
        "\n",
        "The breakthrough came in December 2024 with DeepSeek-V3, a model featuring 671 billion parameters that demonstrated superior reasoning skills and strong performance in coding and mathematics. According to internal benchmarks, V3 outperformed both openly available models like Meta's Llama and closed models like OpenAI's GPT-4o.\n",
        "\n",
        "In January 2025, DeepSeek released the R1 reasoning model alongside a consumer chatbot application. R1 employs a chain-of-thought approach similar to OpenAI's o1 model, solving problems by processing queries step by step. The model has been praised for its ability to tackle complex reasoning tasks, particularly in mathematics and coding, while effectively fact-checking itself to avoid common pitfalls.\n",
        "\n",
        "## Market Impact and Global Response\n",
        "\n",
        "The January 2025 release of DeepSeek's chatbot had immediate and dramatic consequences. Within days, the DeepSeek app surpassed ChatGPT as the most downloaded free application on Apple's U.S. App Store. By January 27, 2025, the company had accumulated approximately 22 million daily active users.\n",
        "\n",
        "The market reaction was swift and severe. On January 27, Nvidia's stock price plummeted 17%, wiping out nearly $600 billion in market capitalization—the largest single-day loss for any company in U.S. history. The broader technology sector experienced significant declines as investors reevaluated assumptions about AI infrastructure demand and the competitive landscape.\n",
        "\n",
        "The development raised questions about whether the U.S. could maintain its lead in artificial intelligence and whether the massive investments in AI chips would sustain their projected returns. In China, DeepSeek's success triggered a price war, compelling major tech companies including ByteDance, Tencent, Baidu, and Alibaba to significantly cut prices on their AI models.\n",
        "\n",
        "## Company Culture and Organization\n",
        "\n",
        "DeepSeek operates with a distinctly different culture from typical Chinese technology companies. Rather than adopting the industry-standard \"996\" work culture (9 a.m. to 9 p.m., six days a week), DeepSeek fosters a meritocratic environment that prioritizes technical competence over extensive work experience. The company aggressively recruits doctoral AI researchers from top Chinese universities and frequently hires recent graduates. Interestingly, DeepSeek also employs individuals without computer science backgrounds to help its technology better understand diverse subjects.\n",
        "\n",
        "The company maintains a relatively small team of approximately 200 employees compared to OpenAI's 3,500. Most DeepSeek researchers finished their degrees within the past two years, bringing fresh perspectives and minimal corporate baggage. Former employees have described the work environment as offering abundant computing resources and freedom to experiment—opportunities rarely available to fresh graduates at other companies.\n",
        "\n",
        "## Challenges and Controversies\n",
        "\n",
        "DeepSeek faces several challenges and has attracted various controversies. The company operates under U.S. export controls that restrict access to advanced semiconductors. While High-Flyer acquired a substantial stockpile of Nvidia A100 chips before the anticipated sanctions—estimates range from 10,000 to 50,000 units—the company must now work with less powerful chips for new training runs.\n",
        "\n",
        "Content moderation presents another challenge. DeepSeek's models have been noted for adhering to official Chinese Communist Party ideology and censorship guidelines, particularly in recent releases. Like other AI chatbots, DeepSeek's models struggle with fact-checking, exhibit tendencies to hallucinate information, and sometimes lack deep insight in areas requiring abstract thinking.\n",
        "\n",
        "The U.S. government has grown wary of potential foreign influence, with reports indicating plans to ban DeepSeek on government devices. The company delayed the release of its R2 model, initially planned for May 2025, due to challenges training it on domestically produced Huawei chips.\n",
        "\n",
        "## Future Outlook\n",
        "\n",
        "DeepSeek has stated that it focuses on research rather than immediate commercialization, positioning itself more like a nonprofit research organization than a typical technology company. This approach—ironically the opposite of OpenAI's trajectory from nonprofit to profit-driven enterprise—allows DeepSeek to prioritize fundamental AI research.\n",
        "\n",
        "Looking ahead, DeepSeek continues to release model updates and has published research detailing more efficient methods for AI development. While subsequent releases throughout 2025 have been viewed as incremental improvements rather than new shockwaves, analysts suggest more significant releases may be forthcoming. The company's success has demonstrated that powerful AI can be built through smarter software optimization rather than brute-force hardware acquisition, potentially reshaping the entire AI industry's approach to model development.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "DeepSeek represents a significant shift in the global AI landscape. By developing competitive large language models at dramatically lower costs despite hardware restrictions, the company has challenged assumptions about the requirements for advanced AI development. Whether DeepSeek's research-focused approach and efficiency-driven methodology will reshape the broader industry remains to be seen, but its impact on AI development strategies and market dynamics has already proven substantial."
      ],
      "metadata": {
        "id": "jyj_ZFKtLUiS"
      }
    }
  ]
}