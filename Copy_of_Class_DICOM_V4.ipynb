{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM00oramYfMadYMR3mC8xhV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173/blob/main/Copy_of_Class_DICOM_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXB6ugBZckOU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Packages"
      ],
      "metadata": {
        "id": "ZXpVFbt5c89T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXhh_CjKc9cj",
        "outputId": "55da47e4-a19b-4d6e-affb-667ec2040829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download and Extract Data**"
      ],
      "metadata": {
        "id": "hQefRtCSc96S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import zipfile\n",
        "import sys\n",
        "import shutil\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Configuration – change only if you want a different URL / filename\n",
        "# ------------------------------------------------------------------\n",
        "URL = \"https://biologicslab.co/BIO1173/data/\"\n",
        "ZIP_FILENAME = \"pna_data.zip\"\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Download the zip file (streamed, so it works with large files)\n",
        "# ------------------------------------------------------------------\n",
        "def download_zip(url: str, dest: Path, chunk_size: int = 8192) -> None:\n",
        "    \"\"\"Download a file from `url` and write it to `dest`.\"\"\"\n",
        "    print(f\"Downloading {ZIP_FILENAME} to {dest}...\", end='')\n",
        "    with requests.get(url, stream=True, timeout=30) as r:\n",
        "        r.raise_for_status()           # will raise for 4xx/5xx\n",
        "        with dest.open(\"wb\") as f_out:\n",
        "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                if chunk:               # filter out keep‑alive new chunks\n",
        "                    f_out.write(chunk)\n",
        "    print(\"done\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Un‑zip the downloaded archive into a *named* directory\n",
        "# ------------------------------------------------------------------\n",
        "def unzip_file(zip_path: Path, extract_to: Path) -> None:\n",
        "    \"\"\"Extract all members of `zip_path` into `extract_to`.\"\"\"\n",
        "    print(f\"Unzipping {ZIP_FILENAME} to {extract_to}...\", end='')\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "        zf.extractall(extract_to)\n",
        "    print(\"done\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Optional – delete the zip after extraction\n",
        "# ------------------------------------------------------------------\n",
        "def clean_up_zip(zip_path: Path) -> None:\n",
        "    \"\"\"Delete the zip file – only if you no longer need it.\"\"\"\n",
        "    zip_path.unlink()\n",
        "    print(f\"Removed temporary archive: {zip_path}... done\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Main routine\n",
        "# ------------------------------------------------------------------\n",
        "def main() -> None:\n",
        "    cwd          = Path.cwd()            # current working directory\n",
        "    zip_path     = cwd / ZIP_FILENAME\n",
        "    extract_dir  = cwd / zip_path.stem   # e.g. /pna_data\n",
        "\n",
        "    # Ensure the extraction directory exists\n",
        "    extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download\n",
        "    download_zip(URL+ZIP_FILENAME, zip_path)\n",
        "\n",
        "    # Un‑zip\n",
        "    unzip_file(zip_path, extract_dir)\n",
        "\n",
        "    # Clean‑up the downloaded archive\n",
        "    clean_up_zip(zip_path)\n",
        "\n",
        "    print(f\"Files have been extracted to {extract_dir}\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFkhNgo3c-T6",
        "outputId": "0fa9248b-867e-48ac-ad41-4873a2a33175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pna_data.zip to /content/pna_data.zip...done\n",
            "Unzipping pna_data.zip to /content/pna_data...done\n",
            "Removed temporary archive: /content/pna_data.zip... done\n",
            "Files have been extracted to /content/pna_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Process DICOM Images**\n",
        "\n"
      ],
      "metadata": {
        "id": "zivizylnc-oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "\n",
        "# Global settings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "#  Helper: read a single DICOM file\n",
        "# -------------------------------------------------------------\n",
        "def read_dicom_file(file_path: str):\n",
        "    \"\"\"Read a DICOM file and extract image data + basic metadata.\"\"\"\n",
        "    ds = pydicom.dcmread(file_path)\n",
        "\n",
        "    # Basic metadata\n",
        "    metadata = {\n",
        "        'filename': os.path.basename(file_path),\n",
        "        'patient_name': getattr(ds, 'PatientName', 'Unknown'),\n",
        "        'patient_id': getattr(ds, 'PatientID', 'Unknown'),\n",
        "        'study_date': getattr(ds, 'StudyDate', 'Unknown'),\n",
        "        'study_time': getattr(ds, 'StudyTime', 'Unknown'),\n",
        "        'modality': getattr(ds, 'Modality', 'Unknown'),\n",
        "        'manufacturer': getattr(ds, 'Manufacturer', 'Unknown'),\n",
        "        'institution_name': getattr(ds, 'InstitutionName', 'Unknown'),\n",
        "        'series_description': getattr(ds, 'SeriesDescription', 'Unknown'),\n",
        "        'bits_allocated': getattr(ds, 'BitsAllocated', 'Unknown'),\n",
        "        'rows': getattr(ds, 'Rows', 'Unknown'),\n",
        "        'columns': getattr(ds, 'Columns', 'Unknown'),\n",
        "        'pixel_spacing': getattr(ds, 'PixelSpacing', 'Unknown')\n",
        "    }\n",
        "\n",
        "    # Image data\n",
        "    if hasattr(ds, 'pixel_array'):\n",
        "        image_array = ds.pixel_array\n",
        "\n",
        "        # Normalise to 0‑255 if needed\n",
        "        if image_array.dtype != np.uint8:\n",
        "            image_array = ((image_array - image_array.min()) /\n",
        "                           (image_array.max() - image_array.min()) * 255).astype(np.uint8)\n",
        "\n",
        "        metadata['image_available'] = True\n",
        "        metadata['image_shape'] = image_array.shape\n",
        "    else:\n",
        "        metadata['image_available'] = False\n",
        "        metadata['image_shape'] = 'No image data'\n",
        "\n",
        "    return ds, metadata\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "#  Helper: fast drop‑check\n",
        "# -------------------------------------------------------------\n",
        "def is_file_dropped(file_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Quick guard that tells us whether a DICOM file is already\n",
        "    missing / unreadable.\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(file_path):\n",
        "        return True\n",
        "\n",
        "    if os.path.getsize(file_path) == 0:\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        pydicom.dcmread(file_path, stop_before_pixels=True)\n",
        "    except Exception:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "#  Load & preprocess – merge CSVs, keep only valid DICOM rows\n",
        "# -------------------------------------------------------------\n",
        "def load_and_preprocess_data(\n",
        "    data_dir: str = '.',\n",
        "    log_dropped: bool = True\n",
        "):\n",
        "    # Load the two CSVs, merge on patient ID, and keep only rows\n",
        "    # that have an intact DICOM image.\n",
        "    info_df   = pd.read_csv(os.path.join(data_dir, 'pna_detailed_class_info.csv'))\n",
        "    labels_df = pd.read_csv(os.path.join(data_dir, 'pna_train_labels.csv'))\n",
        "\n",
        "    # Define patient ID variable\n",
        "    info_id_col   = 'patientId'\n",
        "    labels_id_col = 'patientId'\n",
        "\n",
        "    merged_df = pd.merge(info_df, labels_df, left_on=info_id_col,\n",
        "                         right_on=labels_id_col, how='inner')\n",
        "\n",
        "    dicom_dir = os.path.join(data_dir, 'pna_train_images')\n",
        "    valid_rows = []\n",
        "    dropped_ids = []\n",
        "\n",
        "    for idx, row in merged_df.iterrows():\n",
        "        patient_id = row[info_id_col]\n",
        "        dicom_file = os.path.join(dicom_dir, f\"{patient_id}.dcm\")\n",
        "\n",
        "        if is_file_dropped(dicom_file):\n",
        "            dropped_ids.append(patient_id)\n",
        "        else:\n",
        "            valid_rows.append(idx)\n",
        "\n",
        "    filtered_df = merged_df.loc[valid_rows].copy()\n",
        "    print(f\"Filtered DataFrame shape (with valid DICOM files): {filtered_df.shape}\")\n",
        "\n",
        "    return filtered_df, dropped_ids\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "#  Build X, y arrays – skip any DICOM that fails\n",
        "# -------------------------------------------------------------\n",
        "def create_dataset(\n",
        "    filtered_df: pd.DataFrame,\n",
        "    data_dir: str = '.',\n",
        "    target_column: str = 'Target',\n",
        "    max_samples: int | None = None,\n",
        "    verbose: bool = True,\n",
        "    # optional: allow a reproducible random seed\n",
        "    random_state: int | None = None,\n",
        ") -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build X, y arrays from the given DataFrame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filtered_df : pd.DataFrame\n",
        "        DataFrame that contains (at least) the columns `patientId` and the target.\n",
        "    data_dir : str, default='.'\n",
        "        Base directory that contains the sub‑folder `pna_train_images/`.\n",
        "    target_column : str, default='Target'\n",
        "        Column name that holds the target label.\n",
        "    max_samples : int | None, default=None\n",
        "        If provided, a random subset of this size will be chosen from\n",
        "        ``filtered_df`` before loading.  If ``max_samples`` is larger\n",
        "        than the number of available rows, all rows are used.\n",
        "    verbose : bool, default=True\n",
        "        Show progress / debug messages.\n",
        "    random_state : int | None, default=None\n",
        "        Seed for reproducible shuffling.  Pass an integer if you need\n",
        "        deterministic behaviour; otherwise the selection is truly random.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : np.ndarray\n",
        "        Image data of shape (N, H, W, 3) with dtype uint8.\n",
        "    y : np.ndarray\n",
        "        Corresponding target labels of shape (N,) with dtype int.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    from tqdm import tqdm\n",
        "    import numpy as np\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        if verbose:\n",
        "            print(\"Input DataFrame is empty – nothing to load.\")\n",
        "        return np.array([], dtype=np.uint8), np.array([], dtype=int)\n",
        "\n",
        "    # ---------- Randomly sub‑sample if requested ----------\n",
        "    if max_samples is not None:\n",
        "        n_available = len(filtered_df)\n",
        "        if max_samples < n_available:\n",
        "            # ``sample`` performs a random shuffle; replace=False guarantees\n",
        "            # unique rows.  ``random_state`` makes the selection reproducible.\n",
        "            filtered_df = filtered_df.sample(n=max_samples, random_state=random_state)\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\n",
        "                    f\"Requested max_samples={max_samples} \"\n",
        "                    f\"but only {n_available} rows are available – \"\n",
        "                    \"using all rows.\"\n",
        "                )\n",
        "    # ---------- Build dataset ----------\n",
        "    print(\"Creating dataset\")\n",
        "\n",
        "    dicom_dir = os.path.join(data_dir, \"pna_train_images\")\n",
        "\n",
        "    iterator = tqdm(\n",
        "        filtered_df.iterrows(),\n",
        "        total=len(filtered_df),\n",
        "        desc=\"Loading DICOM Images\",\n",
        "        disable=not verbose,\n",
        "    )\n",
        "\n",
        "    images, labels = [], []\n",
        "\n",
        "    info_id_col, labels_id_col = 'patientId', 'patientId'\n",
        "\n",
        "    for i, (_, row) in enumerate(iterator, start=1):\n",
        "        patient_id = row[info_id_col]\n",
        "        dicom_file = os.path.join(dicom_dir, f\"{patient_id}.dcm\")\n",
        "\n",
        "        if not os.path.exists(dicom_file):\n",
        "            if verbose:\n",
        "                tqdm.write(f\"[{i}] Missing file: {patient_id}\")\n",
        "            continue\n",
        "\n",
        "        ds, metadata = read_dicom_file(dicom_file)\n",
        "\n",
        "        if metadata is None or not metadata.get(\"image_available\", False):\n",
        "            if verbose:\n",
        "                tqdm.write(f\"[{i}] No image in {patient_id}\")\n",
        "            continue\n",
        "\n",
        "        img = ds.pixel_array\n",
        "        if img.ndim == 2:\n",
        "            img = np.stack([img] * 3, axis=-1)\n",
        "\n",
        "        images.append(img.astype(np.uint8))\n",
        "        labels.append(int(row[target_column]))\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Assemble the final arrays *after* the loop finishes\n",
        "    # ----------------------------------------------------------------------\n",
        "\n",
        "    X = np.stack(images, axis=0) if images else np.array([], dtype=np.uint8)\n",
        "    y = np.array(labels, dtype=int) if labels else np.array([], dtype=int)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"The number of Image files = {len(X)}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "#  Main block – run the whole pipeline\n",
        "# -------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to the data root\n",
        "    data_root = os.path.join('.', 'pna_data')"
      ],
      "metadata": {
        "id": "nQz7yVgbc_OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generate Datasets**"
      ],
      "metadata": {
        "id": "8V8M5NcAc_uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "\n",
        "# Define number of images to use\n",
        "MAX_SAMPLES=500\n",
        "\n",
        "# Generate filtered_df\n",
        "filtered_df, _ = load_and_preprocess_data(data_dir=data_root)\n",
        "\n",
        "# Build X, y\n",
        "X, y = create_dataset(filtered_df, data_dir=data_root, target_column='Target', max_samples=MAX_SAMPLES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3_gNwiCdARy",
        "outputId": "9e8efa05-d38c-4383-ca17-f86f76c8c6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered DataFrame shape (with valid DICOM files): (9337, 7)\n",
            "Creating dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading DICOM Images: 100%|██████████| 500/500 [00:04<00:00, 123.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of Image files = 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build Data Vectors**"
      ],
      "metadata": {
        "id": "SZBJLJyxdAtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, Optional, Callable, Any\n",
        "\n",
        "# Set Import Variables\n",
        "NUM_EPOCHS: int=1\n",
        "BATCH_SIZE: int=16\n",
        "IMG_SIZE: int=244\n",
        "\n",
        "# ------------------------------------------\n",
        "# Helper: Build transforms\n",
        "# ------------------------------------------\n",
        "def get_transform(\n",
        "    img_size=IMG_SIZE,\n",
        "    is_train: bool = True,\n",
        "    crop_size=IMG_SIZE,\n",
        "    h_flip: bool = True,\n",
        "    augment: bool = False\n",
        ") -> Callable:\n",
        "    \"\"\"\n",
        "    Returns a torchvision transform chain.\n",
        "    \"\"\"\n",
        "    if is_train:\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.RandomResizedCrop(crop_size) if augment else transforms.RandomCrop(crop_size),\n",
        "            transforms.RandomHorizontalFlip() if h_flip else transforms.Lambda(lambda x: x),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    else:  # eval / test\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.CenterCrop(crop_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    return transform\n",
        "\n",
        "\n",
        "# ------------------------------------------\n",
        "# Helper: Build dataloaders\n",
        "# ------------------------------------------\n",
        "def build_dataloaders(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    val_split: float = 0.2,\n",
        "    seed: int = 42,\n",
        "    num_workers: int = 4,\n",
        ") -> tuple[DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Returns training and validation DataLoaders.\n",
        "    \"\"\"\n",
        "    dataset = DicomDataset(X, y, transform=get_transform(is_train=True))\n",
        "\n",
        "    total = len(dataset)\n",
        "    val_len = int(total * val_split)\n",
        "    train_len = total - val_len\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
        "\n",
        "    # Override transforms for validation\n",
        "    val_ds.dataset.transform = get_transform(is_train=False)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# ------------------------------------------\n",
        "# Training loop\n",
        "# ------------------------------------------\n",
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    optimizer: optim.Optimizer,\n",
        "    device: torch.device,\n",
        ") -> float:\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for imgs, targets in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "    return epoch_loss / len(loader.dataset)\n",
        "\n",
        "# --------------------------------------------\n",
        "# Measure validation loss during training\n",
        "# --------------------------------------------\n",
        "def validate(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device,\n",
        ") -> tuple[float, float]:\n",
        "    model.eval()\n",
        "    epoch_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets in tqdm(loader, desc=\"Validation\", leave=False):\n",
        "            imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            epoch_loss += loss.item() * imgs.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == targets).sum().item()\n",
        "\n",
        "    val_loss = epoch_loss / len(loader.dataset)\n",
        "    val_acc = correct / len(loader.dataset)\n",
        "    return val_loss, val_acc\n",
        "\n",
        "# ------------------------------------------\n",
        "# Get ResNet50 model\n",
        "# ------------------------------------------\n",
        "def get_resnet50(\n",
        "    num_classes: int,\n",
        "    pretrained: bool = True,\n",
        "    device: torch.device | None = None,\n",
        "    name: str | None = None\n",
        ") -> nn.Module:\n",
        "    \"\"\"Return a ResNet‑50 backbone.  Optionally attach a `name` attribute.\"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    backbone = models.resnet50(pretrained=pretrained)\n",
        "    backbone.fc = nn.Linear(backbone.fc.in_features, num_classes)\n",
        "    backbone.to(device)\n",
        "\n",
        "    # Attach a name only if one was supplied\n",
        "    if name is not None:\n",
        "        backbone.name = name\n",
        "    return backbone\n",
        "\n",
        "# ------------------------------------------\n",
        "# Get ResNet101 model\n",
        "# ------------------------------------------\n",
        "def get_resnet101(\n",
        "    num_classes: int,\n",
        "    pretrained: bool = True,\n",
        "    device: torch.device | None = None,\n",
        "    name: str | None = None\n",
        ") -> nn.Module:\n",
        "    \"\"\"Return a ResNet‑101 backbone.  Optionally attach a `name` attribute.\"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    backbone = models.resnet101(pretrained=pretrained)\n",
        "    backbone.fc = nn.Linear(backbone.fc.in_features, num_classes)\n",
        "    backbone.to(device)\n",
        "\n",
        "    # Attach a name only if one was supplied\n",
        "    if name is not None:\n",
        "        backbone.name = name\n",
        "    return backbone\n",
        "\n",
        "# ------------------------------------------\n",
        "# Plotting routine\n",
        "# ------------------------------------------\n",
        "\n",
        "def plot_training(history, num_epochs, batch_size):\n",
        "    \"\"\"\n",
        "    Plots training/validation loss & accuracy\n",
        "    \"\"\"\n",
        "    # ------------------------------------------------------------\n",
        "    # Plot the curves\n",
        "    # ------------------------------------------------------------\n",
        "    epochs = np.arange(1, NUM_EPOCHS + 1)\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    ax1.plot(epochs, history['train_loss'], label='train loss', color='C0')\n",
        "    ax1.plot(epochs, history['val_loss'],  label='val loss',   color='C1')\n",
        "    ax2.plot(epochs, history['val_acc'],   label='val acc',   color='C2')\n",
        "\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax1.set_ylim(bottom=0)\n",
        "    ax2.set_ylim(bottom=0, top=1)\n",
        "\n",
        "    # Merge legends from both axes\n",
        "    lines, labels = ax1.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(lines + lines2, labels + labels2, loc='upper left')\n",
        "\n",
        "    plt.title('Training on GPU – loss & accuracy')\n",
        "    plt.tight_layout()\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------\n",
        "# Training routine\n",
        "# ------------------------------------------\n",
        "def run_training(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    lr: float = 1e-4,\n",
        "    weight_decay: float = 1e-4,\n",
        "    val_split: float = 0.2,\n",
        "    device: torch.device | None = None,\n",
        "    model: nn.Module | None = None\n",
        ") -> dict:\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Device handling\n",
        "    # -------------------------------------------------------------\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Prepare the dataset\n",
        "    # -------------------------------------------------------------\n",
        "    X = torch.tensor(X, dtype=torch.float32)\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    # Split into train / val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=val_split, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    train_ds = TensorDataset(X_train, y_train)\n",
        "    val_ds   = TensorDataset(X_val,   y_val)\n",
        "\n",
        "    batch_size = BATCH_SIZE\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Model handling - if no model provided, create one\n",
        "    # -------------------------------------------------------------\n",
        "    if model is None:\n",
        "        # Create a ResNet50 model (since you have this function)\n",
        "        print(\"WARNING: No model. Generating model\")\n",
        "        num_classes = int(y.max().item() + 1)  # Get number of classes\n",
        "        model = get_resnet50(num_classes=num_classes, pretrained=True, device=device)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Loss, Optimiser, Scheduler\n",
        "    # -------------------------------------------------------------\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=num_epochs, eta_min=lr * 0.01\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Lists to store metrics\n",
        "    # -------------------------------------------------------------\n",
        "    train_losses, val_losses, val_accs = [], [], []\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Epoch loop\n",
        "    # -------------------------------------------------------------\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        # ---- Train ------------------------------------------------\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss   = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_train_loss += loss.item() * xb.size(0)   # accumulate over batch\n",
        "\n",
        "        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "\n",
        "        # ---- Validation ------------------------------------------\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss   = criterion(logits, yb)\n",
        "\n",
        "                running_val_loss += loss.item() * xb.size(0)\n",
        "\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                correct += (preds == yb).sum().item()\n",
        "\n",
        "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc  = correct / len(val_loader.dataset)\n",
        "\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        val_accs.append(epoch_val_acc)\n",
        "\n",
        "        # ---- Scheduler step ---------------------------------------\n",
        "        scheduler.step()\n",
        "\n",
        "        # ---- (Optional) print progress ----------------------------\n",
        "        print(f\"Epoch {epoch:02d}/{NUM_EPOCHS} | \"\n",
        "              f\"train_loss={epoch_train_loss:.4f} | \"\n",
        "              f\"val_loss={epoch_val_loss:.4f} | \"\n",
        "              f\"val_acc={epoch_val_acc:.4f}\")\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Build and return the history dict\n",
        "    # -------------------------------------------------------------\n",
        "    history = {\n",
        "        \"train_loss\": train_losses,\n",
        "        \"val_loss\":   val_losses,\n",
        "        \"val_acc\":    val_accs,\n",
        "    }\n",
        "    return history"
      ],
      "metadata": {
        "id": "Bx5m8Q20dBZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Display Functions**"
      ],
      "metadata": {
        "id": "Wo0BpwYedB8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "from typing import Tuple, Optional, Callable, Any\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Dataset wrapper\n",
        "# -------------------------------------------------------------\n",
        "class DicomDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        X: np.ndarray,\n",
        "        y: np.ndarray,\n",
        "        transform: Optional[Callable] = None\n",
        "    ):\n",
        "        assert X.ndim == 4, f\"X must be (N, H, W, C) but got shape {X.shape}\"\n",
        "        assert y.ndim == 1, f\"y must be 1‑D but got shape {y.shape}\"\n",
        "        assert X.shape[0] == y.shape[0], \"X and y must have the same number of samples\"\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.X[idx]          # shape (H, W, 3), dtype uint8\n",
        "        label = int(self.y[idx])\n",
        "\n",
        "        # Convert to PIL Image so torchvision transforms can work\n",
        "        img = transforms.ToPILImage()(img)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "#  Show a single DICOM image (for sanity checks)\n",
        "# -------------------------------------------------------------\n",
        "def display_dicom_image(file_path: str, figsize: tuple = (10, 10)):\n",
        "    \"\"\"Show a single DICOM image with proper orientation.\"\"\"\n",
        "    ds = pydicom.dcmread(file_path)\n",
        "    if hasattr(ds, 'pixel_array'):\n",
        "        img = ds.pixel_array\n",
        "        if getattr(ds, 'PhotometricInterpretation', None) == 'MONOCHROME1':\n",
        "            img = np.max(img) - img\n",
        "\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(ds.SOPClassUID)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"This DICOM has no pixel data.\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "#  Visualise class / target distributions\n",
        "# -------------------------------------------------------------\n",
        "def visualize_data_distribution(filtered_df: pd.DataFrame):\n",
        "    if filtered_df is None:\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Class distribution\n",
        "    plt.subplot(1, 2, 1)\n",
        "    if 'class' in filtered_df.columns:\n",
        "        class_counts = filtered_df['class'].value_counts()\n",
        "        class_counts.plot(kind='bar')\n",
        "        plt.title('Class Distribution')\n",
        "        plt.ylabel('Count')\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No class column found', ha='center')\n",
        "        plt.title('Class Distribution')\n",
        "\n",
        "    # Target distribution\n",
        "    plt.subplot(1, 2, 2)\n",
        "    if 'Target' in filtered_df.columns:\n",
        "        target_counts = filtered_df['Target'].value_counts()\n",
        "        target_counts.plot(kind='bar')\n",
        "        plt.title('Target Distribution')\n",
        "        plt.ylabel('Count')\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No Target column found', ha='center')\n",
        "        plt.title('Target Distribution')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "#  Plot history\n",
        "# -------------------------------------------------------------\n",
        "def plot_history(\n",
        "    history: dict,\n",
        "    num_epochs: int,\n",
        "    batch_size: int,\n",
        "    title: str | None = None,\n",
        ") -> dict:\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 1️⃣ Plot curves\n",
        "    # ------------------------------------------------------------------\n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    ax1.plot(epochs, history[\"train_loss\"], label=\"train loss\", color=\"C0\")\n",
        "    ax1.plot(epochs, history[\"val_loss\"],   label=\"val loss\",   color=\"C1\")\n",
        "    ax2.plot(epochs, history[\"val_acc\"],    label=\"val acc\",    color=\"C2\")\n",
        "\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax2.set_ylabel(\"Accuracy\")\n",
        "    ax1.set_ylim(bottom=0)\n",
        "    ax2.set_ylim(bottom=0, top=1)\n",
        "\n",
        "    # Merge legends from both axes\n",
        "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
        "\n",
        "    # Optional custom title\n",
        "    if title is None:\n",
        "        title = \"Training on GPU – loss & accuracy\"\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "0uwrohp5eMWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train Model**"
      ],
      "metadata": {
        "id": "v2e6Od-reNe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "NUM_EPOCHS= 4\n",
        "\n",
        "# Get model\n",
        "NUM_CLASSES = len(set(y))          # y is your numpy array of labels\n",
        "pna_model = get_resnet101(num_classes=NUM_CLASSES, name=\"pna_model\")\n",
        "\n",
        "# Train model\n",
        "print(f\"---Training is starting for {NUM_EPOCHS} epochs ----------\")\n",
        "history = run_training(\n",
        "    X, y,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-4,\n",
        "    val_split=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "jVL_Ij5edCjy",
        "outputId": "bd6bd58e-7d47-47b8-eaf9-3abcd1cdc5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Training is starting for 4 epochs ----------\n",
            "WARNING: No model. Generating model\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 225MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[16, 1024, 1024, 3] to have 3 channels, but got 1024 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3587232324.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"---Training is starting for {NUM_EPOCHS} epochs ----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m history = run_training(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2243718813.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(X, y, num_epochs, batch_size, lr, weight_decay, val_split, device, model)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0mloss\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[16, 1024, 1024, 3] to have 3 channels, but got 1024 channels instead"
          ]
        }
      ]
    }
  ]
}